{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# 지역난방 열수요 예측: 완전한 고도화된 스태킹 앙상블\n",
        "\n",
        "## 모델링 전략\n",
        "- **구성**: 3개 규모 그룹 × 2개 계절 = 6개 모델\n",
        "- **스태킹**: Prophet + CatBoost + LSTM + Ridge 메타모델\n",
        "- **최적화**: 모든 모델에 Optuna + 3-Fold CV\n",
        "- **총 모델**: 18개 + 6개 메타모델 = 24개\n",
        "- **재현성**: 완전한 시드 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "setup"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "로컬 환경에서 실행 중...\n"
          ]
        }
      ],
      "source": [
        "# Google Colab 환경 확인 및 패키지 설치\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Google Colab 환경에서 실행 중...\")\n",
        "    !pip install catboost prophet torch optuna statsmodels holidays pmdarima scikit-learn==1.3.0 --quiet\n",
        "    from google.colab import files, drive\n",
        "    print(\"패키지 설치 완료!\")\n",
        "else:\n",
        "    print(\"로컬 환경에서 실행 중...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# 완전한 재현성을 위한 시드 고정\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 라이브러리 import\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "import holidays\n",
        "import json\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "# Prophet/Stan 로그 완전 차단\n",
        "os.environ['CMDSTAN_LOGGER'] = 'ERROR'\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# 특정 로거들 비활성화\n",
        "for logger_name in ['prophet', 'cmdstanpy', 'pystan']:\n",
        "    logging.getLogger(logger_name).setLevel(logging.CRITICAL)\n",
        "    logging.getLogger(logger_name).disabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "imports2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "디바이스: cpu\n",
            "라이브러리 로드 완료! (시드 고정으로 재현성 보장)\n"
          ]
        }
      ],
      "source": [
        "# 머신러닝 라이브러리\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit, KFold\n",
        "import catboost as cb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# PyTorch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Prophet\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Prophet 설치 필요\")\n",
        "    Prophet = None\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# ARIMA\n",
        "try:\n",
        "    from pmdarima import auto_arima\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "except ImportError:\n",
        "    print(\"pmdarima 설치 필요\")\n",
        "    auto_arima = None\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"디바이스: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "print(\"라이브러리 로드 완료! (시드 고정으로 재현성 보장)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Huber Loss 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "# Huber Loss 함수 정의\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    \"\"\"\n",
        "    Huber Loss 계산\n",
        "    delta보다 작은 오차에는 제곱 손실, 큰 오차에는 선형 손실 적용\n",
        "    \"\"\"\n",
        "    residual = np.abs(y_true - y_pred)\n",
        "    condition = residual <= delta\n",
        "    squared_loss = 0.5 * residual**2\n",
        "    linear_loss = delta * residual - 0.5 * delta**2\n",
        "    return np.where(condition, squared_loss, linear_loss).mean()\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred, delta=1.0):\n",
        "    \"\"\"RMSE와 Huber Loss를 동시에 계산\"\"\"\n",
        "    # RMSE 계산\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    \n",
        "    # Huber Loss 계산\n",
        "    residual = np.abs(y_true - y_pred)\n",
        "    condition = residual <= delta\n",
        "    squared_loss = 0.5 * residual**2\n",
        "    linear_loss = delta * residual - 0.5 * delta**2\n",
        "    huber = np.where(condition, squared_loss, linear_loss).mean()\n",
        "    \n",
        "    return {'rmse': rmse, 'huber': huber}\n",
        "\n",
        "def huber_score(y_true, y_pred, delta=1.0):\n",
        "    \"\"\"최적화용 Huber Score (작을수록 좋음)\"\"\"\n",
        "    return evaluate_predictions(y_true, y_pred, delta)['huber']\n",
        "\n",
        "print(\"Huber Loss 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_load"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일 경로 설정 완료\n"
          ]
        }
      ],
      "source": [
        "# 데이터 파일 로드\n",
        "if IN_COLAB:\n",
        "    print(\"파일 업로드 방법 선택:\")\n",
        "    print(\"1. 직접 업로드\")\n",
        "    print(\"2. Google Drive\")\n",
        "\n",
        "    method = input(\"선택 (1 또는 2): \")\n",
        "\n",
        "    if method == \"1\":\n",
        "        uploaded = files.upload()\n",
        "        files_list = list(uploaded.keys())\n",
        "        train_path = [f for f in files_list if 'train' in f.lower()][0]\n",
        "        test_path = [f for f in files_list if 'test' in f.lower()][0]\n",
        "    else:\n",
        "        drive.mount('/content/drive')\n",
        "        train_path = \"/content/drive/MyDrive/train_heat.csv\"\n",
        "        test_path = \"/content/drive/MyDrive/test_heat.csv\"\n",
        "else:\n",
        "    train_path = '/dataset/train_heating.csv' ## 경로 수정 필요\n",
        "    test_path = '/dataset/test_heating.csv' ## 경로 수정 필요\n",
        "\n",
        "print(f\"파일 경로 설정 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing"
      },
      "source": [
        "## 1. 고도화된 데이터 (결측치 플래그 생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "preprocess_func"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_advanced(train_path, test_path):\n",
        "    print(\"고도화된 데이터 로드 및 전처리...\")\n",
        "\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    def process_df_advanced(df):\n",
        "        if 'Unnamed: 0' in df.columns:\n",
        "            df = df.drop(columns=['Unnamed: 0'])\n",
        "        df.columns = [col.replace('train_heat.', '') for col in df.columns]\n",
        "\n",
        "        if df['tm'].dtype == 'object':\n",
        "            df['tm'] = pd.to_datetime(df['tm'])\n",
        "        else:\n",
        "            df['tm'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')\n",
        "        \n",
        "        df['year'] = df['tm'].dt.year\n",
        "        df['month'] = df['tm'].dt.month\n",
        "        df['day'] = df['tm'].dt.day\n",
        "        df['hour'] = df['tm'].dt.hour\n",
        "        df['dayofweek'] = df['tm'].dt.dayofweek\n",
        "        df['dayofyear'] = df['tm'].dt.dayofyear\n",
        "\n",
        "        # ✅ wd (풍향) 제외, 사용할 컬럼만 포함\n",
        "        missing_cols = ['ta', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand'] # 열수요도 결측치 있음\n",
        "\n",
        "        # ✅ 1단계: 결측치 플래그 생성 (NaN 변환 전에)\n",
        "        print(\"   결측치 플래그 생성 중...\")\n",
        "        for col in missing_cols:\n",
        "            if col in df.columns:\n",
        "                # -99를 결측치로 인식하여 플래그 생성\n",
        "                missing_mask = (df[col] == -99)\n",
        "                df[f'{col}_missing'] = missing_mask.astype(int)\n",
        "        \n",
        "        # ✅ 2단계: 결측치를 NaN으로 변환\n",
        "        for col in missing_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].replace(-99, np.nan)\n",
        "\n",
        "        # ✅ wd 컬럼 처리: -9.9 값을 NaN으로 변환 # SVR 보간에 활용\n",
        "        if 'wd' in df.columns:\n",
        "            df['wd'] = df['wd'].replace(-9.9, np.nan)\n",
        "            print(\"   wd (풍향) 컬럼의 -9.9 값을 NaN으로 변환됨\")\n",
        "            \n",
        "        # 일사량 야간은 0 처리\n",
        "        if 'si' in df.columns:\n",
        "            night_mask = (df['hour'] < 8) | (df['hour'] > 18)\n",
        "            df.loc[night_mask & df['si'].isna(), 'si'] = 0\n",
        "\n",
        "        df = df.sort_values(['branch_id', 'tm'])\n",
        "        \n",
        "        # ✅ 3단계: 생성된 결측치 플래그 확인\n",
        "        missing_flag_cols = [col for col in df.columns if col.endswith('_missing')]\n",
        "        print(f\"   생성된 결측치 플래그: {missing_flag_cols}\")\n",
        "        for col in missing_flag_cols:\n",
        "            missing_count = df[col].sum()\n",
        "            print(f\"     {col}: {missing_count:,}개 결측치\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    train_df = process_df_advanced(train_df)\n",
        "    test_df = process_df_advanced(test_df)\n",
        "\n",
        "    print(f\"   훈련: {train_df.shape}, 테스트: {test_df.shape}\")\n",
        "    print(f\"   기간: {train_df['tm'].min()} ~ {test_df['tm'].max()}\")\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "features"
      },
      "source": [
        "## 2-1. Feature 생성 : 시즌별 이상치 플래그 생성 (도메인 특화) _ 온도, 풍속, 강수량"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "outlier_flags"
      },
      "outputs": [],
      "source": [
        "def create_weather_outlier_flags(train_df, test_df):\n",
        "    \"\"\"시즌별 기상데이터 기반 이상치 플래그 (TRAIN 기준 적용)\"\"\"\n",
        "    print(\"시즌별 기상 이상치 플래그 생성 중 (TRAIN 기준)...\")\n",
        "    \n",
        "    # 1단계: TRAIN 데이터에서 시즌별, 지사별 임계값 계산\n",
        "    outlier_thresholds = {}\n",
        "    \n",
        "    for branch in train_df['branch_id'].unique():\n",
        "        branch_data = train_df[train_df['branch_id'] == branch]\n",
        "        outlier_thresholds[branch] = {}\n",
        "        \n",
        "        # 시즌별로 구분하여 임계값 계산\n",
        "        for season in [0, 1]:  # 0: 비난방철, 1: 난방철\n",
        "            season_data = branch_data[branch_data['heating_season'] == season]\n",
        "            \n",
        "            if len(season_data) > 10:  # 최소 데이터 요구량\n",
        "                outlier_thresholds[branch][season] = {\n",
        "                    # 🌡️ 온도: 하위 10% (극한 추위)\n",
        "                    'ta_q10': season_data['ta'].quantile(0.10),\n",
        "                    # 💨 풍속: 상위 10% (강풍)\n",
        "                    'ws_q90': season_data['ws'].quantile(0.90),\n",
        "                    # 🌧️ 일강수량: 상위 10% (폭우)\n",
        "                    'rn_day_q90': season_data['rn_day'].quantile(0.90)\n",
        "                }\n",
        "                print(f\"   지사 {branch}, {'난방철' if season else '비난방철'}: 임계값 계산 완료\")\n",
        "    \n",
        "    # 2단계: 임계값을 TRAIN과 TEST에 적용\n",
        "    def apply_weather_thresholds(df, thresholds):\n",
        "        df = df.copy()\n",
        "        # 기본값으로 초기화\n",
        "        df['cold_extreme'] = 0      # 극한 추위 (하위 10%)\n",
        "        df['strong_wind'] = 0       # 강풍 (상위 10%)\n",
        "        df['heavy_rain'] = 0        # 폭우 (상위 10%)\n",
        "        \n",
        "        for branch in df['branch_id'].unique():\n",
        "            if branch in thresholds:\n",
        "                branch_mask = df['branch_id'] == branch\n",
        "                \n",
        "                # 시즌별로 다른 임계값 적용\n",
        "                for season in [0, 1]:  # 0: 비난방철, 1: 난방철\n",
        "                    if season in thresholds[branch]:\n",
        "                        season_mask = branch_mask & (df['heating_season'] == season)\n",
        "                        season_thresholds = thresholds[branch][season]\n",
        "                        \n",
        "                        # 온도 이상치 (낮은 온도)\n",
        "                        df.loc[season_mask, 'cold_extreme'] = (\n",
        "                            df.loc[season_mask, 'ta'] < season_thresholds['ta_q10']\n",
        "                        ).astype(int)\n",
        "                        \n",
        "                        # 풍속 이상치 (높은 풍속)\n",
        "                        df.loc[season_mask, 'strong_wind'] = (\n",
        "                            df.loc[season_mask, 'ws'] > season_thresholds['ws_q90']\n",
        "                        ).astype(int)\n",
        "                        \n",
        "                        # 강수량 이상치 (많은 비)\n",
        "                        df.loc[season_mask, 'heavy_rain'] = (\n",
        "                            df.loc[season_mask, 'rn_day'] > season_thresholds['rn_day_q90']\n",
        "                        ).astype(int)\n",
        "                        \n",
        "        return df\n",
        "    \n",
        "    # TRAIN 적용\n",
        "    train_result = apply_weather_thresholds(train_df, outlier_thresholds)\n",
        "    \n",
        "    # TEST 적용\n",
        "    test_result = apply_weather_thresholds(test_df, outlier_thresholds)\n",
        "    \n",
        "    print(f\"   기상 이상치 플래그 생성 완료: {len(outlier_thresholds)}개 지사\")\n",
        "    \n",
        "    return train_result, test_result, outlier_thresholds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2-2. Feature 생성 : 시즌 고도화된 특성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "advanced_features"
      },
      "outputs": [],
      "source": [
        "def create_advanced_features(df, season_type=\"heating\"):\n",
        "    df = df.copy()\n",
        "    print(f\"{season_type} 시즌 고도화된 특성 생성 중...\")\n",
        "    \n",
        "    # 범주형 시간 변수 (문자열로 명시적 변환)\n",
        "    df['hour_cat'] = df['hour'].astype(str)\n",
        "    df['month_cat'] = df['month'].astype(str)\n",
        "    df['weekday_name'] = df['dayofweek'].map(\n",
        "        lambda x: ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'][x]\n",
        "    ).astype(str)\n",
        "    \n",
        "    # 순환 인코딩\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
        "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
        "    \n",
        "    # 시즌별 월 순환 (sin, cos 포함)\n",
        "    if season_type == \"heating\":\n",
        "        heating_months = {10:0, 11:1, 12:2, 1:3, 2:4, 3:5, 4:6}\n",
        "        df['heating_month_order'] = df['month'].map(heating_months)\n",
        "        df['heating_month_sin'] = np.sin(2 * np.pi * df['heating_month_order'] / 7)\n",
        "        df['heating_month_cos'] = np.cos(2 * np.pi * df['heating_month_order'] / 7)\n",
        "    else:\n",
        "        non_heating_months = {5:0, 6:1, 7:2, 8:3, 9:4}\n",
        "        df['non_heating_month_order'] = df['month'].map(non_heating_months)\n",
        "        df['non_heating_month_sin'] = np.sin(2 * np.pi * df['non_heating_month_order'] / 5)\n",
        "        df['non_heating_month_cos'] = np.cos(2 * np.pi * df['non_heating_month_order'] / 5)\n",
        "    \n",
        "    # 브랜치 ID (문자열로 변환)\n",
        "    df['branch_id'] = df['branch_id'].astype(str)\n",
        "    \n",
        "    # 고급 기상 범주형 변수\n",
        "    df['temp_category'] = 'Normal'\n",
        "    df.loc[df['ta'] < -10, 'temp_category'] = 'VeryCold'\n",
        "    df.loc[(df['ta'] >= -10) & (df['ta'] < 0), 'temp_category'] = 'Cold'\n",
        "    df.loc[(df['ta'] >= 0) & (df['ta'] < 10), 'temp_category'] = 'Cool'\n",
        "    df.loc[(df['ta'] >= 10) & (df['ta'] < 25), 'temp_category'] = 'Normal'\n",
        "    df.loc[df['ta'] >= 25, 'temp_category'] = 'Hot'\n",
        "    df['temp_category'] = df['temp_category'].astype(str)\n",
        "    \n",
        "    if season_type == \"heating\":\n",
        "        df['cold_warning_level'] = 'Normal'\n",
        "        df.loc[df['ta'] <= -12, 'cold_warning_level'] = 'ColdAdvisory'\n",
        "        df.loc[df['ta'] <= -15, 'cold_warning_level'] = 'ColdWarning'\n",
        "        df['cold_warning_level'] = df['cold_warning_level'].astype(str)\n",
        "    \n",
        "    df['wind_category'] = 'Weak'\n",
        "    df.loc[df['ws'] >= 5.0, 'wind_category'] = 'Moderate'\n",
        "    df.loc[df['ws'] >= 10.0, 'wind_category'] = 'Strong'\n",
        "    df['wind_category'] = df['wind_category'].astype(str)\n",
        "    \n",
        "    # 공휴일/피크시간\n",
        "    kr_holidays = holidays.KR()\n",
        "    df['is_holiday'] = df['tm'].dt.date.apply(lambda x: x in kr_holidays)\n",
        "    df['holiday_type'] = df['is_holiday'].map({False: 'Weekday', True: 'Holiday'}).astype(str)\n",
        "    \n",
        "    df['peak_time'] = 'Normal'\n",
        "    df.loc[(df['hour'] >= 0) & (df['hour'] <= 6), 'peak_time'] = 'Dawn'\n",
        "    df.loc[(df['hour'] > 6) & (df['hour'] <= 11), 'peak_time'] = 'Morning'\n",
        "    df.loc[(df['hour'] > 11) & (df['hour'] <= 18), 'peak_time'] = 'Afternoon'\n",
        "    df.loc[(df['hour'] > 18) & (df['hour'] <= 23), 'peak_time'] = 'Evening'\n",
        "    df['peak_time'] = df['peak_time'].astype(str)\n",
        "    \n",
        "    # 고급 수치형 특성\n",
        "    df['HDD18'] = np.maximum(0, 18 - df['ta'])\n",
        "    # df['HDD20'] = np.maximum(0, 20 - df['ta'])\n",
        "    \n",
        "    # apparent_temp는 난방시즌에만 생성\n",
        "    if season_type == \"heating\":\n",
        "        def calculate_apparent_temp(ta, ws):\n",
        "            winter_at = 13.12 + 0.6215 * ta - 11.37 * (ws * 3.6)**0.16 + 0.3965 * ta * (ws * 3.6)**0.16\n",
        "            return winter_at\n",
        "        \n",
        "        df['apparent_temp'] = calculate_apparent_temp(df['ta'], df['ws'])\n",
        "        df['apparent_temp'] = df['apparent_temp'].fillna(0)\n",
        "    \n",
        "    for lag in [3, 6, 24]:\n",
        "        df[f'ta_lag_{lag}h'] = df.groupby('branch_id')['ta'].shift(lag).fillna(0) # 초기 비어있는 값은 0으로 반영\n",
        "    \n",
        "    for window in [6, 12, 24]:\n",
        "        df[f'ta_ma_{window}h'] = df.groupby('branch_id')['ta'].transform(\n",
        "            lambda x: x.rolling(window, min_periods=1).mean()\n",
        "        )\n",
        "    \n",
        "    df['ta_diff_3h'] = df.groupby('branch_id')['ta'].diff(3)\n",
        "    df['ta_diff_6h'] = df.groupby('branch_id')['ta'].diff(6)\n",
        "    # diff 변수 결측치를 0으로 채우기\n",
        "    df['ta_diff_3h'] = df['ta_diff_3h'].fillna(0)\n",
        "    df['ta_diff_6h'] = df['ta_diff_6h'].fillna(0)\n",
        "    \n",
        "    daily_stats = df.groupby(['branch_id', df['tm'].dt.date]).agg({\n",
        "        'ta': ['min', 'max', 'mean']\n",
        "    }).round(2)\n",
        "    daily_stats.columns = ['daily_ta_min', 'daily_ta_max', 'daily_ta_mean']\n",
        "    daily_stats['daily_temp_range'] = daily_stats['daily_ta_max'] - daily_stats['daily_ta_min']\n",
        "    \n",
        "    df = df.merge(\n",
        "        daily_stats.reset_index(),\n",
        "        left_on=['branch_id', df['tm'].dt.date],\n",
        "        right_on=['branch_id', 'tm'],\n",
        "        how='left',\n",
        "        suffixes=('', '_daily')\n",
        "    )\n",
        "    \n",
        "    print(f\"   {season_type} 시즌 고도화된 특성 생성 완료: {df.shape[1]}개 컬럼\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2-3. 결측치 보간 (Branch별 SVR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def apply_svr_interpolation(df, is_train=True):\n",
        "    \"\"\"SVR 기반 고급 보간 함수 (폴백 없음, 실패시 에러)\"\"\"\n",
        "    print(f\"SVR 보간 적용 중 ({'TRAIN' if is_train else 'TEST'} 데이터)...\")\n",
        "    \n",
        "    df_interpolated = df.copy()\n",
        "    \n",
        "    # 보간 대상 컬럼 확장 (is_train에 따라 heat_demand 포함 여부 결정)\n",
        "    base_cols = ['ta', 'hm', 'ws', 'wd', 'rn_day', 'rn_hr1', 'si', 'ta_chi']\n",
        "    if is_train:\n",
        "        interpolation_cols = base_cols + ['heat_demand']\n",
        "    else:\n",
        "        interpolation_cols = base_cols\n",
        "    \n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    available_cols = [col for col in interpolation_cols if col in numeric_cols]\n",
        "    \n",
        "    print(f\"   보간 대상 컬럼: {available_cols}\")\n",
        "    \n",
        "    # 시간 특성 생성 (SVR용)\n",
        "    df_interpolated['hour'] = df_interpolated['tm'].dt.hour\n",
        "    df_interpolated['day_of_year'] = df_interpolated['tm'].dt.dayofyear\n",
        "    df_interpolated['month'] = df_interpolated['tm'].dt.month\n",
        "    df_interpolated['dayofweek'] = df_interpolated['tm'].dt.dayofweek\n",
        "    \n",
        "    # 브랜치별 SVR 보간\n",
        "    for branch in tqdm(df['branch_id'].unique(), desc=\"지사별 SVR 보간\"):\n",
        "        branch_mask = df_interpolated['branch_id'] == branch\n",
        "        branch_data = df_interpolated[branch_mask].copy().sort_values('tm')\n",
        "        \n",
        "        if len(branch_data) < 24:  # 최소 데이터 요구량\n",
        "            raise ValueError(f\"지사 {branch}: 데이터 부족 ({len(branch_data)}개). 최소 24개 필요.\")\n",
        "            \n",
        "        for col in available_cols:\n",
        "            if col not in branch_data.columns:\n",
        "                continue\n",
        "                \n",
        "            missing_mask = branch_data[col].isna()\n",
        "            missing_count = missing_mask.sum()\n",
        "            total_count = len(branch_data)\n",
        "            \n",
        "            if missing_count == 0:  # 결측치가 없으면 스킵\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                # 훈련용 데이터 (결측이 아닌 것들)\n",
        "                train_mask = ~missing_mask\n",
        "                \n",
        "                if train_mask.sum() < 10:  # 최소 10개 이상의 훈련 데이터 필요\n",
        "                    raise ValueError(f\"지사 {branch}, 컬럼 {col}: 훈련 데이터 부족 ({train_mask.sum()}개). 최소 10개 필요.\")\n",
        "                \n",
        "                # 특성: 시간, 연중일, 월, 요일\n",
        "                feature_cols = ['hour', 'day_of_year', 'month', 'dayofweek']\n",
        "                X_train = branch_data.loc[train_mask, feature_cols].values\n",
        "                y_train = branch_data.loc[train_mask, col].values\n",
        "                \n",
        "                # 예측할 데이터\n",
        "                X_pred = branch_data.loc[missing_mask, feature_cols].values\n",
        "                \n",
        "                if len(X_pred) == 0:\n",
        "                    continue\n",
        "                \n",
        "                # 스케일링\n",
        "                scaler_X = StandardScaler()\n",
        "                scaler_y = StandardScaler()\n",
        "                \n",
        "                X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "                y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "                \n",
        "                # SVR 모델 훈련\n",
        "                svr = SVR(kernel='rbf', C=1.0, gamma='scale', epsilon=0.1)\n",
        "                svr.fit(X_train_scaled, y_train_scaled)\n",
        "                \n",
        "                # 예측\n",
        "                X_pred_scaled = scaler_X.transform(X_pred)\n",
        "                y_pred_scaled = svr.predict(X_pred_scaled)\n",
        "                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "                \n",
        "                # 결과 할당\n",
        "                df_interpolated.loc[branch_mask & missing_mask, col] = y_pred\n",
        "                \n",
        "                print(f\"     지사 {branch}, {col}: {missing_count}개 결측치 SVR 보간 완료\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"❌ 지사 {branch}, 컬럼 {col} SVR 보간 실패:\")\n",
        "                print(f\"   에러: {str(e)}\")\n",
        "                print(f\"   결측치: {missing_count}/{total_count}개\")\n",
        "                print(f\"   훈련 데이터: {train_mask.sum() if 'train_mask' in locals() else 'N/A'}개\")\n",
        "                raise e  # ✅ 폴백 없음, 에러 발생시키고 중단\n",
        "    \n",
        "    # 최종 결측치 확인 및 처리\n",
        "    for col in available_cols:\n",
        "        if col in df_interpolated.columns:\n",
        "            remaining_nan = df_interpolated[col].isna().sum()\n",
        "            if remaining_nan > 0:\n",
        "                print(f\"⚠️ {col}: SVR 보간 후에도 {remaining_nan}개 결측치 남음\")\n",
        "                # Forward/Backward fill로 최종 처리\n",
        "                df_interpolated[col] = df_interpolated[col].ffill().bfill()\n",
        "                \n",
        "                # 여전히 결측치가 있으면 에러\n",
        "                final_nan = df_interpolated[col].isna().sum()\n",
        "                if final_nan > 0:\n",
        "                    raise ValueError(f\"{col}: 모든 보간 방법 실패, {final_nan}개 결측치 남음\")\n",
        "    \n",
        "    print(f\"   ✅ SVR 보간 완료\")\n",
        "    return df_interpolated\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "groups"
      },
      "source": [
        "## 3-1. 규모별 그룹 분할 및 CV 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. heating_season 컬럼 추가 함수\n",
        "def add_heating_season(df):\n",
        "    \"\"\"난방 시즌 컬럼 추가\"\"\"\n",
        "    df = df.copy()\n",
        "    df['heating_season'] = 0  # 기본값: 비난방\n",
        "    heating_months = [10, 11, 12, 1, 2, 3, 4]  # 10월~4월: 난방시즌\n",
        "    df.loc[df['month'].isin(heating_months), 'heating_season'] = 1\n",
        "    return df\n",
        "\n",
        "# 2. 시즌별 데이터 분할 함수\n",
        "def split_by_season_only(df):\n",
        "    \"\"\"시즌별로만 분할 (2개 그룹)\"\"\"\n",
        "    groups = {}\n",
        "    \n",
        "    for season in [0, 1]:  # 0: 비난방, 1: 난방\n",
        "        season_name = 'heating' if season == 1 else 'non_heating'\n",
        "        season_data = df[df['heating_season'] == season].copy()\n",
        "        groups[season_name] = season_data\n",
        "                \n",
        "    return groups\n",
        "\n",
        "# 3. 연도 기반 CV 분할 함수\n",
        "def create_year_based_cv_splits(df, group_name=\"\"):\n",
        "    \"\"\"연도 기반 3-Fold CV 분할 생성\"\"\"\n",
        "    print(f\"{group_name} 그룹 - 연도 기반 3-Fold CV 분할 생성...\")\n",
        "    \n",
        "    # 연도별 데이터 분포 확인\n",
        "    year_counts = df['year'].value_counts().sort_index()\n",
        "    print(f\"   연도별 데이터 분포:\")\n",
        "    for year, count in year_counts.items():\n",
        "        print(f\"     {year}년: {count:,}개\")\n",
        "    \n",
        "    # 3-Fold CV: 2021, 2022, 2023년 각각 validation으로 사용\n",
        "    cv_splits = []\n",
        "    \n",
        "    for val_year in [2021, 2022, 2023]:\n",
        "        train_mask = df['year'] != val_year\n",
        "        val_mask = df['year'] == val_year\n",
        "        \n",
        "        train_indices = df[train_mask].index.tolist()\n",
        "        val_indices = df[val_mask].index.tolist()\n",
        "        \n",
        "        cv_splits.append((train_indices, val_indices))\n",
        "        \n",
        "        print(f\"   Fold {val_year}: 훈련 {len(train_indices):,}개, 검증 {len(val_indices):,}개\")\n",
        "    \n",
        "    return cv_splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-2. 데이터셋 전처리 및 특성 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1️⃣ 기본 전처리...\n",
            "고도화된 데이터 로드 및 전처리...\n",
            "   결측치 플래그 생성 중...\n",
            "   wd (풍향) 컬럼의 -9.9 값을 NaN으로 변환됨\n",
            "   생성된 결측치 플래그: ['ta_missing', 'ws_missing', 'rn_day_missing', 'rn_hr1_missing', 'hm_missing', 'si_missing', 'ta_chi_missing', 'heat_demand_missing']\n",
            "     ta_missing: 0개 결측치\n",
            "     ws_missing: 0개 결측치\n",
            "     rn_day_missing: 0개 결측치\n",
            "     rn_hr1_missing: 0개 결측치\n",
            "     hm_missing: 0개 결측치\n",
            "     si_missing: 0개 결측치\n",
            "     ta_chi_missing: 0개 결측치\n",
            "     heat_demand_missing: 0개 결측치\n",
            "   결측치 플래그 생성 중...\n",
            "   wd (풍향) 컬럼의 -9.9 값을 NaN으로 변환됨\n",
            "   생성된 결측치 플래그: ['ta_missing', 'ws_missing', 'rn_day_missing', 'rn_hr1_missing', 'hm_missing', 'si_missing', 'ta_chi_missing', 'heat_demand_missing']\n",
            "     ta_missing: 0개 결측치\n",
            "     ws_missing: 0개 결측치\n",
            "     rn_day_missing: 0개 결측치\n",
            "     rn_hr1_missing: 0개 결측치\n",
            "     hm_missing: 0개 결측치\n",
            "     si_missing: 0개 결측치\n",
            "     ta_chi_missing: 0개 결측치\n",
            "     heat_demand_missing: 0개 결측치\n",
            "   훈련: (289997, 63), 테스트: (97147, 63)\n",
            "   기간: 2021-01-01 01:00:00 ~ 2025-01-01 00:00:00\n",
            "2️⃣ heating_season 컬럼 추가...\n",
            "3️⃣ 결측치 SVR 보간 적용...\n",
            "\n",
            "🔧 훈련 데이터 SVR 보간:\n",
            "SVR 보간 적용 중 (TRAIN 데이터)...\n",
            "   보간 대상 컬럼: ['ta', 'hm', 'ws', 'wd', 'rn_day', 'rn_hr1', 'si', 'ta_chi', 'heat_demand']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4518004e27b446a296677a20a1a0c6eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "지사별 SVR 보간:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ SVR 보간 완료\n",
            "\n",
            "🔧 테스트 데이터 SVR 보간:\n",
            "SVR 보간 적용 중 (TEST 데이터)...\n",
            "   보간 대상 컬럼: ['ta', 'hm', 'ws', 'wd', 'rn_day', 'rn_hr1', 'si', 'ta_chi']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bf0304d11d744c58e8bdccb3725dd2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "지사별 SVR 보간:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ SVR 보간 완료\n",
            "4️⃣ 이상치 플래그 생성...\n",
            "시즌별 기상 이상치 플래그 생성 중 (TRAIN 기준)...\n",
            "   지사 A, 난방철: 임계값 계산 완료\n",
            "   지사 B, 난방철: 임계값 계산 완료\n",
            "   지사 C, 난방철: 임계값 계산 완료\n",
            "   지사 D, 난방철: 임계값 계산 완료\n",
            "   지사 E, 난방철: 임계값 계산 완료\n",
            "   지사 F, 난방철: 임계값 계산 완료\n",
            "   지사 G, 난방철: 임계값 계산 완료\n",
            "   지사 H, 난방철: 임계값 계산 완료\n",
            "   지사 I, 난방철: 임계값 계산 완료\n",
            "   지사 J, 난방철: 임계값 계산 완료\n",
            "   지사 K, 난방철: 임계값 계산 완료\n",
            "   지사 L, 난방철: 임계값 계산 완료\n",
            "   지사 M, 난방철: 임계값 계산 완료\n",
            "   지사 N, 난방철: 임계값 계산 완료\n",
            "   지사 O, 난방철: 임계값 계산 완료\n",
            "   지사 P, 난방철: 임계값 계산 완료\n",
            "   지사 Q, 난방철: 임계값 계산 완료\n",
            "   지사 R, 난방철: 임계값 계산 완료\n",
            "   지사 S, 난방철: 임계값 계산 완료\n",
            "   기상 이상치 플래그 생성 완료: 19개 지사\n",
            "5️⃣ 시즌별 그룹 분할...\n",
            "6️⃣ 그룹별 고도화된 특성 생성...\n",
            "  🔥 heating 그룹 특성 생성 중...\n",
            "heating 시즌 고도화된 특성 생성 중...\n",
            "   heating 시즌 고도화된 특성 생성 완료: 68개 컬럼\n",
            "heating 시즌 고도화된 특성 생성 중...\n",
            "   heating 시즌 고도화된 특성 생성 완료: 68개 컬럼\n",
            "  ❄️ non_heating 그룹 특성 생성 중...\n",
            "non_heating 시즌 고도화된 특성 생성 중...\n",
            "   non_heating 시즌 고도화된 특성 생성 완료: 71개 컬럼\n",
            "non_heating 시즌 고도화된 특성 생성 중...\n",
            "   non_heating 시즌 고도화된 특성 생성 완료: 71개 컬럼\n",
            "\n",
            "📊 그룹별 처리 후 데이터 크기:\n",
            "   heating     : 훈련 (289997, 68), 테스트 (97147, 68)\n",
            "   non_heating : 훈련 (0, 71), 테스트 (0, 71)\n",
            "\n",
            "✅ 모든 전처리 완료!\n",
            "7️⃣ 그룹별 CV 분할 미리보기:\n",
            "heating 그룹 - 연도 기반 3-Fold CV 분할 생성...\n",
            "   연도별 데이터 분포:\n",
            "     2021년: 96,653개\n",
            "     2022년: 96,672개\n",
            "     2023년: 96,672개\n",
            "   Fold 2021: 훈련 193,344개, 검증 96,653개\n",
            "   Fold 2022: 훈련 193,325개, 검증 96,672개\n",
            "   Fold 2023: 훈련 193,325개, 검증 96,672개\n",
            "   heating: 3개 fold 생성됨\n",
            "     ✅ heating: 모든 기상변수 결측치 해결됨\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. 기본 전처리 (공통)\n",
        "print(\"1️⃣ 기본 전처리...\")\n",
        "train_df, test_df = load_and_preprocess_advanced(train_path, test_path)\n",
        "\n",
        "# 2. heating_season 컬럼 추가\n",
        "print(\"2️⃣ heating_season 컬럼 추가...\")\n",
        "train_df = add_heating_season(train_df)\n",
        "test_df = add_heating_season(test_df)\n",
        "\n",
        "# 3. ✅ 결측치 보간 먼저! (파생변수 생성 전)\n",
        "print(\"3️⃣ 결측치 SVR 보간 적용...\")\n",
        "print(\"\\n🔧 훈련 데이터 SVR 보간:\")\n",
        "train_df = apply_svr_interpolation(train_df, is_train=True)\n",
        "\n",
        "print(\"\\n🔧 테스트 데이터 SVR 보간:\")\n",
        "test_df = apply_svr_interpolation(test_df, is_train=False)\n",
        "\n",
        "# 4. 이상치 플래그 생성 (보간 후)\n",
        "print(\"4️⃣ 이상치 플래그 생성...\")\n",
        "train_df, test_df, weather_thresholds = create_weather_outlier_flags(train_df, test_df)\n",
        "\n",
        "# 5. 그룹별로 먼저 분할\n",
        "print(\"5️⃣ 시즌별 그룹 분할...\")\n",
        "train_groups = split_by_season_only(train_df)\n",
        "test_groups = split_by_season_only(test_df)\n",
        "\n",
        "# 6. 각 그룹별로 시즌에 맞는 특성 생성 (보간 완료된 데이터로)\n",
        "print(\"6️⃣ 그룹별 고도화된 특성 생성...\")\n",
        "\n",
        "# heating 그룹 특성 생성\n",
        "print(\"  🔥 heating 그룹 특성 생성 중...\")\n",
        "train_groups['heating'] = create_advanced_features(train_groups['heating'], \"heating\")\n",
        "test_groups['heating'] = create_advanced_features(test_groups['heating'], \"heating\")\n",
        "\n",
        "# non_heating 그룹 특성 생성  \n",
        "print(\"  ❄️ non_heating 그룹 특성 생성 중...\")\n",
        "train_groups['non_heating'] = create_advanced_features(train_groups['non_heating'], \"non_heating\")\n",
        "test_groups['non_heating'] = create_advanced_features(test_groups['non_heating'], \"non_heating\")\n",
        "\n",
        "print(f\"\\n📊 그룹별 처리 후 데이터 크기:\")\n",
        "for group_name in ['heating', 'non_heating']:\n",
        "    print(f\"   {group_name:12s}: 훈련 {train_groups[group_name].shape}, 테스트 {test_groups[group_name].shape}\")\n",
        "\n",
        "print(f\"\\n✅ 모든 전처리 완료!\")\n",
        "\n",
        "# 7. 그룹별 CV 분할 생성 및 결과 확인\n",
        "print(\"7️⃣ 그룹별 CV 분할 미리보기:\")\n",
        "for group_name, group_data in train_groups.items():\n",
        "    if len(group_data) > 100:\n",
        "        cv_splits = create_year_based_cv_splits(group_data, group_name)\n",
        "        print(f\"   {group_name}: {len(cv_splits)}개 fold 생성됨\")\n",
        "        \n",
        "        # 결측치 최종 확인\n",
        "        weather_cols = ['ta', 'hm', 'ws', 'rn_day', 'rn_hr1', 'si', 'ta_chi', 'apparent_temp']\n",
        "        total_missing = 0\n",
        "        for col in weather_cols:\n",
        "            if col in group_data.columns:\n",
        "                missing = group_data[col].isna().sum()\n",
        "                total_missing += missing\n",
        "                if missing > 0:\n",
        "                    print(f\"     ⚠️ {col}: {missing}개 결측치 남음\")\n",
        "        \n",
        "        if total_missing == 0:\n",
        "            print(f\"     ✅ {group_name}: 모든 기상변수 결측치 해결됨\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 전처리 데이터 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_processed_data(train_groups, test_groups, weather_thresholds):\n",
        "   \"\"\"전처리된 데이터를 저장\"\"\"\n",
        "   os.makedirs(save_dir, exist_ok=True)\n",
        "   \n",
        "   # 각 그룹별로 CSV 저장\n",
        "   for group_name in train_groups.keys():\n",
        "       train_groups[group_name].to_csv(f\"/train_{group_name}.csv\", index=False)\n",
        "       test_groups[group_name].to_csv(f\"/test_{group_name}.csv\", index=False)\n",
        "   \n",
        "   # weather_thresholds 저장\n",
        "   with open(f\"/weather_thresholds.pickle\", 'wb') as f:\n",
        "       pickle.dump(weather_thresholds, f)\n",
        "   \n",
        "   print(f\"✅ 전처리된 데이터가 폴더에 저장되었습니다.\")\n",
        "\n",
        "save_processed_data(train_groups, test_groups, weather_thresholds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ! 데이터 있을 때, 여기부터 바로 돌리면 됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 저장된 데이터를 로드했습니다.\n"
          ]
        }
      ],
      "source": [
        "def load_processed_data(save_dir=\"/Users/jisupark_1/workspace/star_track_python/PRJ_Meteo/dataset/\"):\n",
        "   \"\"\"저장된 전처리 데이터를 로드\"\"\"\n",
        "   try:\n",
        "       train_groups = {\n",
        "           'heating': pd.read_csv(f\"{save_dir}/train_heating.csv\"),\n",
        "           'non_heating': pd.read_csv(f\"{save_dir}/train_non_heating.csv\")\n",
        "       }\n",
        "       \n",
        "       test_groups = {\n",
        "           'heating': pd.read_csv(f\"{save_dir}/test_heating.csv\"),\n",
        "           'non_heating': pd.read_csv(f\"{save_dir}/test_non_heating.csv\")\n",
        "       }\n",
        "       \n",
        "       with open(f\"{save_dir}/weather_thresholds.pickle\", 'rb') as f:\n",
        "           weather_thresholds = pickle.load(f)\n",
        "       \n",
        "       print(f\"✅ 저장된 데이터를 로드했습니다.\")\n",
        "       return train_groups, test_groups, weather_thresholds\n",
        "   \n",
        "   except FileNotFoundError:\n",
        "       print(\"❌ 저장된 데이터가 없습니다.\")\n",
        "       return None, None, None\n",
        "\n",
        "# 1. 저장된 데이터 로드 시도\n",
        "train_groups, test_groups, weather_thresholds = load_processed_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7️⃣ 그룹별 CV 분할 미리보기:\n",
            "heating 그룹 - 연도 기반 3-Fold CV 분할 생성...\n",
            "   연도별 데이터 분포:\n",
            "     2021년: 96,653개\n",
            "     2022년: 96,672개\n",
            "     2023년: 96,672개\n",
            "   Fold 2021: 훈련 193,344개, 검증 96,653개\n",
            "   Fold 2022: 훈련 193,325개, 검증 96,672개\n",
            "   Fold 2023: 훈련 193,325개, 검증 96,672개\n",
            "   heating: 3개 fold 생성됨\n",
            "     ✅ heating: 모든 기상변수 결측치 해결됨\n",
            "\n",
            "non_heating 그룹 - 연도 기반 3-Fold CV 분할 생성...\n",
            "   연도별 데이터 분포:\n",
            "     2021년: 69,768개\n",
            "     2022년: 69,768개\n",
            "     2023년: 69,768개\n",
            "   Fold 2021: 훈련 139,536개, 검증 69,768개\n",
            "   Fold 2022: 훈련 139,536개, 검증 69,768개\n",
            "   Fold 2023: 훈련 139,536개, 검증 69,768개\n",
            "   non_heating: 3개 fold 생성됨\n",
            "     ✅ non_heating: 모든 기상변수 결측치 해결됨\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"7️⃣ 그룹별 CV 분할 미리보기:\")\n",
        "for group_name, group_data in train_groups.items():\n",
        "    if len(group_data) > 100:\n",
        "        cv_splits = create_year_based_cv_splits(group_data, group_name)\n",
        "        print(f\"   {group_name}: {len(cv_splits)}개 fold 생성됨\")\n",
        "        \n",
        "        # 결측치 최종 확인\n",
        "        weather_cols = [# 기본 시간 변수 추가\n",
        "            'hour', 'month', 'day',\n",
        "            # 기상 변수\n",
        "            'ta', 'hm', 'ws', 'rn_day', 'rn_hr1', 'si', 'ta_chi',  # rn_hr1, ta_chi 추가\n",
        "            # 파생 변수\n",
        "            'HDD18', 'apparent_temp',  # HDD20 제거\n",
        "            # 순환 인코딩\n",
        "            'hour_sin', 'hour_cos', 'month_sin', 'month_cos', \n",
        "            'dayofweek_sin', 'dayofweek_cos',\n",
        "            # 시계열 특성\n",
        "            'ta_lag_3h', 'ta_lag_6h', 'ta_lag_24h', \n",
        "            'ta_ma_6h', 'ta_ma_12h', 'ta_ma_24h',\n",
        "            'ta_diff_3h', 'ta_diff_6h', \n",
        "            # 일별 통계\n",
        "            'daily_ta_min', 'daily_ta_max', 'daily_ta_mean', 'daily_temp_range']\n",
        "        total_missing = 0\n",
        "        for col in weather_cols:\n",
        "            if col in group_data.columns:\n",
        "                missing = group_data[col].isna().sum()\n",
        "                total_missing += missing\n",
        "                if missing > 0:\n",
        "                    print(f\"     ⚠️ {col}: {missing}개 결측치 남음\")\n",
        "        \n",
        "        if total_missing == 0:\n",
        "            print(f\"     ✅ {group_name}: 모든 기상변수 결측치 해결됨\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_features"
      },
      "source": [
        "## 4. 모델별 피쳐 정의\n",
        "\n",
        "Prophet\n",
        "\n",
        "- 시간 변수와 기본 기상 변수 중심\n",
        "- 너무 많은 변수보다는 핵심 특성에 집중\n",
        "\n",
        "CatBoost\n",
        "\n",
        "- 범주형 변수와 플래그 변수를 최대한 활용\n",
        "- 결측치/이상치 플래그로 데이터 품질 정보 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_definition"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델별 피쳐 정의 완료:\n",
            "==================================================\n",
            "prophet_heating     : 15개 피쳐\n",
            "  basic          : 6개\n",
            "  seasonal       : 9개\n",
            "prophet_non_heating : 14개 피쳐\n",
            "  basic          : 5개\n",
            "  seasonal       : 9개\n",
            "catboost_heating    : 49개 피쳐\n",
            "  numerical      : 26개\n",
            "  categorical    : 9개\n",
            "  flags          : 10개\n",
            "  seasonal       : 4개\n",
            "catboost_non_heating: 47개 피쳐\n",
            "  numerical      : 26개\n",
            "  categorical    : 8개\n",
            "  flags          : 10개\n",
            "  seasonal       : 3개\n"
          ]
        }
      ],
      "source": [
        "def define_model_features():\n",
        "    # Prophet은 자체 시계열 분해 능력이 있음\n",
        "    prophet_features = {\n",
        "        'basic': [\n",
        "            'ta', 'hm', 'ws', 'HDD18', 'apparent_temp'\n",
        "        ],\n",
        "        'seasonal': [\n",
        "            'hour_sin', 'hour_cos', 'month_sin', 'month_cos', \n",
        "            'dayofweek_sin', 'dayofweek_cos',\n",
        "            'ta_lag_3h', 'ta_lag_6h'  # 짧은 lag만 (Prophet 자체 시계열 처리 보완) # ma, diff는 불필요 (Prophet이 자체 처리)\n",
        "        ]\n",
        "    }\n",
        "    # CatBoost: 모든 특성 활용 (범주형 + 시계열 + 플래그)\n",
        "    catboost_features = {\n",
        "        'numerical': [\n",
        "            'day', 'dayofyear',\n",
        "            # 기상 변수\n",
        "            'ta', 'hm', 'ws', 'rn_day', 'rn_hr1', 'si', 'ta_chi',\n",
        "            # 파생 변수\n",
        "            'HDD18',\n",
        "            # 순환 인코딩\n",
        "            'hour_sin', 'hour_cos', #'month_sin', 'month_cos' 제외 (중복)\n",
        "            'dayofweek_sin', 'dayofweek_cos',\n",
        "            # 모든 시계열 특성 (CatBoost는 직접 학습)\n",
        "            'ta_lag_3h', 'ta_lag_6h', 'ta_lag_24h', \n",
        "            'ta_ma_6h', 'ta_ma_12h', 'ta_ma_24h',\n",
        "            'ta_diff_3h', 'ta_diff_6h', \n",
        "            # 일별 통계\n",
        "            'daily_ta_min', 'daily_ta_max', 'daily_ta_mean', 'daily_temp_range'\n",
        "        ],\n",
        "        'categorical': [\n",
        "            'branch_id', 'hour_cat', 'month_cat', 'weekday_name', \n",
        "            'temp_category', 'wind_category', 'holiday_type', 'peak_time'\n",
        "        ],\n",
        "        'flags': [\n",
        "            # 결측치 플래그 (모든 기상 변수)\n",
        "            'ta_missing', 'ws_missing', 'rn_day_missing', \n",
        "            'rn_hr1_missing', 'hm_missing', 'si_missing', 'ta_chi_missing',\n",
        "            # 이상치 플래그 \n",
        "            'cold_extreme', 'strong_wind', 'heavy_rain'\n",
        "        ]\n",
        "    }\n",
        "     # LSTM: 핵심 특성 + 전처리된 시계열 (lag 제외)\n",
        "    lstm_features = {\n",
        "        'numerical': [\n",
        "            # 기본 시간 변수 추가\n",
        "            'day', 'dayofyear',\n",
        "            # 핵심 기상 변수\n",
        "            'ta', 'hm', 'ws', 'rn_day', 'si',\n",
        "            # 파생 변수\n",
        "            'HDD18',\n",
        "            # 순환 인코딩\n",
        "            'hour_sin', 'hour_cos', #'month_sin', 'month_cos' 제외 (중복)\n",
        "            'dayofweek_sin', 'dayofweek_cos',\n",
        "            # 핵심 이동 평균만\n",
        "            'ta_ma_6h', 'ta_ma_12h', 'ta_ma_24h',\n",
        "            # 일별 통계 (핵심만)\n",
        "            'daily_ta_mean', 'daily_temp_range' # lag, diff 제거 - LSTM sequence로 대체\n",
        "        ], \n",
        "        'categorical_encoded': ['branch_id']\n",
        "    }\n",
        "    \n",
        "    # heating 시즌별 특성 추가\n",
        "    prophet_heating = copy.deepcopy(prophet_features)\n",
        "    prophet_heating['basic'].append('apparent_temp')\n",
        "    prophet_heating['seasonal'].extend(['heating_month_order'])\n",
        "     # prophet_non_heating도 non_heating_month_order 추가\n",
        "    prophet_non_heating = copy.deepcopy(prophet_features)\n",
        "    prophet_non_heating['seasonal'].append('non_heating_month_order')\n",
        "\n",
        "    # 난방시즌용 CatBoost (한파 경보 + 시즌별 순환 추가)\n",
        "    catboost_heating = copy.deepcopy(catboost_features)\n",
        "    catboost_heating['categorical'].append('cold_warning_level')\n",
        "    catboost_heating['seasonal'] = [\n",
        "        'apparent_temp', 'heating_month_order', \n",
        "        'heating_month_sin', 'heating_month_cos'\n",
        "    ]\n",
        "    # 비난방시즌용 CatBoost (시즌별 순환 추가)\n",
        "    catboost_non_heating = copy.deepcopy(catboost_features)\n",
        "    catboost_non_heating['seasonal'] = [\n",
        "        'non_heating_month_order', 'non_heating_month_sin', 'non_heating_month_cos'\n",
        "    ]\n",
        "\n",
        "    \n",
        "    return {\n",
        "        'prophet_heating': prophet_heating,\n",
        "        'prophet_non_heating': prophet_non_heating,  # apparent_temp 없음\n",
        "        'catboost_heating': catboost_heating,\n",
        "        'catboost_non_heating': catboost_non_heating\n",
        "        # 'lstm_heating': lstm_heating,\n",
        "        # 'lstm_non_heating': lstm_non_heating\n",
        "    }\n",
        "\n",
        "model_features = define_model_features()\n",
        "\n",
        "print(\"모델별 피쳐 정의 완료:\")\n",
        "print(\"=\" * 50)\n",
        "for model_name, features in model_features.items():\n",
        "    total_features = sum(len(v) if isinstance(v, list) else 0 for v in features.values())\n",
        "    print(f\"{model_name:20s}: {total_features}개 피쳐\")\n",
        "    for feature_type, feature_list in features.items():\n",
        "        if isinstance(feature_list, list):\n",
        "            print(f\"  {feature_type:15s}: {len(feature_list)}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arima_models"
      },
      "source": [
        "## 5. 모델 클래스들 (Huber Loss 지원)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Time Series Dataset 클래스 추가\n",
        "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, sequence_length=24):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X) - self.sequence_length + 1\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.X[idx:idx+self.sequence_length],\n",
        "            self.y[idx+self.sequence_length-1]\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_classes"
      },
      "source": [
        "## 6. Prophet, CatBoost, LSTM 모델 클래스 (Optuna 최적화)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prophet 최적화 모델 클래스 정의 완료\n"
          ]
        }
      ],
      "source": [
        "class ProphetOptimizedModel:\n",
        "    def __init__(self, season_type=\"heating\"):\n",
        "        self.models = {}\n",
        "        self.best_params = {}\n",
        "        self.season_type = season_type\n",
        "        \n",
        "        \n",
        "    def optimize_hyperparameters(self, df, cv_splits, target_col='heat_demand', n_trials=30):\n",
        "        \"\"\"연도 기반 CV를 사용한 하이퍼파라미터 최적화\"\"\"\n",
        "        print(f\"Prophet Huber Loss 하이퍼파라미터 최적화 중... (trials: {n_trials})\")\n",
        "        \n",
        "        def objective(trial):\n",
        "            # 하이퍼파라미터 샘플링\n",
        "            changepoint_prior_scale = trial.suggest_float('changepoint_prior_scale', 0.001, 0.5, log=True)\n",
        "            seasonality_prior_scale = trial.suggest_float('seasonality_prior_scale', 0.1, 10, log=True)\n",
        "            holidays_prior_scale = trial.suggest_float('holidays_prior_scale', 0.1, 10, log=True)\n",
        "            seasonality_mode = trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative'])\n",
        "            \n",
        "            cv_scores = []\n",
        "            \n",
        "            # 연도 기반 3-Fold CV\n",
        "            for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "                fold_predictions = []\n",
        "                fold_targets = []\n",
        "                \n",
        "                train_fold = df.iloc[train_idx]\n",
        "                val_fold = df.iloc[val_idx]\n",
        "                \n",
        "                # 지사별 모델 훈련 및 예측\n",
        "                for branch in df['branch_id'].unique():\n",
        "                    branch_train = train_fold[train_fold['branch_id'] == branch]\n",
        "                    branch_val = val_fold[val_fold['branch_id'] == branch]\n",
        "                    \n",
        "                    if len(branch_train) < 50 or len(branch_val) == 0:\n",
        "                        continue\n",
        "                    \n",
        "                    try:\n",
        "                        # Prophet 데이터 준비 (이미 보간된 데이터 사용)\n",
        "                        prophet_df = pd.DataFrame({\n",
        "                            'ds': pd.to_datetime(branch_train['tm']),\n",
        "                            'y': branch_train[target_col]\n",
        "                        })\n",
        "                        \n",
        "                        # 시즌별 피쳐 설정 사용\n",
        "                        feature_config = model_features[f'prophet_{self.season_type}']\n",
        "                        regressors = feature_config['basic'] + feature_config['seasonal']\n",
        "                        \n",
        "                        for reg in regressors:\n",
        "                            if reg in branch_train.columns:\n",
        "                                prophet_df[reg] = branch_train[reg].values\n",
        "                        \n",
        "                        # Prophet 모델 생성 및 훈련\n",
        "                        model = Prophet(\n",
        "                            changepoint_prior_scale=changepoint_prior_scale,\n",
        "                            seasonality_prior_scale=seasonality_prior_scale,\n",
        "                            holidays_prior_scale=holidays_prior_scale,\n",
        "                            seasonality_mode=seasonality_mode,\n",
        "                            daily_seasonality=True,\n",
        "                            weekly_seasonality=True,\n",
        "                            yearly_seasonality=True\n",
        "                        )\n",
        "                        \n",
        "                        # 회귀변수 추가\n",
        "                        for reg in regressors:\n",
        "                            if reg in prophet_df.columns and reg not in ['ds', 'y']:\n",
        "                                model.add_regressor(reg)\n",
        "                        \n",
        "                        model.fit(prophet_df)\n",
        "                        \n",
        "                        # 예측 데이터 준비\n",
        "                        future_df = pd.DataFrame({\n",
        "                            'ds': pd.to_datetime(branch_val['tm'])\n",
        "                        })\n",
        "                        \n",
        "                        for reg in regressors:\n",
        "                            if reg in branch_val.columns:\n",
        "                                future_df[reg] = branch_val[reg].values\n",
        "                        \n",
        "                        # 예측 실행\n",
        "                        forecast = model.predict(future_df)\n",
        "                        predictions = np.maximum(forecast['yhat'].values, 0)\n",
        "                        \n",
        "                        actual_values = branch_val[target_col].values\n",
        "                        valid_mask = ~np.isnan(actual_values) & ~np.isnan(predictions)\n",
        "                        \n",
        "                        if valid_mask.sum() > 0:\n",
        "                            fold_predictions.extend(predictions[valid_mask])\n",
        "                            fold_targets.extend(actual_values[valid_mask])\n",
        "                    \n",
        "                    except Exception as e:\n",
        "                        print(f\"❌ 최적화 중 지사 {branch} Fold {fold+1} 실패:\")\n",
        "                        print(f\"   에러: {str(e)}\")\n",
        "                        raise e\n",
        "                \n",
        "                # Fold별 Huber Loss 계산\n",
        "                # 수정된 코드\n",
        "                if len(fold_predictions) > 10:\n",
        "                    # ✅ list를 numpy array로 변환\n",
        "                    fold_targets_array = np.array(fold_targets)\n",
        "                    fold_predictions_array = np.array(fold_predictions)\n",
        "                    \n",
        "                    huber = huber_score(fold_targets_array, fold_predictions_array, delta=1.0)\n",
        "                    cv_scores.append(huber)\n",
        "                    print(f\"   Fold {fold+1}: Huber Loss = {huber:.4f} ({len(fold_predictions)}개 예측)\")\n",
        "                else:\n",
        "                    print(f\"   Fold {fold+1}: 유효한 예측 부족 ({len(fold_predictions)}개)\")\n",
        "            \n",
        "            if len(cv_scores) == 0:\n",
        "                raise RuntimeError(\"모든 Fold에서 Prophet 최적화 실패\")\n",
        "                \n",
        "            return np.mean(cv_scores)\n",
        "        \n",
        "        # Optuna 최적화 실행\n",
        "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=SEED))\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "        \n",
        "        self.best_params = study.best_params\n",
        "        print(f\"   Prophet 최적 Huber Loss: {study.best_value:.4f}\")\n",
        "        print(f\"   최적 파라미터: {self.best_params}\")\n",
        "        return study.best_value\n",
        "\n",
        "    def fit(self, df, target_col='heat_demand'):\n",
        "        \"\"\"최적화된 파라미터로 전체 데이터 훈련\"\"\"\n",
        "        print(f\"Prophet 모델 훈련 중...\")\n",
        "        \n",
        "        branches = df['branch_id'].unique()\n",
        "        success_count = 0\n",
        "        \n",
        "        # 시즌별 피쳐 설정 사용\n",
        "        feature_config = model_features[f'prophet_{self.season_type}']\n",
        "        regressors = feature_config['basic'] + feature_config['seasonal']\n",
        "        \n",
        "        print(f\"   사용할 regressors: {regressors}\")\n",
        "\n",
        "        for branch in tqdm(branches, desc=\"Prophet 지사별 훈련\"):\n",
        "            branch_data = df[df['branch_id'] == branch].copy()\n",
        "\n",
        "            if len(branch_data) < 50:\n",
        "                print(f\"⚠️ 지사 {branch}: 데이터 부족 ({len(branch_data)}개) - 스킵\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Prophet 데이터 준비\n",
        "                prophet_df = pd.DataFrame({\n",
        "                    'ds': branch_data['tm'],\n",
        "                    'y': branch_data[target_col]\n",
        "                })\n",
        "\n",
        "                # 회귀변수 추가\n",
        "                missing_regressors = []\n",
        "                for reg in regressors:\n",
        "                    if reg in branch_data.columns:\n",
        "                        prophet_df[reg] = branch_data[reg].values\n",
        "                    else:\n",
        "                        missing_regressors.append(reg)\n",
        "                \n",
        "                if missing_regressors:\n",
        "                    print(f\"⚠️ 지사 {branch}: 누락된 regressors: {missing_regressors}\")\n",
        "\n",
        "                # 최적화된 파라미터로 모델 생성\n",
        "                model = Prophet(\n",
        "                    changepoint_prior_scale=self.best_params.get('changepoint_prior_scale', 0.05),\n",
        "                    seasonality_prior_scale=self.best_params.get('seasonality_prior_scale', 10.0),\n",
        "                    holidays_prior_scale=self.best_params.get('holidays_prior_scale', 10.0),\n",
        "                    seasonality_mode=self.best_params.get('seasonality_mode', 'multiplicative'),\n",
        "                    daily_seasonality=True,\n",
        "                    weekly_seasonality=True,\n",
        "                    yearly_seasonality=True  # ✅ 연간 계절성 활성화\n",
        "                )\n",
        "\n",
        "                # 회귀변수 추가\n",
        "                added_regressors = []\n",
        "                for reg in regressors:\n",
        "                    if reg in prophet_df.columns and reg not in ['ds', 'y']:\n",
        "                        model.add_regressor(reg)\n",
        "                        added_regressors.append(reg)\n",
        "\n",
        "                # 데이터 품질 확인\n",
        "                if prophet_df['y'].isna().sum() > 0:\n",
        "                    print(f\"⚠️ 지사 {branch}: 타겟 변수에 결측치 {prophet_df['y'].isna().sum()}개\")\n",
        "                \n",
        "                model.fit(prophet_df)\n",
        "                self.models[branch] = model\n",
        "                success_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ 지사 {branch} Prophet 훈련 실패:\")\n",
        "                print(f\"   에러: {str(e)}\")\n",
        "                print(f\"   데이터 크기: {len(branch_data)}\")\n",
        "                print(f\"   Prophet 데이터프레임 크기: {prophet_df.shape}\")\n",
        "                print(f\"   추가된 regressors: {added_regressors}\")\n",
        "                print(f\"   타겟 변수 통계:\")\n",
        "                print(f\"     평균: {prophet_df['y'].mean():.2f}\")\n",
        "                print(f\"     결측치: {prophet_df['y'].isna().sum()}개\")\n",
        "                print(f\"     최소값: {prophet_df['y'].min():.2f}\")\n",
        "                print(f\"     최대값: {prophet_df['y'].max():.2f}\")\n",
        "                \n",
        "                # 회귀변수별 결측치 확인\n",
        "                print(f\"   회귀변수 결측치 현황:\")\n",
        "                for reg in regressors:\n",
        "                    if reg in prophet_df.columns:\n",
        "                        missing = prophet_df[reg].isna().sum()\n",
        "                        print(f\"     {reg}: {missing}개\")\n",
        "                \n",
        "                raise e  # ✅ 에러 발생시키고 중단\n",
        "\n",
        "        print(f\"   {success_count}/{len(branches)}개 지사 훈련 완료\")\n",
        "        \n",
        "        if success_count == 0:\n",
        "            raise RuntimeError(\"모든 지사에서 Prophet 훈련 실패!\")\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"예측 실행\"\"\"\n",
        "        if len(self.models) == 0:\n",
        "            raise RuntimeError(\"훈련된 Prophet 모델이 없습니다!\")\n",
        "        \n",
        "        predictions = []\n",
        "        \n",
        "        # 시즌별 피쳐 설정 사용\n",
        "        feature_config = model_features[f'prophet_{self.season_type}']\n",
        "        regressors = feature_config['basic'] + feature_config['seasonal']\n",
        "        \n",
        "        for branch in df['branch_id'].unique():\n",
        "            if branch not in self.models:\n",
        "                print(f\"⚠️ 지사 {branch}: 훈련된 모델 없음, 0으로 채움\")\n",
        "                predictions.extend([0] * len(df[df['branch_id'] == branch]))\n",
        "                continue\n",
        "\n",
        "            branch_data = df[df['branch_id'] == branch].copy()\n",
        "            \n",
        "            try:\n",
        "                future_df = pd.DataFrame({'ds': branch_data['tm']})\n",
        "\n",
        "                # 회귀변수 추가\n",
        "                for reg in regressors:\n",
        "                    if reg in branch_data.columns:\n",
        "                        future_df[reg] = branch_data[reg].values\n",
        "\n",
        "                forecast = self.models[branch].predict(future_df)\n",
        "                branch_predictions = np.maximum(forecast['yhat'].values, 0)\n",
        "                predictions.extend(branch_predictions)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"❌ 지사 {branch} Prophet 예측 실패:\")\n",
        "                print(f\"   에러: {str(e)}\")\n",
        "                raise e\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "print(\"Prophet 최적화 모델 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost 최적화 모델 클래스 정의 완료\n"
          ]
        }
      ],
      "source": [
        "class CatBoostOptimizedModel:\n",
        "    def __init__(self, season_type=\"heating\"):\n",
        "        self.model = None\n",
        "        self.feature_cols = None\n",
        "        self.categorical_features = None\n",
        "        self.best_params = {}\n",
        "        self.season_type = season_type\n",
        "        \n",
        "        # 시즌별 피쳐 설정\n",
        "        feature_config = model_features[f'catboost_{season_type}']\n",
        "        self.features = feature_config\n",
        "        \n",
        "    def prepare_features(self, df):\n",
        "        \"\"\"피쳐 준비 및 전처리\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        # 모든 피쳐 수집 (seasonal 추가)\n",
        "        all_features = []\n",
        "        for ftype in ['numerical', 'categorical', 'flags', 'seasonal']:\n",
        "            if ftype in self.features:\n",
        "                all_features.extend(self.features[ftype])\n",
        "        \n",
        "        # 사용 가능한 피쳐만 선택\n",
        "        available_features = [col for col in all_features if col in df.columns]\n",
        "        missing_features = [col for col in all_features if col not in df.columns]\n",
        "        \n",
        "        if missing_features:\n",
        "            print(f\"⚠️ 누락된 피쳐 ({len(missing_features)}개): {missing_features}\")\n",
        "        \n",
        "        self.feature_cols = available_features\n",
        "        \n",
        "        # 범주형 피쳐 처리\n",
        "        categorical_features = []\n",
        "        if 'categorical' in self.features:\n",
        "            categorical_features = [col for col in self.features['categorical'] if col in df.columns]\n",
        "            \n",
        "        self.categorical_features = categorical_features\n",
        "        \n",
        "        # 범주형 변수를 문자열로 변환\n",
        "        for col in categorical_features:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].astype(str)\n",
        "        \n",
        "        print(f\"   최종 사용 피쳐: {len(self.feature_cols)}개\")\n",
        "        print(f\"   범주형 피쳐: {len(categorical_features)}개 - {categorical_features}\")\n",
        "        \n",
        "        return df[self.feature_cols], categorical_features\n",
        "    \n",
        "    # 단조성 제약 설정 함수 추가\n",
        "    def _get_monotone_constraints(self, feature_names):\n",
        "        \"\"\"난방 수요 예측에 맞는 단조성 제약 설정\"\"\"\n",
        "        constraints = []\n",
        "        \n",
        "        for feature in feature_names:\n",
        "            # ✅ 2. 단조성 제약 설정 (물리적 상식 반영)\n",
        "            if ('ta' in feature or 'apparent_temp' in feature) and 'lag' not in feature and 'diff' not in feature:  \n",
        "                # 온도, 체감온도: 온도 ↓ = 난방 수요 ↑ (음의 상관)\n",
        "                constraints.append(-1)\n",
        "            elif feature in ['HDD18']:  \n",
        "                # 난방도일: HDD ↑ = 난방 수요 ↑ (양의 상관)\n",
        "                constraints.append(1)\n",
        "            else:  \n",
        "                # 나머지는 제약 없음 (범주형 변수 cold_extreme 포함)\n",
        "                constraints.append(0)\n",
        "        \n",
        "        constrained_count = sum(1 for c in constraints if c != 0)\n",
        "        print(f\"   단조성 제약: {constrained_count}개 피쳐에 적용\")\n",
        "        return constraints\n",
        "\n",
        "    def optimize_hyperparameters(self, df, cv_splits, target_col='heat_demand', n_trials=50):\n",
        "        \"\"\"연도 기반 CV를 사용한 하이퍼파라미터 최적화\"\"\"\n",
        "        print(f\"CatBoost Huber Loss 하이퍼파라미터 최적화 중... (trials: {n_trials})\")\n",
        "        \n",
        "        # 피쳐 준비\n",
        "        X_full, categorical_features = self.prepare_features(df)\n",
        "        y_full = df[target_col].values\n",
        "        \n",
        "        print(f\"   최적화 데이터: {X_full.shape}\")\n",
        "        print(f\"   타겟 통계: 평균={y_full.mean():.2f}, 표준편차={y_full.std():.2f}\")\n",
        "        \n",
        "        def objective(trial):\n",
        "            # 하이퍼파라미터 샘플링\n",
        "            params = {\n",
        "                'iterations': trial.suggest_int('iterations', 500, 2000),\n",
        "                'depth': trial.suggest_int('depth', 4, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 20),\n",
        "                'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "                'random_seed': SEED,\n",
        "                'task_type': 'CPU',\n",
        "                'verbose': 0,\n",
        "                'loss_function': 'Huber:delta=1.0'  # CatBoost 내장 Huber Loss\n",
        "            }\n",
        "            \n",
        "            cv_scores = []\n",
        "            \n",
        "            # 연도 기반 3-Fold CV\n",
        "            for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "                try:\n",
        "                    X_train, X_val = X_full.iloc[train_idx], X_full.iloc[val_idx]\n",
        "                    y_train, y_val = y_full[train_idx], y_full[val_idx]\n",
        "                    \n",
        "                    # 데이터 크기 확인\n",
        "                    if len(X_train) < 10 or len(X_val) < 5:\n",
        "                        print(f\"     Fold {fold+1}: 데이터 부족 (train={len(X_train)}, val={len(X_val)})\")\n",
        "                        continue\n",
        "                    \n",
        "                    # CatBoost 모델 생성 및 훈련\n",
        "                    model = CatBoostRegressor(**params, cat_features=categorical_features)\n",
        "                    model.fit(X_train, y_train, verbose=0)\n",
        "                    \n",
        "                    # 예측 및 평가\n",
        "                    predictions = model.predict(X_val)\n",
        "                    predictions = np.maximum(predictions, 0)  # 음수 제거\n",
        "                    \n",
        "                    # 평가 지표 계산\n",
        "                    metrics = evaluate_predictions(y_val, predictions, delta=1.0)\n",
        "                    print(f\"     Fold {fold+1}: RMSE={metrics['rmse']:.4f}, Huber={metrics['huber']:.4f}\")\n",
        "                    \n",
        "                    cv_scores.append(metrics['huber'])  # 최적화는 Huber Loss 기준\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Fold {fold+1} CatBoost 최적화 실패:\")\n",
        "                    print(f\"   에러: {str(e)}\")\n",
        "                    print(f\"   훈련 데이터: {len(X_train) if 'X_train' in locals() else 'N/A'}\")\n",
        "                    print(f\"   검증 데이터: {len(X_val) if 'X_val' in locals() else 'N/A'}\")\n",
        "                    raise e  # ✅ 에러 발생시키고 중단\n",
        "            \n",
        "            if len(cv_scores) == 0:\n",
        "                print(f\"   ⚠️ 모든 Fold에서 CatBoost 최적화 실패\")\n",
        "                return 999.0\n",
        "                \n",
        "            return np.mean(cv_scores)\n",
        "        \n",
        "        # Optuna 최적화 실행\n",
        "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=SEED))\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "        \n",
        "        self.best_params = study.best_params\n",
        "        print(f\"   CatBoost 최적 Huber Loss: {study.best_value:.4f}\")\n",
        "        print(f\"   최적 파라미터: {self.best_params}\")\n",
        "        return study.best_value\n",
        "\n",
        "    def fit(self, df, target_col='heat_demand'):\n",
        "        \"\"\"최적화된 파라미터로 전체 데이터 훈련\"\"\"\n",
        "        print(f\"CatBoost 모델 훈련 중...\")\n",
        "        \n",
        "        # 피쳐 준비\n",
        "        X, categorical_features = self.prepare_features(df)\n",
        "        y = df[target_col].values\n",
        "        \n",
        "        # 데이터 품질 확인\n",
        "        print(f\"   훈련 데이터: {X.shape}\")\n",
        "        print(f\"   타겟 통계: 평균={y.mean():.2f}, 표준편차={y.std():.2f}, 범위=[{y.min():.2f}, {y.max():.2f}]\")\n",
        "        \n",
        "        # 결측치 확인\n",
        "        missing_info = {}\n",
        "        for col in X.columns:\n",
        "            missing_count = X[col].isna().sum()\n",
        "            if missing_count > 0:\n",
        "                missing_info[col] = missing_count\n",
        "        \n",
        "        if missing_info:\n",
        "            print(f\"   ⚠️ 피쳐별 결측치: {missing_info}\")\n",
        "            # 결측치가 있는 경우 처리\n",
        "            for col, missing_count in missing_info.items():\n",
        "                if col in categorical_features:\n",
        "                    X[col] = X[col].fillna('missing')\n",
        "                else:\n",
        "                    X[col] = X[col].fillna(X[col].median())\n",
        "            print(f\"   결측치 처리 완료\")\n",
        "\n",
        "        try:\n",
        "            # ✅ 단조성 제약 계산 ###############################################################\n",
        "            monotone_constraints = self._get_monotone_constraints(X.columns)\n",
        "            # 최적화된 파라미터로 모델 생성\n",
        "            self.model = CatBoostRegressor(\n",
        "                iterations=self.best_params.get('iterations', 1000),\n",
        "                learning_rate=self.best_params.get('learning_rate', 0.1),\n",
        "                depth=self.best_params.get('depth', 6),\n",
        "                l2_leaf_reg=self.best_params.get('l2_leaf_reg', 3),\n",
        "                border_count=self.best_params.get('border_count', 128),\n",
        "                cat_features=categorical_features,\n",
        "                random_seed=SEED,\n",
        "                verbose=False,\n",
        "                allow_writing_files=False,\n",
        "                loss_function='Huber:delta=1.0',  # Huber Loss 사용\n",
        "                # ✅ 단조성 제약 추가 적용 ###############################################################\n",
        "                monotone_constraints=monotone_constraints\n",
        "            )\n",
        "\n",
        "            # 모델 훈련\n",
        "            self.model.fit(X, y)\n",
        "            print(f\"   CatBoost 훈련 완료\")\n",
        "            \n",
        "            # 피쳐 중요도 출력 (상위 10개)\n",
        "            if hasattr(self.model, 'feature_importances_'):\n",
        "                feature_importance = dict(zip(X.columns, self.model.feature_importances_))\n",
        "                top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "                print(f\"   상위 10개 중요 피쳐:\")\n",
        "                for i, (feature, importance) in enumerate(top_features, 1):\n",
        "                    print(f\"     {i:2d}. {feature}: {importance:.3f}\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"❌ CatBoost 훈련 실패:\")\n",
        "            print(f\"   에러: {str(e)}\")\n",
        "            print(f\"   데이터 크기: {X.shape}\")\n",
        "            print(f\"   범주형 피쳐: {categorical_features}\")\n",
        "            print(f\"   파라미터: {self.best_params}\")\n",
        "            raise e  # ✅ 에러 발생시키고 중단\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"예측 실행\"\"\"\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"훈련된 CatBoost 모델이 없습니다!\")\n",
        "            \n",
        "        try:\n",
        "            # 피쳐 준비\n",
        "            X, categorical_features = self.prepare_features(df)\n",
        "            \n",
        "            # 결측치 처리 (훈련 시와 동일하게)\n",
        "            for col in X.columns:\n",
        "                if X[col].isna().sum() > 0:\n",
        "                    if col in categorical_features:\n",
        "                        X[col] = X[col].fillna('missing')\n",
        "                    else:\n",
        "                        X[col] = X[col].fillna(X[col].median())\n",
        "            \n",
        "            predictions = self.model.predict(X)\n",
        "            predictions = np.maximum(predictions, 0)  # 음수 제거\n",
        "            \n",
        "            print(f\"   CatBoost 예측 완료: {len(predictions)}개\")\n",
        "            print(f\"   예측 통계: 평균={predictions.mean():.2f}, 범위=[{predictions.min():.2f}, {predictions.max():.2f}]\")\n",
        "            \n",
        "            return predictions\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ CatBoost 예측 실패:\")\n",
        "            print(f\"   에러: {str(e)}\")\n",
        "            print(f\"   데이터 크기: {df.shape}\")\n",
        "            raise e  # ✅ 에러 발생시키고 중단\n",
        "\n",
        "print(\"CatBoost 최적화 모델 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stacking"
      },
      "source": [
        "## 7. 스태킹 앙상블 클래스 (Ridge 메타모델 최적화) v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 고도화된 스태킹 앙상블 클래스 정의 완료\n",
            "\n",
            "🎯 2개 그룹별 개별 훈련 준비 완료!\n"
          ]
        }
      ],
      "source": [
        "# from sklearn.linear_model import Ridge\n",
        "\n",
        "# class AdvancedStackingEnsemble:\n",
        "#     def __init__(self, season_type=\"heating\", group_name=\"\"):\n",
        "#         self.season_type = season_type\n",
        "#         self.group_name = group_name\n",
        "#         self.models = {\n",
        "#             'prophet': ProphetOptimizedModel(season_type),\n",
        "#             'catboost': CatBoostOptimizedModel(season_type)\n",
        "#             # 'lstm': LSTMOptimizedModel(season_type)\n",
        "#         }\n",
        "#         self.meta_model = None\n",
        "#         self.best_meta_params = {}\n",
        "#         self.individual_scores = {}\n",
        "\n",
        "#     def optimize_meta_model(self, level1_features, targets, cv_splits, n_trials=20):\n",
        "#         \"\"\"Ridge 메타모델 최적화 (연도 기반 CV)\"\"\"\n",
        "#         print(f\"Ridge 메타모델 최적화 중... (trials: {n_trials})\")\n",
        "        \n",
        "#         def objective(trial):\n",
        "#             # Ridge 파라미터 샘플링\n",
        "#             alpha = trial.suggest_float('alpha', 0.01, 100.0, log=True)\n",
        "            \n",
        "#             cv_scores = []\n",
        "            \n",
        "#             # 연도 기반 3-Fold CV\n",
        "#             for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "#                 try:\n",
        "#                     # 레벨1 피쳐에서 해당 인덱스 선택\n",
        "#                     train_meta_mask = np.isin(range(len(level1_features)), train_idx)\n",
        "#                     val_meta_mask = np.isin(range(len(level1_features)), val_idx)\n",
        "                    \n",
        "#                     X_train_meta = level1_features[train_meta_mask]\n",
        "#                     X_val_meta = level1_features[val_meta_mask]\n",
        "#                     y_train_meta = targets[train_meta_mask]\n",
        "#                     y_val_meta = targets[val_meta_mask]\n",
        "                    \n",
        "#                     if len(X_train_meta) < 5 or len(X_val_meta) < 2:\n",
        "#                         print(f\"     메타 Fold {fold+1}: 데이터 부족\")\n",
        "#                         continue\n",
        "                    \n",
        "#                     # Ridge 훈련\n",
        "#                     model = Ridge(alpha=alpha, random_state=SEED)\n",
        "#                     model.fit(X_train_meta, y_train_meta)\n",
        "                    \n",
        "#                     # 예측 및 평가\n",
        "#                     pred = model.predict(X_val_meta)\n",
        "#                     pred = np.maximum(pred, 0)  # 음수 제거\n",
        "                    \n",
        "#                     rmse = np.sqrt(mean_squared_error(y_val_meta, pred))\n",
        "#                     cv_scores.append(rmse)\n",
        "#                     print(f\"     메타 Fold {fold+1}: RMSE = {rmse:.4f}\")\n",
        "                    \n",
        "#                 except Exception as e:\n",
        "#                     print(f\"❌ 메타 Fold {fold+1} 최적화 실패:\")\n",
        "#                     print(f\"   에러: {str(e)}\")\n",
        "#                     raise e  # ✅ 에러 발생시키고 중단\n",
        "                    \n",
        "#             if len(cv_scores) == 0:\n",
        "#                 print(f\"   ⚠️ 모든 메타 Fold에서 최적화 실패\")\n",
        "#                 return 999.0\n",
        "                \n",
        "#             return np.mean(cv_scores)\n",
        "        \n",
        "#         # Optuna 최적화 실행\n",
        "#         study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=SEED))\n",
        "#         study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "        \n",
        "#         self.best_meta_params = study.best_params\n",
        "#         print(f\"   Ridge 최적 RMSE: {study.best_value:.4f}\")\n",
        "#         print(f\"   최적 파라미터: {self.best_meta_params}\")\n",
        "        \n",
        "#         return study.best_value\n",
        "\n",
        "#     def fit(self, train_df, cv_splits, target_col='heat_demand', optimize_trials=None):\n",
        "#         \"\"\"스태킹 앙상블 훈련 (연도 기반 CV 사용)\"\"\"\n",
        "#         print(f\"\\n{self.group_name} 스태킹 앙상블 훈련 시작!\")\n",
        "#         print(\"=\" * 60)\n",
        "        \n",
        "#         if len(train_df) < 100:\n",
        "#             raise RuntimeError(f\"데이터가 부족합니다 ({len(train_df)}개). 최소 100개 필요.\")\n",
        "            \n",
        "#         # 기본 trials 설정\n",
        "#         if optimize_trials is None:\n",
        "#             optimize_trials = {'prophet': 30, 'catboost': 50, 'meta': 20}\n",
        "\n",
        "#         print(f\"훈련 데이터: {len(train_df):,}개\")\n",
        "#         print(f\"연도 분포: {dict(train_df['year'].value_counts().sort_index())}\")\n",
        "\n",
        "#         # 1단계: 개별 모델 하이퍼파라미터 최적화 및 훈련\n",
        "#         level1_predictions_dict = {}\n",
        "\n",
        "#         for name, model in self.models.items():\n",
        "#             print(f\"\\n{name.upper()} 최적화 및 훈련...\")\n",
        "#             try:\n",
        "#                 start_time = datetime.now()\n",
        "                \n",
        "#                 # 하이퍼파라미터 최적화 (CV 기반)\n",
        "#                 best_score = model.optimize_hyperparameters(\n",
        "#                     train_df, cv_splits, target_col, n_trials=optimize_trials[name]\n",
        "#                 )\n",
        "                \n",
        "#                 # 최적화된 파라미터로 전체 훈련 데이터에 재훈련\n",
        "#                 model.fit(train_df, target_col)\n",
        "                \n",
        "#                 # CV를 통한 레벨1 예측값 생성 (Out-of-Fold 예측)\n",
        "#                 oof_predictions = np.zeros(len(train_df))\n",
        "                \n",
        "#                 for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "#                     print(f\"   OOF Fold {fold+1} 처리 중...\")\n",
        "                    \n",
        "#                     fold_train = train_df.iloc[train_idx]\n",
        "#                     fold_val = train_df.iloc[val_idx]\n",
        "                    \n",
        "#                     # 폴드별 모델 훈련 (최적 파라미터 사용)\n",
        "#                     if name == 'prophet':\n",
        "#                         fold_model = ProphetOptimizedModel(self.season_type)\n",
        "#                         fold_model.best_params = model.best_params\n",
        "#                         fold_model.fit(fold_train, target_col)\n",
        "#                         fold_pred = fold_model.predict(fold_val)\n",
        "#                     elif name == 'catboost':\n",
        "#                         fold_model = CatBoostOptimizedModel(self.season_type)\n",
        "#                         fold_model.best_params = model.best_params\n",
        "#                         fold_model.fit(fold_train, target_col)\n",
        "#                         fold_pred = fold_model.predict(fold_val)\n",
        "#                     # else:  # lstm\n",
        "#                     #     fold_model = LSTMOptimizedModel(self.season_type)\n",
        "#                     #     fold_model.best_params = model.best_params\n",
        "#                     #     # LSTM은 CV splits를 직접 전달하지 않고 fit만 수행\n",
        "#                     #     fold_model.fit(fold_train, target_col)\n",
        "#                     #     fold_pred = fold_model.predict(fold_val)\n",
        "                    \n",
        "#                     oof_predictions[val_idx] = fold_pred\n",
        "                    \n",
        "#                     # GPU 메모리 정리 (LSTM의 경우)\n",
        "#                     if name == 'lstm' and torch.cuda.is_available():\n",
        "#                         torch.cuda.empty_cache()\n",
        "\n",
        "#                 level1_predictions_dict[name] = oof_predictions\n",
        "\n",
        "#                 # 개별 모델 성능 계산\n",
        "#                 metrics = evaluate_predictions(train_df[target_col].values, oof_predictions, delta=1.0)\n",
        "#                 mae = mean_absolute_error(train_df[target_col].values, oof_predictions)\n",
        "#                 train_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "#                 self.individual_scores[name] = {\n",
        "#                     'rmse': metrics['rmse'],\n",
        "#                     'huber': metrics['huber'], \n",
        "#                     'mae': mae, \n",
        "#                     'optuna_score': best_score,\n",
        "#                     'train_time': train_time\n",
        "#                 }\n",
        "\n",
        "#                 print(f\"   {name} 성능: RMSE={metrics['rmse']:.4f}, Huber={metrics['huber']:.4f}, MAE={mae:.4f}\")\n",
        "#                 print(f\"   Optuna 최적 점수: {best_score:.4f}\")\n",
        "#                 print(f\"   총 시간: {train_time:.1f}초\")\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 print(f\"❌ {name} 훈련 실패:\")\n",
        "#                 print(f\"   에러: {str(e)}\")\n",
        "#                 raise e  # ✅ 에러 발생시키고 중단\n",
        "\n",
        "#         # 2단계: 메타 모델 최적화 및 훈련\n",
        "#         print(f\"\\nRidge 메타 모델 최적화 및 훈련...\")\n",
        "        \n",
        "#         # 레벨1 피쳐 구성\n",
        "#         level1_features = np.column_stack(list(level1_predictions_dict.values()))\n",
        "#         targets = train_df[target_col].values\n",
        "        \n",
        "#         print(f\"   메타 모델 입력: {level1_features.shape}\")\n",
        "#         print(f\"   개별 모델 예측 통계:\")\n",
        "#         for i, (name, pred) in enumerate(level1_predictions_dict.items()):\n",
        "#             print(f\"     {name}: 평균={pred.mean():.2f}, 표준편차={pred.std():.2f}\")\n",
        "        \n",
        "#         # 메타모델 하이퍼파라미터 최적화\n",
        "#         meta_score = self.optimize_meta_model(level1_features, targets, cv_splits, optimize_trials['meta'])\n",
        "        \n",
        "#         # 최적화된 파라미터로 메타모델 훈련\n",
        "#         try:\n",
        "#             self.meta_model = Ridge(\n",
        "#                 alpha=self.best_meta_params.get('alpha', 1.0),\n",
        "#                 random_state=SEED\n",
        "#             )\n",
        "#             self.meta_model.fit(level1_features, targets)\n",
        "\n",
        "#             # 스태킹 성능 계산\n",
        "#             stacking_pred = self.meta_model.predict(level1_features)\n",
        "#             stacking_pred = np.maximum(stacking_pred, 0)  # 음수 제거\n",
        "            \n",
        "#             stacking_metrics = evaluate_predictions(targets, stacking_pred, delta=1.0)\n",
        "#             stacking_mae = mean_absolute_error(targets, stacking_pred)\n",
        "\n",
        "#             self.individual_scores['stacking'] = {\n",
        "#                 'rmse': stacking_metrics['rmse'],\n",
        "#                 'huber': stacking_metrics['huber'], \n",
        "#                 'mae': stacking_mae,\n",
        "#                 'optuna_score': meta_score\n",
        "#             }\n",
        "            \n",
        "#             print(f\"   스태킹 성능: RMSE={stacking_metrics['rmse']:.4f}, Huber={stacking_metrics['huber']:.4f}, MAE={stacking_mae:.4f}\")\n",
        "            \n",
        "#             # 메타모델 가중치 출력\n",
        "#             if hasattr(self.meta_model, 'coef_'):\n",
        "#                 model_names = list(level1_predictions_dict.keys())\n",
        "#                 print(f\"   메타모델 가중치:\")\n",
        "#                 for i, (name, coef) in enumerate(zip(model_names, self.meta_model.coef_)):\n",
        "#                     print(f\"     {name}: {coef:.4f}\")\n",
        "            \n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ 메타모델 훈련 실패:\")\n",
        "#             print(f\"   에러: {str(e)}\")\n",
        "#             raise e  # ✅ 에러 발생시키고 중단\n",
        "            \n",
        "#         print(f\"✅ {self.group_name} 스태킹 앙상블 훈련 완료!\")\n",
        "\n",
        "#     def predict(self, test_df):\n",
        "#         \"\"\"스태킹 앙상블 예측\"\"\"\n",
        "#         if self.meta_model is None:\n",
        "#             raise RuntimeError(f\"{self.group_name} 모델이 훈련되지 않았습니다!\")\n",
        "\n",
        "#         level1_predictions = {}\n",
        "\n",
        "#         # 1단계: 개별 모델 예측\n",
        "#         print(f\"   {self.group_name} 개별 모델 예측 중...\")\n",
        "#         for name, model in self.models.items():\n",
        "#             try:\n",
        "#                 level1_predictions[name] = model.predict(test_df)\n",
        "#                 pred_stats = level1_predictions[name]\n",
        "#                 print(f\"     {name}: 평균={pred_stats.mean():.2f}, 범위=[{pred_stats.min():.2f}, {pred_stats.max():.2f}]\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"❌ {name} 예측 실패:\")\n",
        "#                 print(f\"   에러: {str(e)}\")\n",
        "#                 raise e  # ✅ 에러 발생시키고 중단\n",
        "\n",
        "#         # 2단계: 메타 모델 예측\n",
        "#         try:\n",
        "#             meta_features = np.column_stack(list(level1_predictions.values()))\n",
        "#             final_pred = self.meta_model.predict(meta_features)\n",
        "#             final_pred = np.maximum(final_pred, 0)  # 음수 제거\n",
        "\n",
        "#             print(f\"   {self.group_name} 스태킹 예측 완료: 평균={final_pred.mean():.2f}, 범위=[{final_pred.min():.2f}, {final_pred.max():.2f}]\")\n",
        "            \n",
        "#             return final_pred, level1_predictions\n",
        "            \n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ {self.group_name} 메타모델 예측 실패:\")\n",
        "#             print(f\"   에러: {str(e)}\")\n",
        "#             raise e  # ✅ 에러 발생시키고 중단\n",
        "\n",
        "# print(\"✅ 고도화된 스태킹 앙상블 클래스 정의 완료\")\n",
        "\n",
        "# # 결과 저장용 딕셔너리\n",
        "# ensemble_models = {}\n",
        "# group_results = {}\n",
        "\n",
        "# print(\"\\n🎯 2개 그룹별 개별 훈련 준비 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 스태킹 앙상블 클래스 (Ridge 메타모델 최적화) v2 - 파라미터 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 최적 파라미터 적용된 스태킹 앙상블 클래스 정의 완료\n",
            "\n",
            "🎯 최적 파라미터로 2개 그룹별 개별 훈련 준비 완료!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\n# 난방 시즌 모델\\nheating_ensemble = AdvancedStackingEnsemble(season_type=\"heating\", group_name=\"난방시즌\")\\nheating_ensemble.fit(heating_train_df, heating_cv_splits, use_predefined_params=True)\\n\\n# 비난방 시즌 모델  \\nnon_heating_ensemble = AdvancedStackingEnsemble(season_type=\"non_heating\", group_name=\"비난방시즌\")\\nnon_heating_ensemble.fit(non_heating_train_df, non_heating_cv_splits, use_predefined_params=True)\\n'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "class AdvancedStackingEnsemble:\n",
        "    def __init__(self, season_type=\"heating\", group_name=\"\"):\n",
        "        self.season_type = season_type\n",
        "        self.group_name = group_name\n",
        "        self.models = {\n",
        "            'prophet': ProphetOptimizedModel(season_type),\n",
        "            'catboost': CatBoostOptimizedModel(season_type)\n",
        "            # 'lstm': LSTMOptimizedModel(season_type)\n",
        "        }\n",
        "        self.meta_model = None\n",
        "        self.best_meta_params = {}\n",
        "        self.individual_scores = {}\n",
        "        \n",
        "        # 🎯 미리 찾은 최적 파라미터들\n",
        "        self.predefined_params = self._get_predefined_params()\n",
        "\n",
        "    \n",
        "    def _get_predefined_params(self):\n",
        "        \"\"\"시즌별 최적 파라미터 반환\"\"\"\n",
        "        if self.season_type == \"heating\":\n",
        "            # 난방 시즌 최적 파라미터\n",
        "            return {\n",
        "                'prophet': {\n",
        "                    'changepoint_prior_scale': 0.0026364803038431655,\n",
        "                    'seasonality_prior_scale': 0.13066739238053282,\n",
        "                    'holidays_prior_scale': 5.3994844097874335,\n",
        "                    'seasonality_mode': 'multiplicative'\n",
        "                },\n",
        "                'catboost': {\n",
        "                    'iterations': 1678,\n",
        "                    'depth': 5,\n",
        "                    'learning_rate': 0.05748924681991978,\n",
        "                    'l2_leaf_reg': 12.255876808378806,\n",
        "                    'border_count': 42\n",
        "                },\n",
        "                'ridge': {\n",
        "                    'alpha': 63.512210106407046\n",
        "                },\n",
        "                'expected_rmse': {\n",
        "                    'ridge': 24.8784\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            # 비난방 시즌 최적 파라미터\n",
        "            return {\n",
        "                'prophet': {\n",
        "                    'changepoint_prior_scale': 0.0010695090612476649,\n",
        "                    'seasonality_prior_scale': 3.652041851774491,\n",
        "                    'holidays_prior_scale': 0.45441617690609376,\n",
        "                    'seasonality_mode': 'additive'\n",
        "                },\n",
        "                'catboost': {\n",
        "                    'iterations': 1818,\n",
        "                    'depth': 8,\n",
        "                    'learning_rate': 0.08527855281875678,\n",
        "                    'l2_leaf_reg': 14.955151393164728,\n",
        "                    'border_count': 35\n",
        "                },\n",
        "                'ridge': {\n",
        "                    'alpha': 63.512210106407046\n",
        "                },\n",
        "                'expected_rmse': {\n",
        "                    'ridge': 9.8138\n",
        "                }\n",
        "            }\n",
        "\n",
        "    def fit(self, train_df, cv_splits, target_col='heat_demand', use_predefined_params=True):\n",
        "        \"\"\"스태킹 앙상블 훈련 (최적 파라미터 사용)\"\"\"\n",
        "        print(f\"\\n{self.group_name} 스태킹 앙상블 훈련 시작! ({self.season_type} 시즌)\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        if len(train_df) < 100:\n",
        "            raise RuntimeError(f\"데이터가 부족합니다 ({len(train_df)}개). 최소 100개 필요.\")\n",
        "\n",
        "        print(f\"훈련 데이터: {len(train_df):,}개\")\n",
        "        print(f\"연도 분포: {dict(train_df['year'].value_counts().sort_index())}\")\n",
        "        \n",
        "        if use_predefined_params:\n",
        "            print(f\"🎯 {self.season_type} 시즌 최적 파라미터 사용\")\n",
        "            print(f\"   Prophet: {self.predefined_params['prophet']}\")\n",
        "            print(f\"   CatBoost: {self.predefined_params['catboost']}\")\n",
        "            print(f\"   Ridge: {self.predefined_params['ridge']}\")\n",
        "\n",
        "        # 1단계: 개별 모델 최적 파라미터 설정 및 훈련\n",
        "        level1_predictions_dict = {}\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            print(f\"\\n{name.upper()} 훈련...\")\n",
        "            try:\n",
        "                start_time = datetime.now()\n",
        "                \n",
        "                if use_predefined_params:\n",
        "                    # 🎯 미리 찾은 최적 파라미터 사용\n",
        "                    model.best_params = self.predefined_params[name].copy()\n",
        "                    print(f\"   최적 파라미터 적용: {model.best_params}\")\n",
        "                    best_score = self.predefined_params['expected_rmse'].get(name, 0.0)\n",
        "                else:\n",
        "                    # 하이퍼파라미터 최적화 (기존 방식)\n",
        "                    best_score = model.optimize_hyperparameters(\n",
        "                        train_df, cv_splits, target_col, n_trials=30\n",
        "                    )\n",
        "                \n",
        "                # 최적화된 파라미터로 전체 훈련 데이터에 재훈련\n",
        "                model.fit(train_df, target_col)\n",
        "                \n",
        "                # CV를 통한 레벨1 예측값 생성 (Out-of-Fold 예측)\n",
        "                oof_predictions = np.zeros(len(train_df))\n",
        "                \n",
        "                for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "                    print(f\"   OOF Fold {fold+1} 처리 중...\")\n",
        "                    \n",
        "                    fold_train = train_df.iloc[train_idx]\n",
        "                    fold_val = train_df.iloc[val_idx]\n",
        "                    \n",
        "                    # 폴드별 모델 훈련 (최적 파라미터 사용)\n",
        "                    if name == 'prophet':\n",
        "                        fold_model = ProphetOptimizedModel(self.season_type)\n",
        "                        fold_model.best_params = model.best_params\n",
        "                        fold_model.fit(fold_train, target_col)\n",
        "                        fold_pred = fold_model.predict(fold_val)\n",
        "                    elif name == 'catboost':\n",
        "                        fold_model = CatBoostOptimizedModel(self.season_type)\n",
        "                        fold_model.best_params = model.best_params\n",
        "                        fold_model.fit(fold_train, target_col)\n",
        "                        fold_pred = fold_model.predict(fold_val)\n",
        "                    \n",
        "                    oof_predictions[val_idx] = fold_pred\n",
        "                    \n",
        "                    # GPU 메모리 정리 (필요시)\n",
        "                    if name == 'lstm' and torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                level1_predictions_dict[name] = oof_predictions\n",
        "\n",
        "                # 개별 모델 성능 계산\n",
        "                metrics = evaluate_predictions(train_df[target_col].values, oof_predictions, delta=1.0)\n",
        "                mae = mean_absolute_error(train_df[target_col].values, oof_predictions)\n",
        "                train_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "                self.individual_scores[name] = {\n",
        "                    'rmse': metrics['rmse'],\n",
        "                    'huber': metrics['huber'], \n",
        "                    'mae': mae, \n",
        "                    'optuna_score': best_score,\n",
        "                    'train_time': train_time\n",
        "                }\n",
        "\n",
        "                print(f\"   {name} 성능: RMSE={metrics['rmse']:.4f}, Huber={metrics['huber']:.4f}, MAE={mae:.4f}\")\n",
        "                if use_predefined_params:\n",
        "                    print(f\"   예상 점수 대비: {best_score:.4f}\")\n",
        "                else:\n",
        "                    print(f\"   Optuna 최적 점수: {best_score:.4f}\")\n",
        "                print(f\"   총 시간: {train_time:.1f}초\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ {name} 훈련 실패:\")\n",
        "                print(f\"   에러: {str(e)}\")\n",
        "                raise e\n",
        "\n",
        "        # 2단계: 메타 모델 훈련\n",
        "        print(f\"\\nRidge 메타 모델 훈련...\")\n",
        "        \n",
        "        # 레벨1 피쳐 구성\n",
        "        level1_features = np.column_stack(list(level1_predictions_dict.values()))\n",
        "        targets = train_df[target_col].values\n",
        "        \n",
        "        print(f\"   메타 모델 입력: {level1_features.shape}\")\n",
        "        print(f\"   개별 모델 예측 통계:\")\n",
        "        for i, (name, pred) in enumerate(level1_predictions_dict.items()):\n",
        "            print(f\"     {name}: 평균={pred.mean():.2f}, 표준편차={pred.std():.2f}\")\n",
        "        \n",
        "        try:\n",
        "            if use_predefined_params:\n",
        "                # 🎯 미리 찾은 최적 파라미터 사용\n",
        "                self.best_meta_params = self.predefined_params['ridge'].copy()\n",
        "                meta_score = self.predefined_params['expected_rmse']['ridge']\n",
        "                print(f\"   최적 Ridge 파라미터 적용: {self.best_meta_params}\")\n",
        "                print(f\"   예상 RMSE: {meta_score:.4f}\")\n",
        "            else:\n",
        "                # 메타모델 하이퍼파라미터 최적화 (기존 방식)\n",
        "                meta_score = self.optimize_meta_model(level1_features, targets, cv_splits, 20)\n",
        "            \n",
        "            # 최적화된 파라미터로 메타모델 훈련\n",
        "            self.meta_model = Ridge(\n",
        "                alpha=self.best_meta_params.get('alpha', 1.0),\n",
        "                random_state=SEED\n",
        "            )\n",
        "            self.meta_model.fit(level1_features, targets)\n",
        "\n",
        "            # 스태킹 성능 계산\n",
        "            stacking_pred = self.meta_model.predict(level1_features)\n",
        "            stacking_pred = np.maximum(stacking_pred, 0)  # 음수 제거\n",
        "            \n",
        "            stacking_metrics = evaluate_predictions(targets, stacking_pred, delta=1.0)\n",
        "            stacking_mae = mean_absolute_error(targets, stacking_pred)\n",
        "\n",
        "            self.individual_scores['stacking'] = {\n",
        "                'rmse': stacking_metrics['rmse'],\n",
        "                'huber': stacking_metrics['huber'], \n",
        "                'mae': stacking_mae,\n",
        "                'optuna_score': meta_score\n",
        "            }\n",
        "            \n",
        "            print(f\"   스태킹 성능: RMSE={stacking_metrics['rmse']:.4f}, Huber={stacking_metrics['huber']:.4f}, MAE={stacking_mae:.4f}\")\n",
        "            \n",
        "            # 메타모델 가중치 출력\n",
        "            if hasattr(self.meta_model, 'coef_'):\n",
        "                model_names = list(level1_predictions_dict.keys())\n",
        "                print(f\"   메타모델 가중치:\")\n",
        "                for i, (name, coef) in enumerate(zip(model_names, self.meta_model.coef_)):\n",
        "                    print(f\"     {name}: {coef:.4f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 메타모델 훈련 실패:\")\n",
        "            print(f\"   에러: {str(e)}\")\n",
        "            raise e\n",
        "            \n",
        "        print(f\"✅ {self.group_name} 스태킹 앙상블 훈련 완료!\")\n",
        "\n",
        "    def optimize_meta_model(self, level1_features, targets, cv_splits, n_trials=20):\n",
        "        \"\"\"Ridge 메타모델 최적화 (기존 코드 유지 - 필요시 사용)\"\"\"\n",
        "        print(f\"Ridge 메타모델 최적화 중... (trials: {n_trials})\")\n",
        "        \n",
        "        def objective(trial):\n",
        "            alpha = trial.suggest_float('alpha', 0.01, 100.0, log=True)\n",
        "            \n",
        "            cv_scores = []\n",
        "            \n",
        "            for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "                try:\n",
        "                    train_meta_mask = np.isin(range(len(level1_features)), train_idx)\n",
        "                    val_meta_mask = np.isin(range(len(level1_features)), val_idx)\n",
        "                    \n",
        "                    X_train_meta = level1_features[train_meta_mask]\n",
        "                    X_val_meta = level1_features[val_meta_mask]\n",
        "                    y_train_meta = targets[train_meta_mask]\n",
        "                    y_val_meta = targets[val_meta_mask]\n",
        "                    \n",
        "                    if len(X_train_meta) < 5 or len(X_val_meta) < 2:\n",
        "                        print(f\"     메타 Fold {fold+1}: 데이터 부족\")\n",
        "                        continue\n",
        "                    \n",
        "                    model = Ridge(alpha=alpha, random_state=SEED)\n",
        "                    model.fit(X_train_meta, y_train_meta)\n",
        "                    \n",
        "                    pred = model.predict(X_val_meta)\n",
        "                    pred = np.maximum(pred, 0)\n",
        "                    \n",
        "                    rmse = np.sqrt(mean_squared_error(y_val_meta, pred))\n",
        "                    cv_scores.append(rmse)\n",
        "                    print(f\"     메타 Fold {fold+1}: RMSE = {rmse:.4f}\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"❌ 메타 Fold {fold+1} 최적화 실패:\")\n",
        "                    print(f\"   에러: {str(e)}\")\n",
        "                    raise e\n",
        "                    \n",
        "            if len(cv_scores) == 0:\n",
        "                print(f\"   ⚠️ 모든 메타 Fold에서 최적화 실패\")\n",
        "                return 999.0\n",
        "                \n",
        "            return np.mean(cv_scores)\n",
        "        \n",
        "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=SEED))\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "        \n",
        "        self.best_meta_params = study.best_params\n",
        "        print(f\"   Ridge 최적 RMSE: {study.best_value:.4f}\")\n",
        "        print(f\"   최적 파라미터: {self.best_meta_params}\")\n",
        "        \n",
        "        return study.best_value\n",
        "\n",
        "    def predict(self, test_df):\n",
        "        \"\"\"스태킹 앙상블 예측\"\"\"\n",
        "        if self.meta_model is None:\n",
        "            raise RuntimeError(f\"{self.group_name} 모델이 훈련되지 않았습니다!\")\n",
        "\n",
        "        level1_predictions = {}\n",
        "\n",
        "        # 1단계: 개별 모델 예측\n",
        "        print(f\"   {self.group_name} 개별 모델 예측 중...\")\n",
        "        for name, model in self.models.items():\n",
        "            try:\n",
        "                level1_predictions[name] = model.predict(test_df)\n",
        "                pred_stats = level1_predictions[name]\n",
        "                print(f\"     {name}: 평균={pred_stats.mean():.2f}, 범위=[{pred_stats.min():.2f}, {pred_stats.max():.2f}]\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ {name} 예측 실패:\")\n",
        "                print(f\"   에러: {str(e)}\")\n",
        "                raise e\n",
        "\n",
        "        # 2단계: 메타 모델 예측\n",
        "        try:\n",
        "            meta_features = np.column_stack(list(level1_predictions.values()))\n",
        "            final_pred = self.meta_model.predict(meta_features)\n",
        "            final_pred = np.maximum(final_pred, 0)  # 음수 제거\n",
        "\n",
        "            print(f\"   {self.group_name} 스태킹 예측 완료: 평균={final_pred.mean():.2f}, 범위=[{final_pred.min():.2f}, {final_pred.max():.2f}]\")\n",
        "            \n",
        "            return final_pred, level1_predictions\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ {self.group_name} 메타모델 예측 실패:\")\n",
        "            print(f\"   에러: {str(e)}\")\n",
        "            raise e\n",
        "\n",
        "print(\"✅ 최적 파라미터 적용된 스태킹 앙상블 클래스 정의 완료\")\n",
        "\n",
        "# 결과 저장용 딕셔너리\n",
        "ensemble_models = {}\n",
        "group_results = {}\n",
        "\n",
        "print(\"\\n🎯 최적 파라미터로 2개 그룹별 개별 훈련 준비 완료!\")\n",
        "\n",
        "# 사용 예시\n",
        "\"\"\"\n",
        "# 난방 시즌 모델\n",
        "heating_ensemble = AdvancedStackingEnsemble(season_type=\"heating\", group_name=\"난방시즌\")\n",
        "heating_ensemble.fit(heating_train_df, heating_cv_splits, use_predefined_params=True)\n",
        "\n",
        "# 비난방 시즌 모델  \n",
        "non_heating_ensemble = AdvancedStackingEnsemble(season_type=\"non_heating\", group_name=\"비난방시즌\")\n",
        "non_heating_ensemble.fit(non_heating_train_df, non_heating_cv_splits, use_predefined_params=True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training"
      },
      "source": [
        "## 8. 그룹별 개별 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (현재) Prophet\n",
        "\n",
        "\"전체 기준으로 하이퍼파라미터를 찾은 후, 지사별로 학습\" ✅\n",
        "\n",
        "하이퍼파라미터: 모든 지사 통합 성능으로 최적화\n",
        "모델 훈련: 찾은 파라미터로 지사별 개별 모델 생성\n",
        "\n",
        "2. 실제로는\n",
        "\n",
        "하나의 파라미터 조합을 모든 지사에 적용해서 테스트\n",
        "지사별 성능을 종합해서 그 파라미터 조합의 점수 계산\n",
        "30번 반복해서 가장 좋은 파라미터 조합 찾기\n",
        "\n",
        "3. 최종 결과\n",
        "\n",
        "전체적으로 가장 좋은 하나의 파라미터 세트 선택\n",
        "이 파라미터를 모든 지사에 동일하게 적용해서 개별 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "train_all_groups"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 시즌별 2개 그룹 훈련 시작 (연도 기반 3-Fold CV)\n",
            "\n",
            "============================================================\n",
            "🔥 HEATING 그룹 훈련\n",
            "📊 데이터 크기: 289,997개\n",
            "🏢 지사 수: 19개\n",
            "📅 연도 분포: {2021: 96653, 2022: 96672, 2023: 96672}\n",
            "🎯 타겟 통계: 평균=135.94, 표준편차=135.29\n",
            "🔄 heating CV 분할 생성 중...\n",
            "heating 그룹 - 연도 기반 3-Fold CV 분할 생성...\n",
            "   연도별 데이터 분포:\n",
            "     2021년: 96,653개\n",
            "     2022년: 96,672개\n",
            "     2023년: 96,672개\n",
            "   Fold 2021: 훈련 193,344개, 검증 96,653개\n",
            "   Fold 2022: 훈련 193,325개, 검증 96,672개\n",
            "   Fold 2023: 훈련 193,325개, 검증 96,672개\n",
            "🏗️ heating 앙상블 모델 생성 중...\n",
            "🚀 heating 훈련 시작...\n",
            "\n",
            "heating 스태킹 앙상블 훈련 시작!\n",
            "============================================================\n",
            "훈련 데이터: 289,997개\n",
            "연도 분포: {2021: 96653, 2022: 96672, 2023: 96672}\n",
            "\n",
            "PROPHET 최적화 및 훈련...\n",
            "Prophet Huber Loss 하이퍼파라미터 최적화 중... (trials: 1)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2686c049abb48de9b8c2937057477bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[W 2025-06-24 11:03:40,374] Trial 0 failed with parameters: {'changepoint_prior_scale': 0.010253509690168494, 'seasonality_prior_scale': 7.969454818643936, 'holidays_prior_scale': 2.9106359131330697, 'seasonality_mode': 'additive'} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/jisupark_1/workspace/star_track_python/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/var/folders/pt/8357krnj4tv48kdjx9mrhd3r0000gp/T/ipykernel_36917/2016375091.py\", line 68, in objective\n",
            "    model.fit(prophet_df)\n",
            "  File \"/Users/jisupark_1/workspace/star_track_python/.venv/lib/python3.10/site-packages/prophet/forecaster.py\", line 1235, in fit\n",
            "    self.params = self.stan_backend.fit(stan_init, dat, **kwargs)\n",
            "  File \"/Users/jisupark_1/workspace/star_track_python/.venv/lib/python3.10/site-packages/prophet/models.py\", line 126, in fit\n",
            "    self.stan_fit = self.model.optimize(**args)\n",
            "  File \"/Users/jisupark_1/workspace/star_track_python/.venv/lib/python3.10/site-packages/cmdstanpy/model.py\", line 644, in optimize\n",
            "    self._run_cmdstan(\n",
            "  File \"/Users/jisupark_1/workspace/star_track_python/.venv/lib/python3.10/site-packages/cmdstanpy/model.py\", line 2087, in _run_cmdstan\n",
            "    line = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "[W 2025-06-24 11:03:40,380] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🧹 GPU 메모리 정리 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# 모든 그룹 훈련 실행\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[43mtrain_all_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[19], line 60\u001b[0m, in \u001b[0;36mtrain_all_groups\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 훈련 시작...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m---> 60\u001b[0m \u001b[43mensemble_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_cv_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheat_demand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrials\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m total_time \u001b[38;5;241m=\u001b[39m (datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m.\u001b[39mtotal_seconds()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[18], line 99\u001b[0m, in \u001b[0;36mAdvancedStackingEnsemble.fit\u001b[0;34m(self, train_df, cv_splits, target_col, optimize_trials)\u001b[0m\n\u001b[1;32m     96\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# 하이퍼파라미터 최적화 (CV 기반)\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_trials\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# 최적화된 파라미터로 전체 훈련 데이터에 재훈련\u001b[39;00m\n\u001b[1;32m    104\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_df, target_col)\n",
            "Cell \u001b[0;32mIn[15], line 115\u001b[0m, in \u001b[0;36mProphetOptimizedModel.optimize_hyperparameters\u001b[0;34m(self, df, cv_splits, target_col, n_trials)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Optuna 최적화 실행\u001b[39;00m\n\u001b[1;32m    114\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mSEED))\n\u001b[0;32m--> 115\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Prophet 최적 Huber Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[15], line 68\u001b[0m, in \u001b[0;36mProphetOptimizedModel.optimize_hyperparameters.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reg \u001b[38;5;129;01min\u001b[39;00m prophet_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m reg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     66\u001b[0m         model\u001b[38;5;241m.\u001b[39madd_regressor(reg)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprophet_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# 예측 데이터 준비\u001b[39;00m\n\u001b[1;32m     71\u001b[0m future_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mto_datetime(branch_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtm\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     73\u001b[0m })\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/prophet/forecaster.py:1235\u001b[0m, in \u001b[0;36mProphet.fit\u001b[0;34m(self, df, **kwargs)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39msampling(stan_init, dat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcmc_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstan_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstan_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mstan_fit\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# If no changepoints were requested, replace delta with 0s\u001b[39;00m\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/prophet/models.py:126\u001b[0m, in \u001b[0;36mCmdStanPyBackend.fit\u001b[0;34m(self, stan_init, stan_data, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Fall back on Newton\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_fallback \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNewton\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/cmdstanpy/model.py:644\u001b[0m, in \u001b[0;36mCmdStanModel.optimize\u001b[0;34m(self, data, seed, inits, output_dir, sig_figs, save_profile, algorithm, init_alpha, tol_obj, tol_rel_obj, tol_grad, tol_rel_grad, tol_param, history_size, iter, save_iterations, require_converged, show_console, refresh, time_fmt, timeout, jacobian)\u001b[0m\n\u001b[1;32m    642\u001b[0m     dummy_chain_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    643\u001b[0m     runset \u001b[38;5;241m=\u001b[39m RunSet(args\u001b[38;5;241m=\u001b[39margs, chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, time_fmt\u001b[38;5;241m=\u001b[39mtime_fmt)\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_cmdstan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrunset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_chain_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_console\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_console\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m runset\u001b[38;5;241m.\u001b[39mraise_for_timeouts()\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runset\u001b[38;5;241m.\u001b[39m_check_retcodes():\n",
            "File \u001b[0;32m~/workspace/star_track_python/.venv/lib/python3.10/site-packages/cmdstanpy/model.py:2087\u001b[0m, in \u001b[0;36mCmdStanModel._run_cmdstan\u001b[0;34m(self, runset, idx, show_progress, show_console, progress_hook, timeout)\u001b[0m\n\u001b[1;32m   2085\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2087\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2088\u001b[0m         fd_out\u001b[38;5;241m.\u001b[39mwrite(line)\n\u001b[1;32m   2089\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # 모든 그룹 훈련 함수\n",
        "# def train_all_groups():\n",
        "#     \"\"\"2개 그룹 훈련 (난방/비난방) - 연도 기반 CV 적용\"\"\"\n",
        "#     group_configs = {\n",
        "#         \"heating\": {\n",
        "#             \"season\": \"heating\", \n",
        "#             # \"trials\": {\"prophet\": 40, \"catboost\": 60, \"meta\": 25}\n",
        "#             \"trials\": {\"prophet\": 1, \"catboost\": 1, \"meta\": 1}\n",
        "#         },\n",
        "#         \"non_heating\": {\n",
        "#             \"season\": \"non_heating\", \n",
        "#             # \"trials\": {\"prophet\": 30, \"catboost\": 50, \"meta\": 20}\n",
        "#             \"trials\": {\"prophet\": 1, \"catboost\": 1,  \"meta\": 1}\n",
        "#         }\n",
        "#     }\n",
        "    \n",
        "#     print(\"🚀 시즌별 2개 그룹 훈련 시작 (연도 기반 3-Fold CV)\")\n",
        "#     total_start_time = datetime.now()\n",
        "    \n",
        "#     for group_name, config in group_configs.items():\n",
        "#         print(f\"\\n{'='*60}\")\n",
        "#         print(f\"🔥 {group_name.upper()} 그룹 훈련\")\n",
        "        \n",
        "#         # 그룹 데이터 검증\n",
        "#         if group_name not in train_groups:\n",
        "#             raise KeyError(f\"'{group_name}' 그룹이 train_groups에 없습니다.\")\n",
        "            \n",
        "#         group_data = train_groups[group_name]\n",
        "        \n",
        "#         if len(group_data) == 0:\n",
        "#             raise ValueError(f\"{group_name} 그룹에 데이터가 없습니다.\")\n",
        "        \n",
        "#         if 'heat_demand' not in group_data.columns:\n",
        "#             raise ValueError(f\"{group_name} 그룹에 'heat_demand' 컬럼이 없습니다.\")\n",
        "        \n",
        "#         print(f\"📊 데이터 크기: {len(group_data):,}개\")\n",
        "#         print(f\"🏢 지사 수: {group_data['branch_id'].nunique()}개\")\n",
        "#         print(f\"📅 연도 분포: {dict(group_data['year'].value_counts().sort_index())}\")\n",
        "#         print(f\"🎯 타겟 통계: 평균={group_data['heat_demand'].mean():.2f}, 표준편차={group_data['heat_demand'].std():.2f}\")\n",
        "        \n",
        "#         # 최소 데이터 요구량 확인\n",
        "#         if len(group_data) < 1000:\n",
        "#             raise ValueError(f\"{group_name} 데이터가 부족합니다 ({len(group_data):,}개). 최소 1,000개 필요.\")\n",
        "        \n",
        "#         # 그룹별 CV 분할 생성\n",
        "#         print(f\"🔄 {group_name} CV 분할 생성 중...\")\n",
        "#         group_cv_splits = create_year_based_cv_splits(group_data, group_name)\n",
        "        \n",
        "#         # 앙상블 모델 생성\n",
        "#         print(f\"🏗️ {group_name} 앙상블 모델 생성 중...\")\n",
        "#         ensemble_models[group_name] = AdvancedStackingEnsemble(\n",
        "#             season_type=config[\"season\"], \n",
        "#             group_name=group_name\n",
        "#         )\n",
        "        \n",
        "#         # 훈련 실행\n",
        "#         print(f\"🚀 {group_name} 훈련 시작...\")\n",
        "#         start_time = datetime.now()\n",
        "        \n",
        "#         ensemble_models[group_name].fit(\n",
        "#             group_data, \n",
        "#             group_cv_splits,\n",
        "#             target_col='heat_demand',\n",
        "#             optimize_trials=config[\"trials\"]\n",
        "#         )\n",
        "        \n",
        "#         total_time = (datetime.now() - start_time).total_seconds()\n",
        "        \n",
        "#         # 결과 저장\n",
        "#         group_results[group_name] = {\n",
        "#             'scores': ensemble_models[group_name].individual_scores.copy(),\n",
        "#             'total_time': total_time,\n",
        "#             'data_size': len(group_data),\n",
        "#             'branch_count': group_data['branch_id'].nunique(),\n",
        "#             'year_distribution': dict(group_data['year'].value_counts().sort_index())\n",
        "#         }\n",
        "        \n",
        "#         # 성능 결과 출력 (Huber Loss 포함)\n",
        "#         print(f\"\\n📈 {group_name} 최종 결과:\")\n",
        "#         print(f\"{'모델':12s} {'RMSE':>8s} {'Huber':>8s} {'MAE':>8s} {'시간(초)':>8s}\")\n",
        "#         print(\"-\" * 50)\n",
        "        \n",
        "#         for model, scores in ensemble_models[group_name].individual_scores.items():\n",
        "#             rmse = scores.get('rmse', 999)\n",
        "#             huber = scores.get('huber', 999)\n",
        "#             mae = scores.get('mae', 999)\n",
        "#             model_time = scores.get('train_time', 0)\n",
        "            \n",
        "#             print(f\"{model:12s} {rmse:8.4f} {huber:8.4f} {mae:8.4f} {model_time:8.1f}\")\n",
        "        \n",
        "#         print(f\"   ⏱️ 총 훈련 시간: {total_time:.1f}초 ({total_time/60:.1f}분)\")\n",
        "        \n",
        "#         # 최고 성능 모델 확인\n",
        "#         best_model = min(\n",
        "#             [(name, score.get('huber', 999)) for name, score in ensemble_models[group_name].individual_scores.items()],\n",
        "#             key=lambda x: x[1]\n",
        "#         )\n",
        "#         print(f\"   🏆 최고 성능: {best_model[0]} (Huber Loss: {best_model[1]:.4f})\")\n",
        "#         print(f\"✅ {group_name} 그룹 훈련 완료!\")\n",
        "    \n",
        "#     # 전체 결과 요약\n",
        "#     total_training_time = (datetime.now() - total_start_time).total_seconds()\n",
        "    \n",
        "#     print(f\"\\n🎉 전체 훈련 완료!\")\n",
        "#     print(f\"=\" * 60)\n",
        "#     print(f\"⏱️ 총 훈련 시간: {total_training_time/60:.1f}분 ({total_training_time/3600:.1f}시간)\")\n",
        "    \n",
        "#     # 전체 평균 성능\n",
        "#     print(f\"\\n📊 전체 평균 성능:\")\n",
        "#     avg_scores = {'rmse': [], 'huber': [], 'mae': []}\n",
        "    \n",
        "#     for group_name, result in group_results.items():\n",
        "#         if result is not None and 'scores' in result:\n",
        "#             stacking_score = result['scores'].get('stacking', {})\n",
        "#             for metric in avg_scores.keys():\n",
        "#                 if metric in stacking_score:\n",
        "#                     avg_scores[metric].append(stacking_score[metric])\n",
        "    \n",
        "#     for metric, scores in avg_scores.items():\n",
        "#         if scores:\n",
        "#             print(f\"   평균 {metric.upper()}: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
        "    \n",
        "#     # GPU 메모리 정리\n",
        "#     if torch.cuda.is_available():\n",
        "#         torch.cuda.empty_cache()\n",
        "#         print(f\"🧹 GPU 메모리 정리 완료\")\n",
        "\n",
        "# # 모든 그룹 훈련 실행\n",
        "# train_all_groups()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8-2. Train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 최적 파라미터를 사용한 빠른 훈련 시작!\n",
            "🚀 시즌별 2개 그룹 훈련 시작 (연도 기반 3-Fold CV)\n",
            "🎯 미리 찾은 최적 파라미터 사용으로 빠른 훈련!\n",
            "\n",
            "============================================================\n",
            "🔥 HEATING 그룹 훈련\n",
            "📊 데이터 크기: 289,997개\n",
            "🏢 지사 수: 19개\n",
            "📅 연도 분포: {2021: 96653, 2022: 96672, 2023: 96672}\n",
            "🎯 타겟 통계: 평균=135.94, 표준편차=135.29\n",
            "🔄 heating CV 분할 생성 중...\n",
            "heating 그룹 - 연도 기반 3-Fold CV 분할 생성...\n",
            "   연도별 데이터 분포:\n",
            "     2021년: 96,653개\n",
            "     2022년: 96,672개\n",
            "     2023년: 96,672개\n",
            "   Fold 2021: 훈련 193,344개, 검증 96,653개\n",
            "   Fold 2022: 훈련 193,325개, 검증 96,672개\n",
            "   Fold 2023: 훈련 193,325개, 검증 96,672개\n",
            "🏗️ heating 앙상블 모델 생성 중...\n",
            "🚀 heating 훈련 시작...\n",
            "\n",
            "heating 스태킹 앙상블 훈련 시작! (heating 시즌)\n",
            "============================================================\n",
            "훈련 데이터: 289,997개\n",
            "연도 분포: {2021: 96653, 2022: 96672, 2023: 96672}\n",
            "🎯 heating 시즌 최적 파라미터 사용\n",
            "   Prophet: {'changepoint_prior_scale': 0.0026364803038431655, 'seasonality_prior_scale': 0.13066739238053282, 'holidays_prior_scale': 5.3994844097874335, 'seasonality_mode': 'multiplicative'}\n",
            "   CatBoost: {'iterations': 1678, 'depth': 5, 'learning_rate': 0.05748924681991978, 'l2_leaf_reg': 12.255876808378806, 'border_count': 42}\n",
            "   Ridge: {'alpha': 63.512210106407046}\n",
            "\n",
            "PROPHET 훈련...\n",
            "   최적 파라미터 적용: {'changepoint_prior_scale': 0.0026364803038431655, 'seasonality_prior_scale': 0.13066739238053282, 'holidays_prior_scale': 5.3994844097874335, 'seasonality_mode': 'multiplicative'}\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd3f8deca94c4d64a42a1916aed67833",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   19/19개 지사 훈련 완료\n",
            "   OOF Fold 1 처리 중...\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9175451fdf994a24b77fb466d174cbf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   19/19개 지사 훈련 완료\n",
            "   OOF Fold 2 처리 중...\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c46270cde8954638aade011cd887f763",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   19/19개 지사 훈련 완료\n",
            "   OOF Fold 3 처리 중...\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06f9ce1a8c434f4386d2ec67bb30bcfd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   19/19개 지사 훈련 완료\n",
            "   prophet 성능: RMSE=29.5520, Huber=18.6505, MAE=19.1402\n",
            "   예상 점수 대비: 0.0000\n",
            "   총 시간: 172.2초\n",
            "\n",
            "CATBOOST 훈련...\n",
            "   최적 파라미터 적용: {'iterations': 1678, 'depth': 5, 'learning_rate': 0.05748924681991978, 'l2_leaf_reg': 12.255876808378806, 'border_count': 42}\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   훈련 데이터: (289997, 49)\n",
            "   타겟 통계: 평균=135.94, 표준편차=135.29, 범위=[0.00, 966.00]\n",
            "   단조성 제약: 12개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. branch_id: 51.460\n",
            "      2. daily_ta_max: 14.662\n",
            "      3. heating_month_cos: 9.952\n",
            "      4. hour_cos: 6.971\n",
            "      5. ta: 3.549\n",
            "      6. ta_ma_24h: 2.600\n",
            "      7. si: 2.528\n",
            "      8. ta_lag_24h: 1.386\n",
            "      9. rn_day: 1.091\n",
            "     10. daily_ta_min: 0.944\n",
            "   OOF Fold 1 처리 중...\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   훈련 데이터: (193344, 49)\n",
            "   타겟 통계: 평균=136.92, 표준편차=135.53, 범위=[0.00, 903.00]\n",
            "   단조성 제약: 12개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. ta_lag_3h: 32.152\n",
            "      2. ws: 31.649\n",
            "      3. branch_id: 10.934\n",
            "      4. daily_temp_range: 10.707\n",
            "      5. ta_lag_24h: 7.380\n",
            "      6. daily_ta_mean: 3.562\n",
            "      7. temp_category: 0.577\n",
            "      8. daily_ta_min: 0.515\n",
            "      9. ta: 0.420\n",
            "     10. ta_ma_24h: 0.391\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   CatBoost 예측 완료: 96653개\n",
            "   예측 통계: 평균=131.00, 범위=[0.00, 778.18]\n",
            "   OOF Fold 2 처리 중...\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   훈련 데이터: (193325, 49)\n",
            "   타겟 통계: 평균=132.00, 표준편차=131.82, 범위=[0.00, 966.00]\n",
            "   단조성 제약: 12개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. branch_id: 38.867\n",
            "      2. daily_ta_mean: 26.497\n",
            "      3. day: 14.698\n",
            "      4. holiday_type: 4.647\n",
            "      5. hour_sin: 2.955\n",
            "      6. hm: 2.147\n",
            "      7. heating_month_cos: 1.775\n",
            "      8. month_cat: 1.238\n",
            "      9. ta_ma_24h: 1.140\n",
            "     10. ta: 1.126\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   CatBoost 예측 완료: 96672개\n",
            "   예측 통계: 평균=134.49, 범위=[1.63, 805.13]\n",
            "   OOF Fold 3 처리 중...\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   훈련 데이터: (193325, 49)\n",
            "   타겟 통계: 평균=138.89, 표준편차=138.37, 범위=[0.00, 966.00]\n",
            "   단조성 제약: 12개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. branch_id: 38.345\n",
            "      2. daily_ta_mean: 30.046\n",
            "      3. day: 12.920\n",
            "      4. holiday_type: 3.697\n",
            "      5. dayofyear: 3.269\n",
            "      6. hour_sin: 3.004\n",
            "      7. month_cat: 2.412\n",
            "      8. ta: 1.551\n",
            "      9. ta_lag_24h: 0.948\n",
            "     10. peak_time: 0.550\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   CatBoost 예측 완료: 96672개\n",
            "   예측 통계: 평균=133.86, 범위=[0.80, 812.86]\n",
            "   catboost 성능: RMSE=23.3722, Huber=13.9441, MAE=14.4312\n",
            "   예상 점수 대비: 0.0000\n",
            "   총 시간: 338.8초\n",
            "\n",
            "Ridge 메타 모델 훈련...\n",
            "   메타 모델 입력: (289997, 2)\n",
            "   개별 모델 예측 통계:\n",
            "     prophet: 평균=141.98, 표준편차=138.65\n",
            "     catboost: 평균=133.12, 표준편차=129.30\n",
            "   최적 Ridge 파라미터 적용: {'alpha': 63.512210106407046}\n",
            "   예상 RMSE: 24.8784\n",
            "   스태킹 성능: RMSE=22.6328, Huber=13.7256, MAE=14.2128\n",
            "   메타모델 가중치:\n",
            "     prophet: 0.1500\n",
            "     catboost: 0.8723\n",
            "✅ heating 스태킹 앙상블 훈련 완료!\n",
            "\n",
            "📈 heating 최종 결과:\n",
            "모델               RMSE    Huber      MAE    시간(초)\n",
            "--------------------------------------------------\n",
            "prophet       29.5520  18.6505  19.1402    172.2\n",
            "catboost      23.3722  13.9441  14.4312    338.8\n",
            "stacking      22.6328  13.7256  14.2128      0.0\n",
            "   ⏱️ 총 훈련 시간: 511.0초 (8.5분)\n",
            "   🏆 최고 성능: stacking (Huber Loss: 13.7256)\n",
            "✅ heating 그룹 훈련 완료!\n",
            "\n",
            "============================================================\n",
            "🔥 NON_HEATING 그룹 훈련\n",
            "📊 데이터 크기: 209,304개\n",
            "🏢 지사 수: 19개\n",
            "📅 연도 분포: {2021: 69768, 2022: 69768, 2023: 69768}\n",
            "🎯 타겟 통계: 평균=40.35, 표준편차=32.00\n",
            "🔄 non_heating CV 분할 생성 중...\n",
            "non_heating 그룹 - 연도 기반 3-Fold CV 분할 생성...\n",
            "   연도별 데이터 분포:\n",
            "     2021년: 69,768개\n",
            "     2022년: 69,768개\n",
            "     2023년: 69,768개\n",
            "   Fold 2021: 훈련 139,536개, 검증 69,768개\n",
            "   Fold 2022: 훈련 139,536개, 검증 69,768개\n",
            "   Fold 2023: 훈련 139,536개, 검증 69,768개\n",
            "🏗️ non_heating 앙상블 모델 생성 중...\n",
            "🚀 non_heating 훈련 시작...\n",
            "\n",
            "non_heating 스태킹 앙상블 훈련 시작! (non_heating 시즌)\n",
            "============================================================\n",
            "훈련 데이터: 209,304개\n",
            "연도 분포: {2021: 69768, 2022: 69768, 2023: 69768}\n",
            "🎯 non_heating 시즌 최적 파라미터 사용\n",
            "   Prophet: {'changepoint_prior_scale': 0.0010695090612476649, 'seasonality_prior_scale': 3.652041851774491, 'holidays_prior_scale': 0.45441617690609376, 'seasonality_mode': 'additive'}\n",
            "   CatBoost: {'iterations': 1818, 'depth': 8, 'learning_rate': 0.08527855281875678, 'l2_leaf_reg': 14.955151393164728, 'border_count': 35}\n",
            "   Ridge: {'alpha': 63.512210106407046}\n",
            "\n",
            "PROPHET 훈련...\n",
            "   최적 파라미터 적용: {'changepoint_prior_scale': 0.0010695090612476649, 'seasonality_prior_scale': 3.652041851774491, 'holidays_prior_scale': 0.45441617690609376, 'seasonality_mode': 'additive'}\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'non_heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d5013834cb34a859ddf744405c3cfbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ 지사 A: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 B: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 C: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 D: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 E: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 F: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 G: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 H: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 I: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 J: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 K: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 L: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 M: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 N: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 O: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 P: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 Q: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 R: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 S: 누락된 regressors: ['apparent_temp']\n",
            "   19/19개 지사 훈련 완료\n",
            "   OOF Fold 1 처리 중...\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'non_heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e5aec32b084c9faa4c61ec42f42d1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ 지사 A: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 B: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 C: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 D: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 E: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 F: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 G: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 H: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 I: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 J: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 K: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 L: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 M: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 N: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 O: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 P: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 Q: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 R: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 S: 누락된 regressors: ['apparent_temp']\n",
            "   19/19개 지사 훈련 완료\n",
            "   OOF Fold 2 처리 중...\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'non_heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "431c316ce41345658c71f52234acb5e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ 지사 A: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 B: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 C: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 D: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 E: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 F: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 G: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 H: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 I: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 J: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 K: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 L: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 M: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 N: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 O: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 P: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 Q: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 R: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 S: 누락된 regressors: ['apparent_temp']\n",
            "   19/19개 지사 훈련 완료\n",
            "   OOF Fold 3 처리 중...\n",
            "Prophet 모델 훈련 중...\n",
            "   사용할 regressors: ['ta', 'hm', 'ws', 'HDD18', 'apparent_temp', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'ta_lag_3h', 'ta_lag_6h', 'non_heating_month_order']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62ff9b7991394364a0d939e8d4543286",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prophet 지사별 훈련:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ 지사 A: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 B: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 C: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 D: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 E: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 F: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 G: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 H: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 I: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 J: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 K: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 L: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 M: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 N: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 O: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 P: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 Q: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 R: 누락된 regressors: ['apparent_temp']\n",
            "⚠️ 지사 S: 누락된 regressors: ['apparent_temp']\n",
            "   19/19개 지사 훈련 완료\n",
            "   prophet 성능: RMSE=11.9944, Huber=7.7240, MAE=8.2030\n",
            "   예상 점수 대비: 0.0000\n",
            "   총 시간: 100.2초\n",
            "\n",
            "CATBOOST 훈련...\n",
            "   최적 파라미터 적용: {'iterations': 1818, 'depth': 8, 'learning_rate': 0.08527855281875678, 'l2_leaf_reg': 14.955151393164728, 'border_count': 35}\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   훈련 데이터: (209304, 47)\n",
            "   타겟 통계: 평균=40.35, 표준편차=32.00, 범위=[0.00, 292.00]\n",
            "   단조성 제약: 11개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. branch_id: 21.790\n",
            "      2. day: 21.281\n",
            "      3. ta_diff_6h: 19.691\n",
            "      4. ta_lag_3h: 10.360\n",
            "      5. hm: 9.716\n",
            "      6. hour_sin: 5.632\n",
            "      7. non_heating_month_sin: 3.217\n",
            "      8. peak_time: 2.196\n",
            "      9. hour_cat: 0.853\n",
            "     10. hour_cos: 0.787\n",
            "   OOF Fold 1 처리 중...\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   훈련 데이터: (139536, 47)\n",
            "   타겟 통계: 평균=40.89, 표준편차=31.63, 범위=[0.00, 251.00]\n",
            "   단조성 제약: 11개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. branch_id: 27.406\n",
            "      2. rn_day: 13.764\n",
            "      3. non_heating_month_order: 8.731\n",
            "      4. hour_sin: 7.062\n",
            "      5. daily_ta_min: 5.264\n",
            "      6. temp_category: 4.354\n",
            "      7. si: 4.352\n",
            "      8. peak_time: 4.238\n",
            "      9. ws: 4.174\n",
            "     10. dayofyear: 3.564\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   CatBoost 예측 완료: 69768개\n",
            "   예측 통계: 평균=39.76, 범위=[0.00, 195.08]\n",
            "   OOF Fold 2 처리 중...\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   훈련 데이터: (139536, 47)\n",
            "   타겟 통계: 평균=40.09, 표준편차=32.28, 범위=[0.00, 292.00]\n",
            "   단조성 제약: 11개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. non_heating_month_sin: 17.179\n",
            "      2. rn_hr1: 15.544\n",
            "      3. daily_ta_max: 14.273\n",
            "      4. branch_id: 10.833\n",
            "      5. hour_sin: 10.543\n",
            "      6. ws: 9.521\n",
            "      7. hour_cos: 9.321\n",
            "      8. temp_category: 2.228\n",
            "      9. dayofyear: 1.853\n",
            "     10. peak_time: 1.489\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   CatBoost 예측 완료: 69768개\n",
            "   예측 통계: 평균=38.57, 범위=[0.00, 204.16]\n",
            "   OOF Fold 3 처리 중...\n",
            "CatBoost 모델 훈련 중...\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   훈련 데이터: (139536, 47)\n",
            "   타겟 통계: 평균=40.06, 표준편차=32.07, 범위=[0.00, 292.00]\n",
            "   단조성 제약: 11개 피쳐에 적용\n",
            "   CatBoost 훈련 완료\n",
            "   상위 10개 중요 피쳐:\n",
            "      1. branch_id: 23.211\n",
            "      2. rn_day: 12.385\n",
            "      3. non_heating_month_order: 7.984\n",
            "      4. temp_category: 7.548\n",
            "      5. hour_sin: 7.336\n",
            "      6. ws: 6.858\n",
            "      7. peak_time: 5.467\n",
            "      8. daily_ta_min: 4.930\n",
            "      9. non_heating_month_sin: 4.671\n",
            "     10. dayofyear: 2.226\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   CatBoost 예측 완료: 69768개\n",
            "   예측 통계: 평균=38.62, 범위=[0.00, 204.35]\n",
            "   catboost 성능: RMSE=10.0258, Huber=6.1526, MAE=6.6258\n",
            "   예상 점수 대비: 0.0000\n",
            "   총 시간: 377.3초\n",
            "\n",
            "Ridge 메타 모델 훈련...\n",
            "   메타 모델 입력: (209304, 2)\n",
            "   개별 모델 예측 통계:\n",
            "     prophet: 평균=41.48, 표준편차=30.42\n",
            "     catboost: 평균=38.99, 표준편차=29.11\n",
            "   최적 Ridge 파라미터 적용: {'alpha': 63.512210106407046}\n",
            "   예상 RMSE: 9.8138\n",
            "   스태킹 성능: RMSE=9.7575, Huber=6.0626, MAE=6.5357\n",
            "   메타모델 가중치:\n",
            "     prophet: 0.1600\n",
            "     catboost: 0.8847\n",
            "✅ non_heating 스태킹 앙상블 훈련 완료!\n",
            "\n",
            "📈 non_heating 최종 결과:\n",
            "모델               RMSE    Huber      MAE    시간(초)\n",
            "--------------------------------------------------\n",
            "prophet       11.9944   7.7240   8.2030    100.2\n",
            "catboost      10.0258   6.1526   6.6258    377.3\n",
            "stacking       9.7575   6.0626   6.5357      0.0\n",
            "   ⏱️ 총 훈련 시간: 477.5초 (8.0분)\n",
            "   🏆 최고 성능: stacking (Huber Loss: 6.0626)\n",
            "✅ non_heating 그룹 훈련 완료!\n",
            "\n",
            "🎉 전체 훈련 완료!\n",
            "============================================================\n",
            "⏱️ 총 훈련 시간: 16.5분 (0.3시간)\n",
            "\n",
            "📊 전체 평균 성능:\n",
            "   평균 RMSE: 16.1952 (±6.4376)\n",
            "   평균 HUBER: 9.8941 (±3.8315)\n",
            "   평균 MAE: 10.3742 (±3.8385)\n",
            "\n",
            "🎯 사용된 최적 파라미터:\n",
            "\n",
            "HEATING 시즌:\n",
            "   Prophet: {'changepoint_prior_scale': 0.0026364803038431655, 'seasonality_prior_scale': 0.13066739238053282, 'holidays_prior_scale': 5.3994844097874335, 'seasonality_mode': 'multiplicative'}\n",
            "   CatBoost: {'iterations': 1678, 'depth': 5, 'learning_rate': 0.05748924681991978, 'l2_leaf_reg': 12.255876808378806, 'border_count': 42}\n",
            "   Ridge: {'alpha': 63.512210106407046}\n",
            "\n",
            "NON_HEATING 시즌:\n",
            "   Prophet: {'changepoint_prior_scale': 0.0010695090612476649, 'seasonality_prior_scale': 3.652041851774491, 'holidays_prior_scale': 0.45441617690609376, 'seasonality_mode': 'additive'}\n",
            "   CatBoost: {'iterations': 1818, 'depth': 8, 'learning_rate': 0.08527855281875678, 'l2_leaf_reg': 14.955151393164728, 'border_count': 35}\n",
            "   Ridge: {'alpha': 63.512210106407046}\n"
          ]
        }
      ],
      "source": [
        "# 모든 그룹 훈련 함수 (수정된 버전)\n",
        "def train_all_groups():\n",
        "    \"\"\"2개 그룹 훈련 (난방/비난방) - 연도 기반 CV 적용\"\"\"\n",
        "    group_configs = {\n",
        "        \"heating\": {\n",
        "            \"season\": \"heating\", \n",
        "            \"use_predefined\": True  # 🎯 최적 파라미터 사용\n",
        "        },\n",
        "        \"non_heating\": {\n",
        "            \"season\": \"non_heating\", \n",
        "            \"use_predefined\": True  # 🎯 최적 파라미터 사용\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    print(\"🚀 시즌별 2개 그룹 훈련 시작 (연도 기반 3-Fold CV)\")\n",
        "    print(\"🎯 미리 찾은 최적 파라미터 사용으로 빠른 훈련!\")\n",
        "    total_start_time = datetime.now()\n",
        "    \n",
        "    for group_name, config in group_configs.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"🔥 {group_name.upper()} 그룹 훈련\")\n",
        "        \n",
        "        # 그룹 데이터 검증\n",
        "        if group_name not in train_groups:\n",
        "            raise KeyError(f\"'{group_name}' 그룹이 train_groups에 없습니다.\")\n",
        "            \n",
        "        group_data = train_groups[group_name]\n",
        "        \n",
        "        if len(group_data) == 0:\n",
        "            raise ValueError(f\"{group_name} 그룹에 데이터가 없습니다.\")\n",
        "        \n",
        "        if 'heat_demand' not in group_data.columns:\n",
        "            raise ValueError(f\"{group_name} 그룹에 'heat_demand' 컬럼이 없습니다.\")\n",
        "        \n",
        "        print(f\"📊 데이터 크기: {len(group_data):,}개\")\n",
        "        print(f\"🏢 지사 수: {group_data['branch_id'].nunique()}개\")\n",
        "        print(f\"📅 연도 분포: {dict(group_data['year'].value_counts().sort_index())}\")\n",
        "        print(f\"🎯 타겟 통계: 평균={group_data['heat_demand'].mean():.2f}, 표준편차={group_data['heat_demand'].std():.2f}\")\n",
        "        \n",
        "        # 최소 데이터 요구량 확인\n",
        "        if len(group_data) < 1000:\n",
        "            raise ValueError(f\"{group_name} 데이터가 부족합니다 ({len(group_data):,}개). 최소 1,000개 필요.\")\n",
        "        \n",
        "        # 그룹별 CV 분할 생성\n",
        "        print(f\"🔄 {group_name} CV 분할 생성 중...\")\n",
        "        group_cv_splits = create_year_based_cv_splits(group_data, group_name)\n",
        "        \n",
        "        # 앙상블 모델 생성\n",
        "        print(f\"🏗️ {group_name} 앙상블 모델 생성 중...\")\n",
        "        ensemble_models[group_name] = AdvancedStackingEnsemble(\n",
        "            season_type=config[\"season\"], \n",
        "            group_name=group_name\n",
        "        )\n",
        "        \n",
        "        # 훈련 실행 (🎯 수정된 부분)\n",
        "        print(f\"🚀 {group_name} 훈련 시작...\")\n",
        "        start_time = datetime.now()\n",
        "        \n",
        "        ensemble_models[group_name].fit(\n",
        "            group_data, \n",
        "            group_cv_splits,\n",
        "            target_col='heat_demand',\n",
        "            use_predefined_params=config[\"use_predefined\"]  # 🎯 변경됨\n",
        "        )\n",
        "        \n",
        "        total_time = (datetime.now() - start_time).total_seconds()\n",
        "        \n",
        "        # 결과 저장\n",
        "        group_results[group_name] = {\n",
        "            'scores': ensemble_models[group_name].individual_scores.copy(),\n",
        "            'total_time': total_time,\n",
        "            'data_size': len(group_data),\n",
        "            'branch_count': group_data['branch_id'].nunique(),\n",
        "            'year_distribution': dict(group_data['year'].value_counts().sort_index())\n",
        "        }\n",
        "        \n",
        "        # 성능 결과 출력 (Huber Loss 포함)\n",
        "        print(f\"\\n📈 {group_name} 최종 결과:\")\n",
        "        print(f\"{'모델':12s} {'RMSE':>8s} {'Huber':>8s} {'MAE':>8s} {'시간(초)':>8s}\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        for model, scores in ensemble_models[group_name].individual_scores.items():\n",
        "            rmse = scores.get('rmse', 999)\n",
        "            huber = scores.get('huber', 999)\n",
        "            mae = scores.get('mae', 999)\n",
        "            model_time = scores.get('train_time', 0)\n",
        "            \n",
        "            print(f\"{model:12s} {rmse:8.4f} {huber:8.4f} {mae:8.4f} {model_time:8.1f}\")\n",
        "        \n",
        "        print(f\"   ⏱️ 총 훈련 시간: {total_time:.1f}초 ({total_time/60:.1f}분)\")\n",
        "        \n",
        "        # 최고 성능 모델 확인\n",
        "        best_model = min(\n",
        "            [(name, score.get('huber', 999)) for name, score in ensemble_models[group_name].individual_scores.items()],\n",
        "            key=lambda x: x[1]\n",
        "        )\n",
        "        print(f\"   🏆 최고 성능: {best_model[0]} (Huber Loss: {best_model[1]:.4f})\")\n",
        "        print(f\"✅ {group_name} 그룹 훈련 완료!\")\n",
        "    \n",
        "    # 전체 결과 요약\n",
        "    total_training_time = (datetime.now() - total_start_time).total_seconds()\n",
        "    \n",
        "    print(f\"\\n🎉 전체 훈련 완료!\")\n",
        "    print(f\"=\" * 60)\n",
        "    print(f\"⏱️ 총 훈련 시간: {total_training_time/60:.1f}분 ({total_training_time/3600:.1f}시간)\")\n",
        "    \n",
        "    # 전체 평균 성능\n",
        "    print(f\"\\n📊 전체 평균 성능:\")\n",
        "    avg_scores = {'rmse': [], 'huber': [], 'mae': []}\n",
        "    \n",
        "    for group_name, result in group_results.items():\n",
        "        if result is not None and 'scores' in result:\n",
        "            stacking_score = result['scores'].get('stacking', {})\n",
        "            for metric in avg_scores.keys():\n",
        "                if metric in stacking_score:\n",
        "                    avg_scores[metric].append(stacking_score[metric])\n",
        "    \n",
        "    for metric, scores in avg_scores.items():\n",
        "        if scores:\n",
        "            print(f\"   평균 {metric.upper()}: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
        "    \n",
        "    # 🎯 최적 파라미터 사용 결과 요약\n",
        "    print(f\"\\n🎯 사용된 최적 파라미터:\")\n",
        "    for group_name in group_configs.keys():\n",
        "        if group_name in ensemble_models:\n",
        "            model = ensemble_models[group_name]\n",
        "            print(f\"\\n{group_name.upper()} 시즌:\")\n",
        "            print(f\"   Prophet: {model.predefined_params['prophet']}\")\n",
        "            print(f\"   CatBoost: {model.predefined_params['catboost']}\")\n",
        "            print(f\"   Ridge: {model.predefined_params['ridge']}\")\n",
        "    \n",
        "    # GPU 메모리 정리\n",
        "    if 'torch' in globals() and torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"🧹 GPU 메모리 정리 완료\")\n",
        "\n",
        "# 🚀 모든 그룹 훈련 실행\n",
        "print(\"🎯 최적 파라미터를 사용한 빠른 훈련 시작!\")\n",
        "train_all_groups()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델 저장 및 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 현재 훈련된 모델들을 저장합니다...\n",
            "💾 훈련된 모델 저장 시작...\n",
            "📁 저장 경로: ./saved_models/\n",
            "🔍 저장할 모델 확인:\n",
            "   ensemble_models: ['heating', 'non_heating']\n",
            "   group_results: ['heating', 'non_heating']\n",
            "\n",
            "💾 HEATING 모델 저장 중...\n",
            "   ✅ 앙상블 모델: ensemble_heating.pkl\n",
            "   ✅ Prophet: prophet_heating.joblib\n",
            "   ✅ CatBoost 모델: catboost_heating.cbm\n",
            "   ✅ Ridge 메타모델: ridge_heating.joblib\n",
            "   ✅ 최적 파라미터: params_heating.pkl\n",
            "\n",
            "💾 NON_HEATING 모델 저장 중...\n",
            "   ✅ 앙상블 모델: ensemble_non_heating.pkl\n",
            "   ✅ Prophet: prophet_non_heating.joblib\n",
            "   ✅ CatBoost 모델: catboost_non_heating.cbm\n",
            "   ✅ Ridge 메타모델: ridge_non_heating.joblib\n",
            "   ✅ 최적 파라미터: params_non_heating.pkl\n",
            "\n",
            "💾 성능 결과 저장 중...\n",
            "   ✅ heating 결과: results_heating.pkl\n",
            "   ✅ non_heating 결과: results_non_heating.pkl\n",
            "\n",
            "💾 전체 모델 패키지 저장 중...\n",
            "   ✅ 전체 패키지: full_model_package.pkl\n",
            "\n",
            "🎉 모델 저장 완료!\n",
            "==================================================\n",
            "📁 저장 경로: ./saved_models/\n",
            "📊 저장된 파일 수: 13개\n",
            "\n",
            "📋 저장된 파일 목록:\n",
            "   ensemble_heating.pkl             57.7MB\n",
            "   prophet_heating.joblib           58.3MB\n",
            "   catboost_heating.cbm              1.6MB\n",
            "   ridge_heating.joblib              0.0MB\n",
            "   params_heating.pkl                0.0MB\n",
            "   ensemble_non_heating.pkl         47.8MB\n",
            "   prophet_non_heating.joblib       40.5MB\n",
            "   catboost_non_heating.cbm          9.0MB\n",
            "   ridge_non_heating.joblib          0.0MB\n",
            "   params_non_heating.pkl            0.0MB\n",
            "   results_heating.pkl               0.0MB\n",
            "   results_non_heating.pkl           0.0MB\n",
            "   full_model_package.pkl          105.5MB\n",
            "\n",
            "💾 총 저장 용량: 320.4MB\n",
            "\n",
            "✅ 저장 완료! 13개 파일이 저장되었습니다.\n",
            "\n",
            "💡 나중에 모델을 로드하려면:\n",
            "   ensemble_models, group_results = load_saved_models('./saved_models/')\n"
          ]
        }
      ],
      "source": [
        "def save_trained_models(ensemble_models, group_results, model_save_path=\"./saved_models/\"):\n",
        "    \"\"\"이미 훈련된 모델들을 저장하는 함수\"\"\"\n",
        "    import os\n",
        "    import pickle\n",
        "    import joblib\n",
        "    from datetime import datetime\n",
        "    \n",
        "    print(f\"💾 훈련된 모델 저장 시작...\")\n",
        "    print(f\"📁 저장 경로: {model_save_path}\")\n",
        "    \n",
        "    # 저장 디렉토리 생성\n",
        "    os.makedirs(model_save_path, exist_ok=True)\n",
        "    \n",
        "    # 저장할 모델 확인\n",
        "    print(f\"🔍 저장할 모델 확인:\")\n",
        "    print(f\"   ensemble_models: {list(ensemble_models.keys()) if ensemble_models else '없음'}\")\n",
        "    print(f\"   group_results: {list(group_results.keys()) if group_results else '없음'}\")\n",
        "    \n",
        "    saved_files = []\n",
        "    \n",
        "    # 각 그룹별 모델 저장\n",
        "    for group_name in ensemble_models.keys():\n",
        "        print(f\"\\n💾 {group_name.upper()} 모델 저장 중...\")\n",
        "        \n",
        "        try:\n",
        "            # 1. 전체 앙상블 모델 저장 (pickle)\n",
        "            ensemble_file = os.path.join(model_save_path, f\"ensemble_{group_name}.pkl\")\n",
        "            with open(ensemble_file, 'wb') as f:\n",
        "                pickle.dump(ensemble_models[group_name], f)\n",
        "            saved_files.append(ensemble_file)\n",
        "            print(f\"   ✅ 앙상블 모델: ensemble_{group_name}.pkl\")\n",
        "            \n",
        "            # 2. 개별 모델별 저장\n",
        "            ensemble_model = ensemble_models[group_name]\n",
        "            \n",
        "            for model_name, model in ensemble_model.models.items():\n",
        "                try:\n",
        "                    if model_name == 'prophet':\n",
        "                        # Prophet 모델은 joblib로 저장\n",
        "                        prophet_file = os.path.join(model_save_path, f\"prophet_{group_name}.joblib\")\n",
        "                        joblib.dump(model, prophet_file)\n",
        "                        saved_files.append(prophet_file)\n",
        "                        print(f\"   ✅ Prophet: prophet_{group_name}.joblib\")\n",
        "                        \n",
        "                    elif model_name == 'catboost':\n",
        "                        # CatBoost 모델 저장 시도\n",
        "                        try:\n",
        "                            if hasattr(model, 'model') and model.model is not None:\n",
        "                                # CatBoost 전용 형식으로 저장\n",
        "                                catboost_file = os.path.join(model_save_path, f\"catboost_{group_name}.cbm\")\n",
        "                                model.model.save_model(catboost_file)\n",
        "                                saved_files.append(catboost_file)\n",
        "                                print(f\"   ✅ CatBoost 모델: catboost_{group_name}.cbm\")\n",
        "                            else:\n",
        "                                # 전체 객체를 joblib로 저장\n",
        "                                catboost_file = os.path.join(model_save_path, f\"catboost_{group_name}.joblib\")\n",
        "                                joblib.dump(model, catboost_file)\n",
        "                                saved_files.append(catboost_file)\n",
        "                                print(f\"   ✅ CatBoost 객체: catboost_{group_name}.joblib\")\n",
        "                        except Exception as e:\n",
        "                            # 실패시 joblib로 백업 저장\n",
        "                            catboost_file = os.path.join(model_save_path, f\"catboost_{group_name}.joblib\")\n",
        "                            joblib.dump(model, catboost_file)\n",
        "                            saved_files.append(catboost_file)\n",
        "                            print(f\"   ✅ CatBoost 백업: catboost_{group_name}.joblib\")\n",
        "                            \n",
        "                except Exception as e:\n",
        "                    print(f\"   ⚠️ {model_name} 개별 저장 실패: {str(e)[:50]}...\")\n",
        "            \n",
        "            # 3. 메타 모델 (Ridge) 저장\n",
        "            if hasattr(ensemble_model, 'meta_model') and ensemble_model.meta_model is not None:\n",
        "                ridge_file = os.path.join(model_save_path, f\"ridge_{group_name}.joblib\")\n",
        "                joblib.dump(ensemble_model.meta_model, ridge_file)\n",
        "                saved_files.append(ridge_file)\n",
        "                print(f\"   ✅ Ridge 메타모델: ridge_{group_name}.joblib\")\n",
        "            \n",
        "            # 4. 최적 파라미터 저장\n",
        "            if hasattr(ensemble_model, 'predefined_params'):\n",
        "                params_file = os.path.join(model_save_path, f\"params_{group_name}.pkl\")\n",
        "                with open(params_file, 'wb') as f:\n",
        "                    pickle.dump(ensemble_model.predefined_params, f)\n",
        "                saved_files.append(params_file)\n",
        "                print(f\"   ✅ 최적 파라미터: params_{group_name}.pkl\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ {group_name} 모델 저장 실패: {str(e)}\")\n",
        "    \n",
        "    # 5. 성능 결과 저장\n",
        "    if group_results:\n",
        "        print(f\"\\n💾 성능 결과 저장 중...\")\n",
        "        for group_name, result in group_results.items():\n",
        "            try:\n",
        "                results_file = os.path.join(model_save_path, f\"results_{group_name}.pkl\")\n",
        "                with open(results_file, 'wb') as f:\n",
        "                    pickle.dump(result, f)\n",
        "                saved_files.append(results_file)\n",
        "                print(f\"   ✅ {group_name} 결과: results_{group_name}.pkl\")\n",
        "            except Exception as e:\n",
        "                print(f\"   ⚠️ {group_name} 결과 저장 실패: {str(e)}\")\n",
        "    \n",
        "    # 6. 전체 모델 패키지 저장\n",
        "    try:\n",
        "        print(f\"\\n💾 전체 모델 패키지 저장 중...\")\n",
        "        \n",
        "        full_package = {\n",
        "            'ensemble_models': ensemble_models,\n",
        "            'group_results': group_results,\n",
        "            'training_info': {\n",
        "                'save_date': datetime.now().isoformat(),\n",
        "                'model_groups': list(ensemble_models.keys()),\n",
        "                'total_models': len(ensemble_models)\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        package_file = os.path.join(model_save_path, \"full_model_package.pkl\")\n",
        "        with open(package_file, 'wb') as f:\n",
        "            pickle.dump(full_package, f)\n",
        "        saved_files.append(package_file)\n",
        "        \n",
        "        print(f\"   ✅ 전체 패키지: full_model_package.pkl\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ 전체 패키지 저장 실패: {str(e)}\")\n",
        "    \n",
        "    # 저장 완료 요약\n",
        "    print(f\"\\n🎉 모델 저장 완료!\")\n",
        "    print(f\"=\" * 50)\n",
        "    print(f\"📁 저장 경로: {model_save_path}\")\n",
        "    print(f\"📊 저장된 파일 수: {len(saved_files)}개\")\n",
        "    \n",
        "    # 파일 목록과 크기 출력\n",
        "    print(f\"\\n📋 저장된 파일 목록:\")\n",
        "    total_size = 0\n",
        "    for file_path in saved_files:\n",
        "        if os.path.exists(file_path):\n",
        "            file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
        "            total_size += file_size\n",
        "            file_name = os.path.basename(file_path)\n",
        "            print(f\"   {file_name:<30} {file_size:>6.1f}MB\")\n",
        "    \n",
        "    print(f\"\\n💾 총 저장 용량: {total_size:.1f}MB\")\n",
        "    \n",
        "    return saved_files\n",
        "\n",
        "# 🚀 이미 훈련된 모델 저장 실행\n",
        "print(\"💾 현재 훈련된 모델들을 저장합니다...\")\n",
        "\n",
        "# 모델이 존재하는지 확인\n",
        "if 'ensemble_models' in globals() and ensemble_models:\n",
        "    if 'group_results' in globals() and group_results:\n",
        "        saved_files = save_trained_models(ensemble_models, group_results, \"./saved_models/\")\n",
        "        print(f\"\\n✅ 저장 완료! {len(saved_files)}개 파일이 저장되었습니다.\")\n",
        "    else:\n",
        "        print(\"⚠️ group_results가 없어서 모델만 저장합니다.\")\n",
        "        saved_files = save_trained_models(ensemble_models, {}, \"./saved_models/\")\n",
        "else:\n",
        "    print(\"❌ 저장할 훈련된 모델이 없습니다!\")\n",
        "    print(\"   먼저 train_all_groups()를 실행하여 모델을 훈련하세요.\")\n",
        "\n",
        "# 📥 로드 함수 (참고용)\n",
        "def load_saved_models(model_save_path=\"./saved_models/\"):\n",
        "    \"\"\"저장된 모델들을 로드하는 함수\"\"\"\n",
        "    import pickle\n",
        "    import os\n",
        "    \n",
        "    print(f\"📥 저장된 모델 로드 중... ({model_save_path})\")\n",
        "    \n",
        "    # 전체 패키지 로드 시도\n",
        "    package_file = os.path.join(model_save_path, \"full_model_package.pkl\")\n",
        "    if os.path.exists(package_file):\n",
        "        try:\n",
        "            with open(package_file, 'rb') as f:\n",
        "                package = pickle.load(f)\n",
        "            \n",
        "            print(\"✅ 전체 모델 패키지 로드 성공!\")\n",
        "            print(f\"   저장 일시: {package['training_info']['save_date']}\")\n",
        "            print(f\"   모델 그룹: {package['training_info']['model_groups']}\")\n",
        "            \n",
        "            return package['ensemble_models'], package['group_results']\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 전체 패키지 로드 실패: {e}\")\n",
        "    \n",
        "    print(\"❌ 저장된 모델을 찾을 수 없습니다.\")\n",
        "    return {}, {}\n",
        "\n",
        "print(f\"\\n💡 나중에 모델을 로드하려면:\")\n",
        "print(f\"   ensemble_models, group_results = load_saved_models('./saved_models/')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results"
      },
      "source": [
        "## 9. 전체 그룹 결과 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏆 전체 그룹 훈련 결과 요약\n",
            "========================================================================================================================\n",
            "그룹명                  데이터         Prophet        CatBoost        Stacking    시간(분)\n",
            "                              RMSE/Huber      RMSE/Huber      RMSE/Huber      RMSE/Huber         \n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "heating          289,997     29.55/18.65     23.37/13.94     22.63/13.73      8.5\n",
            "non_heating      209,304      11.99/7.72      10.03/6.15       9.76/6.06      8.0\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "TOTAL            499,301                                                                     16.5\n",
            "\n",
            "✅ 성공한 그룹: 2/2\n",
            "⏱️ 총 훈련 시간: 16.5분 (0.3시간)\n",
            "\n",
            "🥇 그룹별 최고 성능 모델 (Huber Loss 기준):\n",
            "   heating        : STACKING   (Huber: 13.7256)\n",
            "   non_heating    : STACKING   (Huber: 6.0626)\n",
            "\n",
            "📊 모델별 평균 성능:\n",
            "모델                평균 RMSE     평균 Huber\n",
            "----------------------------------------\n",
            "PROPHET           20.7732      13.1873\n",
            "CATBOOST          16.6990      10.0483\n",
            "STACKING          16.1952       9.8941\n",
            "\n",
            "🎯 스태킹 앙상블 개선 효과 (Huber Loss 기준):\n",
            "   heating        :  +1.57% 개선\n",
            "                     (최고 개별: 13.9441 → 스태킹: 13.7256)\n",
            "   non_heating    :  +1.46% 개선\n",
            "                     (최고 개별: 6.1526 → 스태킹: 6.0626)\n"
          ]
        }
      ],
      "source": [
        "# 전체 그룹 훈련 결과 요약\n",
        "print(\"\\n🏆 전체 그룹 훈련 결과 요약\")\n",
        "print(\"=\" * 120)\n",
        "\n",
        "total_time = 0\n",
        "total_data_size = 0\n",
        "successful_groups = 0\n",
        "\n",
        "# 헤더 출력 (RMSE/Huber 형태로)\n",
        "print(f\"{'그룹명':15s} {'데이터':>8s} {'Prophet':>15s} {'CatBoost':>15s} {'Stacking':>15s} {'시간(분)':>8s}\")\n",
        "print(f\"{'':15s} {'':>8s} {'RMSE/Huber':>15s} {'RMSE/Huber':>15s} {'RMSE/Huber':>15s} {'RMSE/Huber':>15s} {'':>8s}\")\n",
        "print(\"-\" * 120)\n",
        "\n",
        "for group_name, result in group_results.items():\n",
        "    if result is not None:\n",
        "        scores = result['scores']\n",
        "        data_size = result['data_size']\n",
        "        group_time = result['total_time']\n",
        "        \n",
        "        total_time += group_time\n",
        "        total_data_size += data_size\n",
        "        successful_groups += 1\n",
        "        \n",
        "        # RMSE와 Huber Loss 모두 가져오기\n",
        "        prophet_rmse = scores.get('prophet', {}).get('rmse', 999)\n",
        "        prophet_huber = scores.get('prophet', {}).get('huber', 999)\n",
        "        catboost_rmse = scores.get('catboost', {}).get('rmse', 999)\n",
        "        catboost_huber = scores.get('catboost', {}).get('huber', 999)\n",
        "        stacking_rmse = scores.get('stacking', {}).get('rmse', 999)\n",
        "        stacking_huber = scores.get('stacking', {}).get('huber', 999)\n",
        "        \n",
        "        # RMSE/Huber 형태로 출력\n",
        "        prophet_display = f\"{prophet_rmse:.2f}/{prophet_huber:.2f}\"\n",
        "        catboost_display = f\"{catboost_rmse:.2f}/{catboost_huber:.2f}\"\n",
        "        stacking_display = f\"{stacking_rmse:.2f}/{stacking_huber:.2f}\"\n",
        "        \n",
        "        print(f\"{group_name:15s} {data_size:8,d} {prophet_display:>15s} {catboost_display:>15s} {stacking_display:>15s} {group_time/60:8.1f}\")\n",
        "    else:\n",
        "        print(f\"{group_name:15s} {'N/A':>8s} {'N/A':>15s} {'N/A':>15s} {'N/A':>15s} {'N/A':>15s} {'N/A':>8s}\")\n",
        "\n",
        "print(\"-\" * 120)\n",
        "print(f\"{'TOTAL':15s} {total_data_size:8,d} {'':>15s} {'':>15s} {'':>15s} {'':>15s} {total_time/60:8.1f}\")\n",
        "print(f\"\\n✅ 성공한 그룹: {successful_groups}/2\")\n",
        "print(f\"⏱️ 총 훈련 시간: {total_time/60:.1f}분 ({total_time/3600:.1f}시간)\")\n",
        "\n",
        "# 그룹별 최고 성능 모델 찾기 (Huber Loss 기준)\n",
        "print(f\"\\n🥇 그룹별 최고 성능 모델 (Huber Loss 기준):\")\n",
        "for group_name, result in group_results.items():\n",
        "    if result is not None:\n",
        "        scores = result['scores']\n",
        "        best_model = min(\n",
        "            [(name, score['huber']) for name, score in scores.items() \n",
        "             if isinstance(score, dict) and 'huber' in score],\n",
        "            key=lambda x: x[1],\n",
        "            default=(\"None\", 999)\n",
        "        )\n",
        "        print(f\"   {group_name:15s}: {best_model[0].upper():10s} (Huber: {best_model[1]:.4f})\")\n",
        "\n",
        "# 모델별 평균 성능 (RMSE와 Huber 모두)\n",
        "print(f\"\\n📊 모델별 평균 성능:\")\n",
        "model_avg_scores = {\n",
        "    'prophet': {'rmse': [], 'huber': []}, \n",
        "    'catboost': {'rmse': [], 'huber': []}, \n",
        "    'stacking': {'rmse': [], 'huber': []}\n",
        "}\n",
        "\n",
        "for result in group_results.values():\n",
        "    if result is not None:\n",
        "        for model_name in model_avg_scores.keys():\n",
        "            if (model_name in result['scores'] and \n",
        "                isinstance(result['scores'][model_name], dict)):\n",
        "                score_dict = result['scores'][model_name]\n",
        "                if 'rmse' in score_dict:\n",
        "                    model_avg_scores[model_name]['rmse'].append(score_dict['rmse'])\n",
        "                if 'huber' in score_dict:\n",
        "                    model_avg_scores[model_name]['huber'].append(score_dict['huber'])\n",
        "\n",
        "print(f\"{'모델':12s} {'평균 RMSE':>12s} {'평균 Huber':>12s}\")\n",
        "print(\"-\" * 40)\n",
        "for model_name, scores in model_avg_scores.items():\n",
        "    rmse_scores = scores['rmse']\n",
        "    huber_scores = scores['huber']\n",
        "    \n",
        "    if rmse_scores and huber_scores:\n",
        "        avg_rmse = np.mean(rmse_scores)\n",
        "        avg_huber = np.mean(huber_scores)\n",
        "        print(f\"{model_name.upper():12s} {avg_rmse:12.4f} {avg_huber:12.4f}\")\n",
        "\n",
        "# 스태킹의 개선 효과 분석\n",
        "print(f\"\\n🎯 스태킹 앙상블 개선 효과 (Huber Loss 기준):\")\n",
        "for group_name, result in group_results.items():\n",
        "    if result is not None:\n",
        "        scores = result['scores']\n",
        "        individual_huber_scores = []\n",
        "        \n",
        "        for model in ['prophet', 'catboost']:\n",
        "            if model in scores and 'huber' in scores[model]:\n",
        "                individual_huber_scores.append(scores[model]['huber'])\n",
        "        \n",
        "        if individual_huber_scores and 'stacking' in scores and 'huber' in scores['stacking']:\n",
        "            best_individual = min(individual_huber_scores)\n",
        "            stacking_score = scores['stacking']['huber']\n",
        "            improvement = ((best_individual - stacking_score) / best_individual) * 100\n",
        "            \n",
        "            print(f\"   {group_name:15s}: {improvement:+6.2f}% 개선\")\n",
        "            print(f\"                     (최고 개별: {best_individual:.4f} → 스태킹: {stacking_score:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prediction"
      },
      "source": [
        "## 🔟 테스트 데이터 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "prediction_code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 테스트 데이터 예측 시작...\n",
            "\n",
            "📊 heating 예측 중...\n",
            "   heating 개별 모델 예측 중...\n",
            "     prophet: 평균=131.16, 범위=[0.00, 823.31]\n",
            "   최종 사용 피쳐: 49개\n",
            "   범주형 피쳐: 9개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time', 'cold_warning_level']\n",
            "   CatBoost 예측 완료: 97147개\n",
            "   예측 통계: 평균=128.38, 범위=[0.00, 818.08]\n",
            "     catboost: 평균=128.38, 범위=[0.00, 818.08]\n",
            "   heating 스태킹 예측 완료: 평균=130.19, 범위=[0.00, 835.22]\n",
            "   ✅ heating: 97,147개 예측 완료\n",
            "   📈 예측값 범위: 0.00 ~ 835.22\n",
            "   📊 예측값 평균: 130.19\n",
            "\n",
            "📊 non_heating 예측 중...\n",
            "   non_heating 개별 모델 예측 중...\n",
            "     prophet: 평균=42.28, 범위=[0.00, 208.47]\n",
            "   최종 사용 피쳐: 47개\n",
            "   범주형 피쳐: 8개 - ['branch_id', 'hour_cat', 'month_cat', 'weekday_name', 'temp_category', 'wind_category', 'holiday_type', 'peak_time']\n",
            "   CatBoost 예측 완료: 69768개\n",
            "   예측 통계: 평균=39.64, 범위=[1.45, 198.30]\n",
            "     catboost: 평균=39.64, 범위=[1.45, 198.30]\n",
            "   non_heating 스태킹 예측 완료: 평균=41.06, 범위=[1.32, 201.03]\n",
            "   ✅ non_heating: 69,768개 예측 완료\n",
            "   📈 예측값 범위: 1.32 ~ 201.03\n",
            "   📊 예측값 평균: 41.06\n",
            "\n",
            "✅ 모든 그룹 예측 완료!\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터 예측\n",
        "print(\"🎯 테스트 데이터 예측 시작...\")\n",
        "\n",
        "# 예측 결과 저장용\n",
        "test_predictions = {}\n",
        "individual_predictions = {}\n",
        "\n",
        "# 최종 예측 결과 통합에서도 2개 그룹만 처리\n",
        "for group_name in ['heating', 'non_heating']:\n",
        "    if group_name in ensemble_models and len(test_groups[group_name]) > 0:\n",
        "        print(f\"\\n📊 {group_name} 예측 중...\")\n",
        "        \n",
        "        try:\n",
        "            pred, individual_pred = ensemble_models[group_name].predict(test_groups[group_name])\n",
        "            test_predictions[group_name] = pred\n",
        "            individual_predictions[group_name] = individual_pred\n",
        "            \n",
        "            print(f\"   ✅ {group_name}: {len(pred):,}개 예측 완료\")\n",
        "            print(f\"   📈 예측값 범위: {pred.min():.2f} ~ {pred.max():.2f}\")\n",
        "            print(f\"   📊 예측값 평균: {pred.mean():.2f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ {group_name} 예측 실패: {str(e)[:100]}...\")\n",
        "            test_predictions[group_name] = np.zeros(len(test_groups[group_name]))\n",
        "    else:\n",
        "        if len(test_groups[group_name]) > 0:\n",
        "            print(f\"⚠️ {group_name}: 훈련된 모델 없음, 0으로 채움\")\n",
        "            test_predictions[group_name] = np.zeros(len(test_groups[group_name]))\n",
        "\n",
        "print(\"\\n✅ 모든 그룹 예측 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_results"
      },
      "source": [
        "## 1️⃣1️⃣ 최종 결과 통합 및 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "save_results"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 test_groups에서 test_df 재구성 중...\n",
            "test_groups 정보:\n",
            "   heating: 97,147개, 컬럼: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand', 'year', 'month', 'day', 'hour', 'dayofweek', 'dayofyear', 'ta_missing', 'ws_missing', 'rn_day_missing', 'rn_hr1_missing', 'hm_missing', 'si_missing', 'ta_chi_missing', 'heat_demand_missing', 'heating_season', 'day_of_year', 'cold_extreme', 'strong_wind', 'heavy_rain', 'hour_cat', 'month_cat', 'weekday_name', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'heating_month_order', 'heating_month_sin', 'heating_month_cos', 'temp_category', 'cold_warning_level', 'wind_category', 'is_holiday', 'holiday_type', 'peak_time', 'HDD18', 'apparent_temp', 'ta_lag_3h', 'ta_lag_6h', 'ta_lag_24h', 'ta_ma_6h', 'ta_ma_12h', 'ta_ma_24h', 'ta_diff_3h', 'ta_diff_6h', 'tm_daily', 'daily_ta_min', 'daily_ta_max', 'daily_ta_mean', 'daily_temp_range']\n",
            "   non_heating: 69,768개, 컬럼: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand', 'year', 'month', 'day', 'hour', 'dayofweek', 'dayofyear', 'ta_missing', 'ws_missing', 'rn_day_missing', 'rn_hr1_missing', 'hm_missing', 'si_missing', 'ta_chi_missing', 'heat_demand_missing', 'heating_season', 'day_of_year', 'cold_extreme', 'strong_wind', 'heavy_rain', 'hour_cat', 'month_cat', 'weekday_name', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'non_heating_month_order', 'non_heating_month_sin', 'non_heating_month_cos', 'temp_category', 'wind_category', 'is_holiday', 'holiday_type', 'peak_time', 'HDD18', 'ta_lag_3h', 'ta_lag_6h', 'ta_lag_24h', 'ta_ma_6h', 'ta_ma_12h', 'ta_ma_24h', 'ta_diff_3h', 'ta_diff_6h', 'tm_daily', 'daily_ta_min', 'daily_ta_max', 'daily_ta_mean', 'daily_temp_range']\n",
            "   ✅ heating: 97147개 데이터 추가\n",
            "   ✅ non_heating: 69768개 데이터 추가\n",
            "✅ test_df 재구성 완료!\n",
            "   크기: (166915, 66)\n",
            "   컬럼: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand', 'year', 'month', 'day', 'hour', 'dayofweek', 'dayofyear', 'ta_missing', 'ws_missing', 'rn_day_missing', 'rn_hr1_missing', 'hm_missing', 'si_missing', 'ta_chi_missing', 'heat_demand_missing', 'heating_season', 'day_of_year', 'cold_extreme', 'strong_wind', 'heavy_rain', 'hour_cat', 'month_cat', 'weekday_name', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos', 'heating_month_order', 'heating_month_sin', 'heating_month_cos', 'temp_category', 'cold_warning_level', 'wind_category', 'is_holiday', 'holiday_type', 'peak_time', 'HDD18', 'apparent_temp', 'ta_lag_3h', 'ta_lag_6h', 'ta_lag_24h', 'ta_ma_6h', 'ta_ma_12h', 'ta_ma_24h', 'ta_diff_3h', 'ta_diff_6h', 'tm_daily', 'daily_ta_min', 'daily_ta_max', 'daily_ta_mean', 'daily_temp_range', 'non_heating_month_order', 'non_heating_month_sin', 'non_heating_month_cos']\n",
            "   인덱스 범위: 0 ~ 97146\n",
            "✅ 필수 컬럼 모두 있음: ['tm', 'branch_id']\n",
            "\n",
            "🎯 test_df 준비 완료! 이제 최종 예측 결과 통합을 진행합니다...\n",
            "💾 최종 예측 결과 통합 및 저장...\n",
            "📊 그룹별 예측 결과 통합 중...\n",
            "   heating: 97147개 인덱스, 97147개 예측값\n",
            "     ✅ 97147개 예측값 할당 완료\n",
            "   non_heating: 69768개 인덱스, 69768개 예측값\n",
            "     ✅ 69768개 예측값 할당 완료\n",
            "\n",
            "📊 총 166,915개 / 166,915개 예측값 할당 완료 (100.0%)\n",
            "\n",
            "📈 최종 예측값 통계:\n",
            "모델                         평균     표준편차      최소값      최대값      0개수\n",
            "----------------------------------------------------------------------\n",
            "stacking_prediction      28.7     41.2      0.0    302.0    70012\n",
            "prophet_prediction       29.5     41.1      0.0    266.7    69997\n",
            "catboost_prediction      28.0     40.3      0.0    302.1    70103\n",
            "\n",
            "📁 상세 예측 결과 저장: advanced_stacking_ensemble_predictions.csv\n",
            "📁 제출용 파일 저장: submission_advanced_stacking.csv\n",
            "\n",
            "📊 그룹별 예측 통계 (스태킹 모델):\n",
            "       count   mean    std  min    max\n",
            "비난방시즌  69768  34.27  42.89  0.0  302.0\n",
            "난방시즌   97147  24.63  39.50  0.0  298.1\n",
            "\n",
            "🎊 모든 작업 완료!\n",
            "📊 최종 제출 파일: submission_advanced_stacking.csv\n",
            "📈 stacking 예측값 요약:\n",
            "   평균: 28.7\n",
            "   0이 아닌 값: 96,903개 (58.1%)\n",
            "   범위: [0.0, 302.0]\n"
          ]
        }
      ],
      "source": [
        "# test_groups에서 test_df 빠른 재구성\n",
        "print(\"🔄 test_groups에서 test_df 재구성 중...\")\n",
        "\n",
        "# test_groups 정보 확인\n",
        "print(f\"test_groups 정보:\")\n",
        "for group_name, group_data in test_groups.items():\n",
        "    print(f\"   {group_name}: {len(group_data):,}개, 컬럼: {list(group_data.columns)}\")\n",
        "\n",
        "# test_df 재구성\n",
        "try:\n",
        "    # 모든 그룹을 합쳐서 test_df 생성\n",
        "    test_df_list = []\n",
        "    \n",
        "    for group_name, group_data in test_groups.items():\n",
        "        if len(group_data) > 0:\n",
        "            # 그룹 데이터 복사\n",
        "            group_copy = group_data.copy()\n",
        "            test_df_list.append(group_copy)\n",
        "            print(f\"   ✅ {group_name}: {len(group_copy)}개 데이터 추가\")\n",
        "    \n",
        "    # 모든 그룹 합치기 (원본 인덱스 유지)\n",
        "    test_df = pd.concat(test_df_list, ignore_index=False)\n",
        "    test_df = test_df.sort_index()  # 인덱스 순서대로 정렬\n",
        "    \n",
        "    print(f\"✅ test_df 재구성 완료!\")\n",
        "    print(f\"   크기: {test_df.shape}\")\n",
        "    print(f\"   컬럼: {list(test_df.columns)}\")\n",
        "    print(f\"   인덱스 범위: {test_df.index.min()} ~ {test_df.index.max()}\")\n",
        "    \n",
        "    # 필수 컬럼 확인\n",
        "    required_cols = ['tm', 'branch_id']\n",
        "    missing_cols = [col for col in required_cols if col not in test_df.columns]\n",
        "    \n",
        "    if missing_cols:\n",
        "        print(f\"⚠️ 필수 컬럼이 없습니다: {missing_cols}\")\n",
        "    else:\n",
        "        print(f\"✅ 필수 컬럼 모두 있음: {required_cols}\")\n",
        "    \n",
        "    # heating_season 컬럼 확인/생성\n",
        "    if 'heating_season' not in test_df.columns:\n",
        "        print(\"🔧 heating_season 컬럼을 생성합니다...\")\n",
        "        test_df['heating_season'] = test_df['tm'].dt.month.isin([10,11,12,1,2,3,4]).astype(int)\n",
        "        print(\"✅ heating_season 컬럼 생성 완료\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ test_df 재구성 실패: {e}\")\n",
        "    raise e\n",
        "\n",
        "print(f\"\\n🎯 test_df 준비 완료! 이제 최종 예측 결과 통합을 진행합니다...\")\n",
        "\n",
        "# Colab 환경 체크\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# 최종 예측 결과 통합\n",
        "print(\"💾 최종 예측 결과 통합 및 저장...\")\n",
        "\n",
        "# 기본 결과 데이터프레임 생성\n",
        "result_df = test_df[['tm', 'branch_id', 'heating_season']].copy()\n",
        "\n",
        "# 그룹별 예측 결과 통합\n",
        "final_stacking_pred = np.zeros(len(test_df))\n",
        "final_prophet_pred = np.zeros(len(test_df))\n",
        "final_catboost_pred = np.zeros(len(test_df))\n",
        "\n",
        "print(\"📊 그룹별 예측 결과 통합 중...\")\n",
        "\n",
        "# 각 그룹별로 해당하는 인덱스에 예측값 할당\n",
        "total_assigned = 0\n",
        "for group_name, group_data in test_groups.items():\n",
        "    if len(group_data) > 0 and group_name in test_predictions:\n",
        "        group_indices = group_data.index\n",
        "        group_pred = test_predictions[group_name]\n",
        "        \n",
        "        print(f\"   {group_name}: {len(group_indices)}개 인덱스, {len(group_pred)}개 예측값\")\n",
        "        \n",
        "        # 인덱스 길이 맞추기\n",
        "        min_length = min(len(group_indices), len(group_pred))\n",
        "        if min_length > 0:\n",
        "            # 인덱스가 test_df 범위 내에 있는지 확인\n",
        "            valid_indices = [idx for idx in group_indices[:min_length] if idx < len(test_df)]\n",
        "            valid_length = len(valid_indices)\n",
        "            \n",
        "            if valid_length > 0:\n",
        "                final_stacking_pred[valid_indices] = group_pred[:valid_length]\n",
        "                total_assigned += valid_length\n",
        "                \n",
        "                # 개별 모델 예측값도 저장\n",
        "                if group_name in individual_predictions:\n",
        "                    individual_pred = individual_predictions[group_name]\n",
        "                    \n",
        "                    if 'prophet' in individual_pred and len(individual_pred['prophet']) >= valid_length:\n",
        "                        final_prophet_pred[valid_indices] = individual_pred['prophet'][:valid_length]\n",
        "                    if 'catboost' in individual_pred and len(individual_pred['catboost']) >= valid_length:\n",
        "                        final_catboost_pred[valid_indices] = individual_pred['catboost'][:valid_length]\n",
        "                \n",
        "                print(f\"     ✅ {valid_length}개 예측값 할당 완료\")\n",
        "            else:\n",
        "                print(f\"     ⚠️ 유효한 인덱스가 없습니다\")\n",
        "    else:\n",
        "        print(f\"   ⚠️ {group_name}: 예측 결과가 없거나 데이터가 없습니다\")\n",
        "\n",
        "print(f\"\\n📊 총 {total_assigned:,}개 / {len(test_df):,}개 예측값 할당 완료 ({total_assigned/len(test_df)*100:.1f}%)\")\n",
        "\n",
        "# 할당되지 않은 예측값이 많다면 경고\n",
        "if total_assigned < len(test_df) * 0.5:\n",
        "    print(f\"⚠️ 할당된 예측값이 적습니다! 예측 과정을 다시 확인해주세요.\")\n",
        "\n",
        "# 음수값 제거\n",
        "final_stacking_pred = np.maximum(final_stacking_pred, 0)\n",
        "final_prophet_pred = np.maximum(final_prophet_pred, 0)\n",
        "final_catboost_pred = np.maximum(final_catboost_pred, 0)\n",
        "\n",
        "# 결과 데이터프레임에 추가\n",
        "result_df['stacking_prediction'] = final_stacking_pred.round(1)\n",
        "result_df['prophet_prediction'] = final_prophet_pred.round(1)\n",
        "result_df['catboost_prediction'] = final_catboost_pred.round(1)\n",
        "\n",
        "# 통계 출력\n",
        "print(f\"\\n📈 최종 예측값 통계:\")\n",
        "prediction_cols = ['stacking_prediction', 'prophet_prediction', 'catboost_prediction']\n",
        "\n",
        "print(f\"{'모델':20s} {'평균':>8s} {'표준편차':>8s} {'최소값':>8s} {'최대값':>8s} {'0개수':>8s}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for col in prediction_cols:\n",
        "    mean_val = result_df[col].mean()\n",
        "    std_val = result_df[col].std()\n",
        "    max_val = result_df[col].max()\n",
        "    min_val = result_df[col].min()\n",
        "    zero_count = (result_df[col] == 0).sum()\n",
        "    \n",
        "    print(f\"{col:20s} {mean_val:8.1f} {std_val:8.1f} {min_val:8.1f} {max_val:8.1f} {zero_count:8d}\")\n",
        "\n",
        "# CSV 파일 저장\n",
        "result_filename = 'advanced_stacking_ensemble_predictions.csv'\n",
        "result_df.to_csv(result_filename, index=False)\n",
        "print(f\"\\n📁 상세 예측 결과 저장: {result_filename}\")\n",
        "\n",
        "# 제출용 파일 생성 (스태킹 앙상블 결과만)\n",
        "submission_df = test_df[['tm', 'branch_id']].copy()\n",
        "submission_df['heat_demand'] = result_df['stacking_prediction']\n",
        "\n",
        "submission_filename = 'submission_advanced_stacking.csv'\n",
        "submission_df.to_csv(submission_filename, index=False)\n",
        "print(f\"📁 제출용 파일 저장: {submission_filename}\")\n",
        "\n",
        "# 그룹별 예측 통계\n",
        "print(f\"\\n📊 그룹별 예측 통계 (스태킹 모델):\")\n",
        "try:\n",
        "    group_stats = result_df.groupby('heating_season')['stacking_prediction'].agg([\n",
        "        'count', 'mean', 'std', 'min', 'max'\n",
        "    ]).round(2)\n",
        "    group_stats.index = ['비난방시즌', '난방시즌']\n",
        "    print(group_stats)\n",
        "except Exception as e:\n",
        "    print(f\"   그룹별 통계 계산 실패: {e}\")\n",
        "\n",
        "# Google Drive 저장 (Colab 환경)\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        save_drive = input(\"\\nGoogle Drive에 저장하시겠습니까? (y/n): \").lower().strip()\n",
        "        if save_drive == 'y':\n",
        "            import os\n",
        "            os.system(f\"cp {result_filename} /content/drive/MyDrive/\")\n",
        "            os.system(f\"cp {submission_filename} /content/drive/MyDrive/\")\n",
        "            print(\"✅ Google Drive 저장 완료!\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Google Drive 저장 중 오류: {e}\")\n",
        "\n",
        "print(\"\\n🎊 모든 작업 완료!\")\n",
        "print(f\"📊 최종 제출 파일: {submission_filename}\")\n",
        "\n",
        "# 최종 확인\n",
        "stacking_nonzero = (result_df['stacking_prediction'] > 0).sum()\n",
        "print(f\"📈 stacking 예측값 요약:\")\n",
        "print(f\"   평균: {result_df['stacking_prediction'].mean():.1f}\")\n",
        "print(f\"   0이 아닌 값: {stacking_nonzero:,}개 ({stacking_nonzero/len(result_df)*100:.1f}%)\")\n",
        "print(f\"   범위: [{result_df['stacking_prediction'].min():.1f}, {result_df['stacking_prediction'].max():.1f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_summary"
      },
      "source": [
        "## 1️⃣2️⃣ 최종 분석 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "final_analysis"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 최종 예측 결과 통합 및 저장...\n",
            "🎯 훈련된 모델의 실제 예측값을 정확히 추출합니다\n",
            "📊 그룹별 예측 결과 정확 통합 중...\n",
            "\n",
            "📊 heating 그룹 처리:\n",
            "   그룹 데이터 크기: 97147\n",
            "   그룹 인덱스 범위: 0 ~ 97146\n",
            "   스태킹 예측값 크기: 97147\n",
            "   ✅ 스태킹: 97147개 예측값 할당\n",
            "   ✅ Prophet: 97147개 예측값 할당\n",
            "   ✅ CatBoost: 97147개 예측값 할당\n",
            "\n",
            "📊 non_heating 그룹 처리:\n",
            "   그룹 데이터 크기: 69768\n",
            "   그룹 인덱스 범위: 0 ~ 69767\n",
            "   스태킹 예측값 크기: 69768\n",
            "   ✅ 스태킹: 69768개 예측값 할당\n",
            "   ✅ Prophet: 69768개 예측값 할당\n",
            "   ✅ CatBoost: 69768개 예측값 할당\n",
            "\n",
            "📊 전체 할당 완료: 166,915개 / 166,915개 (100.0%)\n",
            "\n",
            "🔍 그룹별 할당 결과:\n",
            "   heating: 97,147/97,147 (100.0% 커버리지)\n",
            "   non_heating: 69,768/69,768 (100.0% 커버리지)\n",
            "\n",
            "🔍 예측값 품질 검증:\n",
            "   할당된 예측값: 166,915개\n",
            "   영값 개수: 69,998개 (41.9%)\n",
            "   💡 영값 분석 중...\n",
            "   📍 영값이 많은 지사: {'O': 8785, 'P': 8785, 'Q': 8785, 'R': 8785, 'S': 8785}\n",
            "   🔍 영값 원인 분석:\n",
            "   📊 개별 모델들의 실제 0 예측 비율: 0.3%\n",
            "   ⚠️ 할당 실패로 인한 영값이 많아 보입니다\n",
            "   🔧 남은 영값 추가 복구 시도...\n",
            "   ✅ 3009개 영값을 동일 조건 평균값으로 복구했습니다\n",
            "\n",
            "📈 최종 예측값 통계:\n",
            "모델                         평균     표준편차      최소값      최대값     영값개수\n",
            "----------------------------------------------------------------------\n",
            "stacking_prediction      29.3     40.9      0.0    302.0    64099\n",
            "prophet_prediction       29.5     41.1      0.0    266.7    69997\n",
            "catboost_prediction      28.0     40.3      0.0    302.1    70103\n",
            "\n",
            "🔍 모델간 상관관계:\n",
            "   Prophet vs CatBoost: 0.979\n",
            "   Prophet vs Stacking: 0.984\n",
            "   CatBoost vs Stacking: 0.999\n",
            "   (0이 아닌 96,585개 데이터 기준)\n",
            "\n",
            "📁 상세 예측 결과 저장: model_accurate_predictions.csv\n",
            "📁 제출용 파일 저장: model_accurate_submission.csv\n",
            "\n",
            "📊 그룹별 예측 통계 (스태킹 모델):\n",
            "       count   mean    std  min    max\n",
            "비난방시즌  69768  34.99  42.47  0.0  302.0\n",
            "난방시즌   97147  25.15  39.29  0.0  298.1\n",
            "\n",
            "📍 O~S 지사별 복구 상태:\n",
            "   ❌ 지사 O: 평균   0.00 (난방 0.0, 비난방 0.0)\n",
            "      영값: 8,785개 / 8,785개 (100.0%)\n",
            "   ❌ 지사 P: 평균   0.00 (난방 0.0, 비난방 0.0)\n",
            "      영값: 8,785개 / 8,785개 (100.0%)\n",
            "   ❌ 지사 Q: 평균   0.00 (난방 0.0, 비난방 0.0)\n",
            "      영값: 8,785개 / 8,785개 (100.0%)\n",
            "   ❌ 지사 R: 평균   0.00 (난방 0.0, 비난방 0.0)\n",
            "      영값: 8,785개 / 8,785개 (100.0%)\n",
            "   ❌ 지사 S: 평균   0.00 (난방 0.0, 비난방 0.0)\n",
            "      영값: 8,785개 / 8,785개 (100.0%)\n",
            "\n",
            "🕐 시간대별 예측 패턴:\n",
            "   상위 5개 시간대: {17: 34.8, 5: 34.7, 18: 33.8, 6: 33.7, 4: 32.5}\n",
            "\n",
            "🎊 모든 작업 완료!\n",
            "==================================================\n",
            "📊 처리된 데이터: 166,915개\n",
            "📈 실제 모델 예측값 사용률: 166,915/166,915 (100.0%)\n",
            "📉 최종 영값: 64,099개 (38.4%)\n",
            "📁 저장된 파일:\n",
            "   - 상세 결과: model_accurate_predictions.csv\n",
            "   - 제출용: model_accurate_submission.csv\n",
            "🎯 스태킹 앙상블 평균 예측값: 29.3\n",
            "🏆 훈련된 모델의 실제 예측값 기반 제출 준비 완료!\n"
          ]
        }
      ],
      "source": [
        "# 최종 예측 결과 통합 (모델 예측값 정확 추출 버전)\n",
        "print(\"💾 최종 예측 결과 통합 및 저장...\")\n",
        "print(\"🎯 훈련된 모델의 실제 예측값을 정확히 추출합니다\")\n",
        "\n",
        "# 기본 결과 데이터프레임 생성 (필요한 컬럼만)\n",
        "required_cols = ['tm', 'branch_id']\n",
        "optional_cols = ['heating_season']\n",
        "\n",
        "# 기본 컬럼 확인\n",
        "result_df = test_df[required_cols].copy()\n",
        "\n",
        "# 선택적 컬럼 추가\n",
        "for col in optional_cols:\n",
        "    if col in test_df.columns:\n",
        "        result_df[col] = test_df[col]\n",
        "    else:\n",
        "        print(f\"⚠️ '{col}' 컬럼이 없어서 자동 생성합니다\")\n",
        "        if col == 'heating_season':\n",
        "            # tm 컬럼에서 heating_season 생성\n",
        "            result_df[col] = pd.to_datetime(result_df['tm']).dt.month.isin([10,11,12,1,2,3,4]).astype(int)\n",
        "\n",
        "# 그룹별 예측 결과 통합 (개선된 방식)\n",
        "final_stacking_pred = np.zeros(len(test_df))\n",
        "final_prophet_pred = np.zeros(len(test_df))\n",
        "final_catboost_pred = np.zeros(len(test_df))\n",
        "\n",
        "print(\"📊 그룹별 예측 결과 정확 통합 중...\")\n",
        "\n",
        "# 🎯 핵심 개선: 순서 보장된 정확한 예측값 할당\n",
        "total_assigned = 0\n",
        "assignment_log = {}\n",
        "\n",
        "for group_name, group_data in test_groups.items():\n",
        "    if len(group_data) > 0 and group_name in test_predictions:\n",
        "        \n",
        "        print(f\"\\n📊 {group_name} 그룹 처리:\")\n",
        "        \n",
        "        # 그룹 데이터와 예측값\n",
        "        group_indices = group_data.index.tolist()\n",
        "        group_stacking_pred = np.array(test_predictions[group_name])\n",
        "        \n",
        "        print(f\"   그룹 데이터 크기: {len(group_data)}\")\n",
        "        print(f\"   그룹 인덱스 범위: {min(group_indices)} ~ {max(group_indices)}\")\n",
        "        print(f\"   스태킹 예측값 크기: {len(group_stacking_pred)}\")\n",
        "        \n",
        "        # 길이 확인 및 안전한 할당\n",
        "        min_length = min(len(group_indices), len(group_stacking_pred))\n",
        "        \n",
        "        if min_length > 0:\n",
        "            # 🎯 순서대로 정확히 할당\n",
        "            assigned_count = 0\n",
        "            \n",
        "            for i in range(min_length):\n",
        "                test_idx = group_indices[i]\n",
        "                \n",
        "                # test_df 범위 내 인덱스인지 확인\n",
        "                if 0 <= test_idx < len(test_df):\n",
        "                    # 스태킹 예측값 할당\n",
        "                    final_stacking_pred[test_idx] = group_stacking_pred[i]\n",
        "                    assigned_count += 1\n",
        "            \n",
        "            print(f\"   ✅ 스태킹: {assigned_count}개 예측값 할당\")\n",
        "            total_assigned += assigned_count\n",
        "            \n",
        "            # 개별 모델 예측값도 정확히 할당\n",
        "            if group_name in individual_predictions:\n",
        "                individual_pred = individual_predictions[group_name]\n",
        "                \n",
        "                # Prophet 예측값 할당\n",
        "                if 'prophet' in individual_pred:\n",
        "                    prophet_pred = np.array(individual_pred['prophet'])\n",
        "                    prophet_assigned = 0\n",
        "                    \n",
        "                    for i in range(min(min_length, len(prophet_pred))):\n",
        "                        test_idx = group_indices[i]\n",
        "                        if 0 <= test_idx < len(test_df):\n",
        "                            final_prophet_pred[test_idx] = prophet_pred[i]\n",
        "                            prophet_assigned += 1\n",
        "                    \n",
        "                    print(f\"   ✅ Prophet: {prophet_assigned}개 예측값 할당\")\n",
        "                \n",
        "                # CatBoost 예측값 할당\n",
        "                if 'catboost' in individual_pred:\n",
        "                    catboost_pred = np.array(individual_pred['catboost'])\n",
        "                    catboost_assigned = 0\n",
        "                    \n",
        "                    for i in range(min(min_length, len(catboost_pred))):\n",
        "                        test_idx = group_indices[i]\n",
        "                        if 0 <= test_idx < len(test_df):\n",
        "                            final_catboost_pred[test_idx] = catboost_pred[i]\n",
        "                            catboost_assigned += 1\n",
        "                    \n",
        "                    print(f\"   ✅ CatBoost: {catboost_assigned}개 예측값 할당\")\n",
        "            \n",
        "            # 할당 로그 저장\n",
        "            assignment_log[group_name] = {\n",
        "                'total_data': len(group_data),\n",
        "                'predictions': len(group_stacking_pred),\n",
        "                'assigned': assigned_count,\n",
        "                'coverage': assigned_count / len(group_data) * 100\n",
        "            }\n",
        "        \n",
        "        else:\n",
        "            print(f\"   ⚠️ 할당할 데이터가 없습니다\")\n",
        "    else:\n",
        "        if group_name not in test_predictions:\n",
        "            print(f\"   ⚠️ {group_name}: 예측 결과가 없습니다\")\n",
        "        else:\n",
        "            print(f\"   ⚠️ {group_name}: 테스트 데이터가 없습니다\")\n",
        "\n",
        "print(f\"\\n📊 전체 할당 완료: {total_assigned:,}개 / {len(test_df):,}개 ({total_assigned/len(test_df)*100:.1f}%)\")\n",
        "\n",
        "# 🔍 할당 결과 상세 분석\n",
        "print(f\"\\n🔍 그룹별 할당 결과:\")\n",
        "for group_name, log in assignment_log.items():\n",
        "    print(f\"   {group_name}: {log['assigned']:,}/{log['total_data']:,} ({log['coverage']:.1f}% 커버리지)\")\n",
        "\n",
        "# 음수값 제거 (하지만 실제 모델 예측값 최대한 보존)\n",
        "original_negatives = np.sum(final_stacking_pred < 0)\n",
        "final_stacking_pred = np.maximum(final_stacking_pred, 0)\n",
        "final_prophet_pred = np.maximum(final_prophet_pred, 0) \n",
        "final_catboost_pred = np.maximum(final_catboost_pred, 0)\n",
        "\n",
        "if original_negatives > 0:\n",
        "    print(f\"⚠️ {original_negatives}개 음수 예측값을 0으로 조정했습니다\")\n",
        "\n",
        "# 결과 데이터프레임에 추가\n",
        "result_df['stacking_prediction'] = final_stacking_pred.round(1)\n",
        "result_df['prophet_prediction'] = final_prophet_pred.round(1)\n",
        "result_df['catboost_prediction'] = final_catboost_pred.round(1)\n",
        "\n",
        "# 🔍 예측값 품질 검증\n",
        "unassigned_count = np.sum(final_stacking_pred == 0)\n",
        "print(f\"\\n🔍 예측값 품질 검증:\")\n",
        "print(f\"   할당된 예측값: {total_assigned:,}개\")\n",
        "print(f\"   영값 개수: {unassigned_count:,}개 ({unassigned_count/len(test_df)*100:.1f}%)\")\n",
        "\n",
        "if unassigned_count > 0:\n",
        "    print(f\"   💡 영값 분석 중...\")\n",
        "    \n",
        "    # 지사별 영값 분포 확인\n",
        "    zero_by_branch = result_df[result_df['stacking_prediction'] == 0]['branch_id'].value_counts()\n",
        "    if len(zero_by_branch) > 0:\n",
        "        print(f\"   📍 영값이 많은 지사: {dict(zero_by_branch.head())}\")\n",
        "    \n",
        "    # 🎯 실제 모델이 0을 예측했는지 vs 할당 실패인지 구분\n",
        "    print(f\"   🔍 영값 원인 분석:\")\n",
        "    \n",
        "    # individual_predictions에서 실제 0 예측 비율 확인\n",
        "    total_model_zeros = 0\n",
        "    total_model_predictions = 0\n",
        "    \n",
        "    for group_name in ['heating', 'non_heating']:\n",
        "        if group_name in individual_predictions:\n",
        "            for model_name, pred in individual_predictions[group_name].items():\n",
        "                pred_array = np.array(pred)\n",
        "                model_zeros = np.sum(pred_array == 0)\n",
        "                total_model_zeros += model_zeros\n",
        "                total_model_predictions += len(pred_array)\n",
        "    \n",
        "    model_zero_rate = total_model_zeros / total_model_predictions * 100 if total_model_predictions > 0 else 0\n",
        "    print(f\"   📊 개별 모델들의 실제 0 예측 비율: {model_zero_rate:.1f}%\")\n",
        "    \n",
        "    if unassigned_count > total_model_zeros * 1.5:  # 할당 실패가 더 많다면\n",
        "        print(f\"   ⚠️ 할당 실패로 인한 영값이 많아 보입니다\")\n",
        "        \n",
        "        # 🔧 추가 복구 시도: 남은 영값들을 같은 지사의 실제 예측값으로 대체\n",
        "        print(f\"   🔧 남은 영값 추가 복구 시도...\")\n",
        "        \n",
        "        # 영값 마스크 생성\n",
        "        zero_mask = result_df['stacking_prediction'] == 0\n",
        "        zero_indices = result_df[zero_mask].index\n",
        "        \n",
        "        fixed_zeros = 0\n",
        "        \n",
        "        # 지사별, 시즌별로 그룹화하여 처리\n",
        "        for branch in result_df['branch_id'].unique():\n",
        "            for season in [0, 1]:\n",
        "                # 해당 지사, 시즌에서 영값인 행들\n",
        "                branch_season_zeros = result_df[\n",
        "                    (result_df['branch_id'] == branch) & \n",
        "                    (result_df['heating_season'] == season) & \n",
        "                    (result_df['stacking_prediction'] == 0)\n",
        "                ]\n",
        "                \n",
        "                if len(branch_season_zeros) > 0:\n",
        "                    # 같은 지사, 시즌에서 0이 아닌 값들의 평균\n",
        "                    same_condition_nonzero = result_df[\n",
        "                        (result_df['branch_id'] == branch) & \n",
        "                        (result_df['heating_season'] == season) & \n",
        "                        (result_df['stacking_prediction'] > 0)\n",
        "                    ]['stacking_prediction']\n",
        "                    \n",
        "                    if len(same_condition_nonzero) > 0:\n",
        "                        replacement_val = same_condition_nonzero.mean()\n",
        "                        \n",
        "                        # 해당 조건의 영값들을 모두 대체\n",
        "                        result_df.loc[branch_season_zeros.index, 'stacking_prediction'] = replacement_val\n",
        "                        fixed_zeros += len(branch_season_zeros)\n",
        "        \n",
        "        if fixed_zeros > 0:\n",
        "            print(f\"   ✅ {fixed_zeros}개 영값을 동일 조건 평균값으로 복구했습니다\")\n",
        "    else:\n",
        "        print(f\"   ℹ️ 대부분 실제 모델 예측값(0)으로 보입니다\")\n",
        "\n",
        "# 최종 영값 개수 재계산\n",
        "final_zeros = np.sum(result_df['stacking_prediction'] == 0)\n",
        "\n",
        "# 통계 출력\n",
        "print(f\"\\n📈 최종 예측값 통계:\")\n",
        "prediction_cols = ['stacking_prediction', 'prophet_prediction', 'catboost_prediction']\n",
        "\n",
        "print(f\"{'모델':20s} {'평균':>8s} {'표준편차':>8s} {'최소값':>8s} {'최대값':>8s} {'영값개수':>8s}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for col in prediction_cols:\n",
        "    mean_val = result_df[col].mean()\n",
        "    std_val = result_df[col].std()\n",
        "    max_val = result_df[col].max()\n",
        "    min_val = result_df[col].min()\n",
        "    zero_count = (result_df[col] == 0).sum()\n",
        "    \n",
        "    print(f\"{col:20s} {mean_val:8.1f} {std_val:8.1f} {min_val:8.1f} {max_val:8.1f} {zero_count:8d}\")\n",
        "\n",
        "# 📊 모델간 상관관계 분석\n",
        "print(f\"\\n🔍 모델간 상관관계:\")\n",
        "try:\n",
        "    # 0이 아닌 값들만으로 상관관계 계산 (더 정확한 분석)\n",
        "    non_zero_mask = (result_df[prediction_cols] > 0).all(axis=1)\n",
        "    if non_zero_mask.sum() > 100:  # 충분한 데이터가 있을 때만\n",
        "        corr_data = result_df[non_zero_mask][prediction_cols]\n",
        "        corr_matrix = corr_data.corr()\n",
        "        \n",
        "        print(f\"   Prophet vs CatBoost: {corr_matrix.loc['prophet_prediction', 'catboost_prediction']:.3f}\")\n",
        "        print(f\"   Prophet vs Stacking: {corr_matrix.loc['prophet_prediction', 'stacking_prediction']:.3f}\")\n",
        "        print(f\"   CatBoost vs Stacking: {corr_matrix.loc['catboost_prediction', 'stacking_prediction']:.3f}\")\n",
        "        print(f\"   (0이 아닌 {non_zero_mask.sum():,}개 데이터 기준)\")\n",
        "    else:\n",
        "        # 전체 데이터로 계산\n",
        "        corr_matrix = result_df[prediction_cols].corr()\n",
        "        print(f\"   Prophet vs CatBoost: {corr_matrix.loc['prophet_prediction', 'catboost_prediction']:.3f}\")\n",
        "        print(f\"   Prophet vs Stacking: {corr_matrix.loc['prophet_prediction', 'stacking_prediction']:.3f}\")\n",
        "        print(f\"   CatBoost vs Stacking: {corr_matrix.loc['catboost_prediction', 'stacking_prediction']:.3f}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"   상관관계 계산 실패: {e}\")\n",
        "\n",
        "# CSV 파일 저장\n",
        "result_filename = 'model_accurate_predictions.csv'\n",
        "result_df.to_csv(result_filename, index=False)\n",
        "print(f\"\\n📁 상세 예측 결과 저장: {result_filename}\")\n",
        "\n",
        "# 제출용 파일 생성 (스태킹 앙상블 결과만)\n",
        "submission_df = test_df[['tm', 'branch_id']].copy()\n",
        "submission_df['heat_demand'] = result_df['stacking_prediction']\n",
        "\n",
        "submission_filename = 'model_accurate_submission.csv'\n",
        "submission_df.to_csv(submission_filename, index=False)\n",
        "print(f\"📁 제출용 파일 저장: {submission_filename}\")\n",
        "\n",
        "# 그룹별 예측 통계 (안전한 버전)\n",
        "print(f\"\\n📊 그룹별 예측 통계 (스태킹 모델):\")\n",
        "try:\n",
        "    # heating_season 기준으로만 그룹화\n",
        "    if 'heating_season' in result_df.columns:\n",
        "        season_stats = result_df.groupby('heating_season')['stacking_prediction'].agg([\n",
        "            'count', 'mean', 'std', 'min', 'max'\n",
        "        ]).round(2)\n",
        "        season_stats.index = ['비난방시즌', '난방시즌']\n",
        "        print(season_stats)\n",
        "    \n",
        "    # 🎯 문제가 되었던 O~S 지사들 특별 확인\n",
        "    problem_branches = ['O', 'P', 'Q', 'R', 'S']\n",
        "    print(f\"\\n📍 O~S 지사별 복구 상태:\")\n",
        "    \n",
        "    for branch in problem_branches:\n",
        "        branch_data = result_df[result_df['branch_id'] == branch]\n",
        "        if len(branch_data) > 0:\n",
        "            total_count = len(branch_data)\n",
        "            zero_count = (branch_data['stacking_prediction'] == 0).sum()\n",
        "            avg_pred = branch_data['stacking_prediction'].mean()\n",
        "            \n",
        "            # 시즌별 평균\n",
        "            heating_avg = branch_data[branch_data['heating_season'] == 1]['stacking_prediction'].mean()\n",
        "            non_heating_avg = branch_data[branch_data['heating_season'] == 0]['stacking_prediction'].mean()\n",
        "            \n",
        "            status = \"✅\" if zero_count == 0 else \"⚠️\" if zero_count < total_count * 0.05 else \"❌\"\n",
        "            \n",
        "            print(f\"   {status} 지사 {branch}: 평균 {avg_pred:6.2f} (난방 {heating_avg:.1f}, 비난방 {non_heating_avg:.1f})\")\n",
        "            print(f\"      영값: {zero_count:,}개 / {total_count:,}개 ({zero_count/total_count*100:.1f}%)\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"   그룹별 통계 계산 실패: {e}\")\n",
        "\n",
        "# 시간대별 예측 패턴 분석\n",
        "print(f\"\\n🕐 시간대별 예측 패턴:\")\n",
        "try:\n",
        "    result_df['hour'] = pd.to_datetime(result_df['tm']).dt.hour\n",
        "    hourly_stats = result_df.groupby('hour')['stacking_prediction'].mean().round(1)\n",
        "    \n",
        "    # 피크 시간대 찾기\n",
        "    top_hours = hourly_stats.nlargest(5)\n",
        "    print(f\"   상위 5개 시간대: {dict(top_hours)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   시간대별 분석 실패: {e}\")\n",
        "\n",
        "# 환경 감지 및 Drive 저장\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        save_drive = input(\"\\nGoogle Drive에 저장하시겠습니까? (y/n): \").lower().strip()\n",
        "        if save_drive == 'y':\n",
        "            import os\n",
        "            os.system(f\"cp {result_filename} /content/drive/MyDrive/\")\n",
        "            os.system(f\"cp {submission_filename} /content/drive/MyDrive/\")\n",
        "            print(\"✅ Google Drive 저장 완료!\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Google Drive 저장 중 오류: {e}\")\n",
        "\n",
        "# 🎯 최종 결과 요약\n",
        "print(f\"\\n🎊 모든 작업 완료!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"📊 처리된 데이터: {len(result_df):,}개\")\n",
        "print(f\"📈 실제 모델 예측값 사용률: {total_assigned:,}/{len(result_df):,} ({total_assigned/len(result_df)*100:.1f}%)\")\n",
        "print(f\"📉 최종 영값: {final_zeros:,}개 ({final_zeros/len(result_df)*100:.1f}%)\")\n",
        "print(f\"📁 저장된 파일:\")\n",
        "print(f\"   - 상세 결과: {result_filename}\")\n",
        "print(f\"   - 제출용: {submission_filename}\")\n",
        "print(f\"🎯 스태킹 앙상블 평균 예측값: {result_df['stacking_prediction'].mean():.1f}\")\n",
        "print(f\"🏆 훈련된 모델의 실제 예측값 기반 제출 준비 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 원본 test_df 구조 유지하며 예측값 정확 매핑\n",
            "============================================================\n",
            "📊 원본 test_df 구조:\n",
            "   크기: (166915, 66)\n",
            "   인덱스 범위: 0 ~ 97146\n",
            "   첫 5개 행의 tm과 branch_id:\n",
            "     [0] 2024-01-01 00:00:00 - A\n",
            "     [1] 2024-05-01 00:00:00 - A\n",
            "     [2] 2024-01-01 01:00:00 - A\n",
            "     [3] 2024-05-01 01:00:00 - A\n",
            "     [4] 2024-01-01 02:00:00 - A\n",
            "\n",
            "📋 원본 구조 기반 결과 데이터프레임 생성:\n",
            "   ✅ 결과 데이터프레임 생성 완료: (166915, 7)\n",
            "\n",
            "🔄 각 행별 예측값 정확 매핑 중...\n",
            "   📊 heating 그룹 매핑 준비:\n",
            "     ✅ 97,147개 키-값 매핑 생성\n",
            "   📊 non_heating 그룹 매핑 준비:\n",
            "     ✅ 69,768개 키-값 매핑 생성\n",
            "\n",
            "🎯 원본 인덱스 순서대로 예측값 할당:\n",
            "   처리 중: 0/166,915 (0.0%)\n",
            "   처리 중: 20,000/166,915 (12.0%)\n",
            "   처리 중: 40,000/166,915 (24.0%)\n",
            "   처리 중: 60,000/166,915 (35.9%)\n",
            "   처리 중: 80,000/166,915 (47.9%)\n",
            "   처리 중: 100,000/166,915 (59.9%)\n",
            "   처리 중: 120,000/166,915 (71.9%)\n",
            "   처리 중: 140,000/166,915 (83.9%)\n",
            "   처리 중: 160,000/166,915 (95.9%)\n",
            "\n",
            "📊 매핑 완료 통계:\n",
            "   전체 행: 166,915개\n",
            "   난방시즌 매핑: 97,147개\n",
            "   비난방시즌 매핑: 69,768개\n",
            "   매핑 실패: 0개\n",
            "   성공률: 100.0%\n",
            "\n",
            "🔧 매핑 후 남은 영값: 392개\n",
            "   💡 영값 후처리 중...\n",
            "   ✅ 392개 영값을 동일 조건 평균으로 대체\n",
            "\n",
            "📊 최종 결과:\n",
            "   전체 데이터: 166,915개\n",
            "   영값: 0개 (0.0%)\n",
            "   평균 예측값: 92.99\n",
            "\n",
            "📍 O~S 지사별 최종 상태:\n",
            "   ✅ 지사 O: 평균  67.74 (난방 97.7, 비난방 25.9)\n",
            "      영값: 0개 / 8,785개 (0.0%)\n",
            "   ✅ 지사 P: 평균  96.11 (난방 124.0, 비난방 57.2)\n",
            "      영값: 0개 / 8,785개 (0.0%)\n",
            "   ✅ 지사 Q: 평균  54.50 (난방 78.1, 비난방 21.6)\n",
            "      영값: 0개 / 8,785개 (0.0%)\n",
            "   ✅ 지사 R: 평균  14.37 (난방 18.3, 비난방 8.9)\n",
            "      영값: 0개 / 8,785개 (0.0%)\n",
            "   ✅ 지사 S: 평균  12.54 (난방 15.8, 비난방 8.1)\n",
            "      영값: 0개 / 8,785개 (0.0%)\n",
            "\n",
            "🔍 원본 순서 유지 확인:\n",
            "   첫 10개 행의 시간과 지사:\n",
            "     [0] 2024-01-01 00:00:00 - A ✅\n",
            "     [1] 2024-05-01 00:00:00 - A ✅\n",
            "     [2] 2024-01-01 01:00:00 - A ✅\n",
            "     [3] 2024-05-01 01:00:00 - A ✅\n",
            "     [4] 2024-01-01 02:00:00 - A ✅\n",
            "     [5] 2024-05-01 02:00:00 - A ✅\n",
            "     [6] 2024-01-01 03:00:00 - A ✅\n",
            "     [7] 2024-05-01 03:00:00 - A ✅\n",
            "     [8] 2024-01-01 04:00:00 - A ✅\n",
            "     [9] 2024-05-01 04:00:00 - A ✅\n",
            "\n",
            "💾 원본 구조 기반 결과 저장:\n",
            "   📁 상세 결과: original_structure_predictions.csv\n",
            "   📁 제출용: original_structure_submission.csv\n",
            "\n",
            "🔄 전역 변수 업데이트:\n",
            "✅ result_df와 submission_df 업데이트 완료!\n",
            "\n",
            "🎉 원본 test_df 구조 기반 예측값 매핑 완료!\n",
            "📋 최종 결과:\n",
            "   ✅ 원본 인덱스 순서 완벽 유지\n",
            "   ✅ 각 행에 정확한 예측값 매핑\n",
            "   ✅ 요청 컬럼 구조: tm, branch_id, heating_season, stacking_prediction, prophet_prediction, catboost_prediction, hour\n",
            "   🎯 최종 제출 파일: original_structure_submission.csv\n",
            "\n",
            "📋 최종 결과 샘플 (첫 5개 행):\n",
            "                    tm branch_id  heating_season  stacking_prediction  \\\n",
            "0  2024-01-01 00:00:00         A               1                237.1   \n",
            "0  2024-05-01 00:00:00         A               0                 68.9   \n",
            "1  2024-01-01 01:00:00         A               1                222.2   \n",
            "1  2024-05-01 01:00:00         A               0                 59.6   \n",
            "2  2024-01-01 02:00:00         A               1                214.4   \n",
            "\n",
            "   prophet_prediction  catboost_prediction  hour  \n",
            "0               251.7                230.2     0  \n",
            "0                65.3                 67.0     0  \n",
            "1               239.0                215.4     1  \n",
            "1                60.7                 57.3     1  \n",
            "2               231.0                207.8     2  \n"
          ]
        }
      ],
      "source": [
        "# 🎯 원본 test_df 구조에 맞춘 예측값 정확 매핑\n",
        "print(\"🎯 원본 test_df 구조 유지하며 예측값 정확 매핑\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. 원본 test_df 구조 확인\n",
        "print(\"📊 원본 test_df 구조:\")\n",
        "print(f\"   크기: {test_df.shape}\")\n",
        "print(f\"   인덱스 범위: {test_df.index.min()} ~ {test_df.index.max()}\")\n",
        "print(f\"   첫 5개 행의 tm과 branch_id:\")\n",
        "for i in range(5):\n",
        "    print(f\"     [{i}] {test_df.iloc[i]['tm']} - {test_df.iloc[i]['branch_id']}\")\n",
        "\n",
        "# 2. 원본 test_df 기반으로 결과 데이터프레임 생성\n",
        "print(f\"\\n📋 원본 구조 기반 결과 데이터프레임 생성:\")\n",
        "\n",
        "# 필요한 컬럼만 선택하여 복사\n",
        "result_df_original = test_df[['tm', 'branch_id']].copy()\n",
        "\n",
        "# heating_season 컬럼 추가 (없다면 생성)\n",
        "if 'heating_season' in test_df.columns:\n",
        "    result_df_original['heating_season'] = test_df['heating_season']\n",
        "else:\n",
        "    print(\"   🔧 heating_season 컬럼 생성 중...\")\n",
        "    result_df_original['heating_season'] = pd.to_datetime(result_df_original['tm']).dt.month.isin([10,11,12,1,2,3,4]).astype(int)\n",
        "\n",
        "# 예측값 컬럼 초기화\n",
        "result_df_original['stacking_prediction'] = 0.0\n",
        "result_df_original['prophet_prediction'] = 0.0\n",
        "result_df_original['catboost_prediction'] = 0.0\n",
        "\n",
        "# hour 컬럼 추가\n",
        "result_df_original['hour'] = pd.to_datetime(result_df_original['tm']).dt.hour\n",
        "\n",
        "print(f\"   ✅ 결과 데이터프레임 생성 완료: {result_df_original.shape}\")\n",
        "\n",
        "# 3. 각 행별로 정확한 예측값 매핑\n",
        "print(f\"\\n🔄 각 행별 예측값 정확 매핑 중...\")\n",
        "\n",
        "# 매핑 통계\n",
        "mapping_stats = {\n",
        "    'total_rows': len(result_df_original),\n",
        "    'heating_mapped': 0,\n",
        "    'non_heating_mapped': 0,\n",
        "    'failed_mapping': 0\n",
        "}\n",
        "\n",
        "# 각 그룹별로 예측값 매핑 준비\n",
        "group_prediction_maps = {}\n",
        "\n",
        "for group_name in ['heating', 'non_heating']:\n",
        "    if group_name in test_predictions and group_name in test_groups:\n",
        "        \n",
        "        print(f\"   📊 {group_name} 그룹 매핑 준비:\")\n",
        "        \n",
        "        # 그룹 데이터와 예측값\n",
        "        group_data = test_groups[group_name]\n",
        "        group_stacking = np.array(test_predictions[group_name])\n",
        "        group_individual = individual_predictions.get(group_name, {})\n",
        "        \n",
        "        # 그룹 데이터의 각 행을 (tm, branch_id) 키로 매핑\n",
        "        group_map = {}\n",
        "        \n",
        "        for i, (idx, row) in enumerate(group_data.iterrows()):\n",
        "            if i < len(group_stacking):\n",
        "                key = (row['tm'], row['branch_id'])\n",
        "                \n",
        "                group_map[key] = {\n",
        "                    'stacking': group_stacking[i],\n",
        "                    'prophet': group_individual.get('prophet', [0])[i] if i < len(group_individual.get('prophet', [])) else 0,\n",
        "                    'catboost': group_individual.get('catboost', [0])[i] if i < len(group_individual.get('catboost', [])) else 0\n",
        "                }\n",
        "        \n",
        "        group_prediction_maps[group_name] = group_map\n",
        "        print(f\"     ✅ {len(group_map):,}개 키-값 매핑 생성\")\n",
        "\n",
        "# 4. 원본 test_df의 각 행에 대해 예측값 할당\n",
        "print(f\"\\n🎯 원본 인덱스 순서대로 예측값 할당:\")\n",
        "\n",
        "for idx in range(len(result_df_original)):\n",
        "    if idx % 20000 == 0:  # 진행 상황 표시\n",
        "        print(f\"   처리 중: {idx:,}/{len(result_df_original):,} ({idx/len(result_df_original)*100:.1f}%)\")\n",
        "    \n",
        "    # 현재 행의 정보\n",
        "    tm = result_df_original.iloc[idx]['tm']\n",
        "    branch_id = result_df_original.iloc[idx]['branch_id']\n",
        "    heating_season = result_df_original.iloc[idx]['heating_season']\n",
        "    \n",
        "    # 그룹 결정\n",
        "    group_name = 'heating' if heating_season == 1 else 'non_heating'\n",
        "    \n",
        "    # 해당 그룹의 매핑에서 예측값 찾기\n",
        "    if group_name in group_prediction_maps:\n",
        "        key = (tm, branch_id)\n",
        "        \n",
        "        if key in group_prediction_maps[group_name]:\n",
        "            predictions = group_prediction_maps[group_name][key]\n",
        "            \n",
        "            # 예측값 할당\n",
        "            result_df_original.iloc[idx, result_df_original.columns.get_loc('stacking_prediction')] = predictions['stacking']\n",
        "            result_df_original.iloc[idx, result_df_original.columns.get_loc('prophet_prediction')] = predictions['prophet']\n",
        "            result_df_original.iloc[idx, result_df_original.columns.get_loc('catboost_prediction')] = predictions['catboost']\n",
        "            \n",
        "            # 통계 업데이트\n",
        "            if heating_season == 1:\n",
        "                mapping_stats['heating_mapped'] += 1\n",
        "            else:\n",
        "                mapping_stats['non_heating_mapped'] += 1\n",
        "        else:\n",
        "            mapping_stats['failed_mapping'] += 1\n",
        "\n",
        "print(f\"\\n📊 매핑 완료 통계:\")\n",
        "print(f\"   전체 행: {mapping_stats['total_rows']:,}개\")\n",
        "print(f\"   난방시즌 매핑: {mapping_stats['heating_mapped']:,}개\")\n",
        "print(f\"   비난방시즌 매핑: {mapping_stats['non_heating_mapped']:,}개\")\n",
        "print(f\"   매핑 실패: {mapping_stats['failed_mapping']:,}개\")\n",
        "\n",
        "total_mapped = mapping_stats['heating_mapped'] + mapping_stats['non_heating_mapped']\n",
        "success_rate = total_mapped / mapping_stats['total_rows'] * 100\n",
        "print(f\"   성공률: {success_rate:.1f}%\")\n",
        "\n",
        "# 5. 음수값 제거 및 반올림\n",
        "result_df_original['stacking_prediction'] = np.maximum(result_df_original['stacking_prediction'], 0).round(1)\n",
        "result_df_original['prophet_prediction'] = np.maximum(result_df_original['prophet_prediction'], 0).round(1)\n",
        "result_df_original['catboost_prediction'] = np.maximum(result_df_original['catboost_prediction'], 0).round(1)\n",
        "\n",
        "# 6. 매핑 실패한 영값들 처리\n",
        "remaining_zeros = (result_df_original['stacking_prediction'] == 0).sum()\n",
        "print(f\"\\n🔧 매핑 후 남은 영값: {remaining_zeros:,}개\")\n",
        "\n",
        "if remaining_zeros > 0:\n",
        "    print(\"   💡 영값 후처리 중...\")\n",
        "    \n",
        "    # 지사별, 시즌별 평균으로 대체\n",
        "    fixed_count = 0\n",
        "    \n",
        "    for branch in result_df_original['branch_id'].unique():\n",
        "        for season in [0, 1]:\n",
        "            # 해당 조건의 영값들\n",
        "            zero_mask = (\n",
        "                (result_df_original['branch_id'] == branch) & \n",
        "                (result_df_original['heating_season'] == season) & \n",
        "                (result_df_original['stacking_prediction'] == 0)\n",
        "            )\n",
        "            zero_count = zero_mask.sum()\n",
        "            \n",
        "            if zero_count > 0:\n",
        "                # 같은 조건의 0이 아닌 값들의 평균\n",
        "                nonzero_mask = (\n",
        "                    (result_df_original['branch_id'] == branch) & \n",
        "                    (result_df_original['heating_season'] == season) & \n",
        "                    (result_df_original['stacking_prediction'] > 0)\n",
        "                )\n",
        "                nonzero_values = result_df_original[nonzero_mask]['stacking_prediction']\n",
        "                \n",
        "                if len(nonzero_values) > 0:\n",
        "                    avg_val = nonzero_values.mean()\n",
        "                    result_df_original.loc[zero_mask, 'stacking_prediction'] = avg_val\n",
        "                    fixed_count += zero_count\n",
        "    \n",
        "    print(f\"   ✅ {fixed_count:,}개 영값을 동일 조건 평균으로 대체\")\n",
        "\n",
        "# 7. 최종 결과 확인\n",
        "final_zeros = (result_df_original['stacking_prediction'] == 0).sum()\n",
        "print(f\"\\n📊 최종 결과:\")\n",
        "print(f\"   전체 데이터: {len(result_df_original):,}개\")\n",
        "print(f\"   영값: {final_zeros:,}개 ({final_zeros/len(result_df_original)*100:.1f}%)\")\n",
        "print(f\"   평균 예측값: {result_df_original['stacking_prediction'].mean():.2f}\")\n",
        "\n",
        "# 8. O~S 지사별 결과 확인\n",
        "print(f\"\\n📍 O~S 지사별 최종 상태:\")\n",
        "problem_branches = ['O', 'P', 'Q', 'R', 'S']\n",
        "\n",
        "for branch in problem_branches:\n",
        "    branch_data = result_df_original[result_df_original['branch_id'] == branch]\n",
        "    \n",
        "    if len(branch_data) > 0:\n",
        "        zero_count = (branch_data['stacking_prediction'] == 0).sum()\n",
        "        avg_pred = branch_data['stacking_prediction'].mean()\n",
        "        \n",
        "        # 시즌별 평균\n",
        "        heating_avg = branch_data[branch_data['heating_season'] == 1]['stacking_prediction'].mean()\n",
        "        non_heating_avg = branch_data[branch_data['heating_season'] == 0]['stacking_prediction'].mean()\n",
        "        \n",
        "        status = \"✅\" if zero_count == 0 else \"⚠️\" if zero_count < len(branch_data) * 0.1 else \"❌\"\n",
        "        \n",
        "        print(f\"   {status} 지사 {branch}: 평균 {avg_pred:6.2f} (난방 {heating_avg:.1f}, 비난방 {non_heating_avg:.1f})\")\n",
        "        print(f\"      영값: {zero_count:,}개 / {len(branch_data):,}개 ({zero_count/len(branch_data)*100:.1f}%)\")\n",
        "\n",
        "# 9. 원본 순서 확인\n",
        "print(f\"\\n🔍 원본 순서 유지 확인:\")\n",
        "print(\"   첫 10개 행의 시간과 지사:\")\n",
        "for i in range(10):\n",
        "    original_tm = test_df.iloc[i]['tm']\n",
        "    original_branch = test_df.iloc[i]['branch_id']\n",
        "    result_tm = result_df_original.iloc[i]['tm']\n",
        "    result_branch = result_df_original.iloc[i]['branch_id']\n",
        "    \n",
        "    match = \"✅\" if (original_tm == result_tm and original_branch == result_branch) else \"❌\"\n",
        "    print(f\"     [{i}] {original_tm} - {original_branch} {match}\")\n",
        "\n",
        "# 10. 파일 저장\n",
        "print(f\"\\n💾 원본 구조 기반 결과 저장:\")\n",
        "\n",
        "# 상세 결과 (원본 구조 유지)\n",
        "original_structure_filename = 'original_structure_predictions.csv'\n",
        "result_df_original.to_csv(original_structure_filename, index=False)\n",
        "print(f\"   📁 상세 결과: {original_structure_filename}\")\n",
        "\n",
        "# 제출용 파일\n",
        "submission_original = result_df_original[['tm', 'branch_id']].copy()\n",
        "submission_original['heat_demand'] = result_df_original['stacking_prediction']\n",
        "\n",
        "original_submission_filename = 'original_structure_submission.csv'\n",
        "submission_original.to_csv(original_submission_filename, index=False)\n",
        "print(f\"   📁 제출용: {original_submission_filename}\")\n",
        "\n",
        "# 11. 전역 변수 업데이트\n",
        "print(f\"\\n🔄 전역 변수 업데이트:\")\n",
        "result_df = result_df_original.copy()\n",
        "submission_df = submission_original.copy()\n",
        "\n",
        "print(\"✅ result_df와 submission_df 업데이트 완료!\")\n",
        "\n",
        "print(f\"\\n🎉 원본 test_df 구조 기반 예측값 매핑 완료!\")\n",
        "print(f\"📋 최종 결과:\")\n",
        "print(f\"   ✅ 원본 인덱스 순서 완벽 유지\")\n",
        "print(f\"   ✅ 각 행에 정확한 예측값 매핑\")\n",
        "print(f\"   ✅ 요청 컬럼 구조: tm, branch_id, heating_season, stacking_prediction, prophet_prediction, catboost_prediction, hour\")\n",
        "print(f\"   🎯 최종 제출 파일: {original_submission_filename}\")\n",
        "\n",
        "# 샘플 확인\n",
        "print(f\"\\n📋 최종 결과 샘플 (첫 5개 행):\")\n",
        "print(result_df_original[['tm', 'branch_id', 'heating_season', 'stacking_prediction', 'prophet_prediction', 'catboost_prediction', 'hour']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 기존 CSV 파일 지사별 시간순 정렬\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "1️⃣ 상세 예측 파일 정렬\n",
            "\n",
            "📁 상세 예측 파일 처리: original_structure_predictions.csv\n",
            "   ✅ 파일 읽기 완료: 166,915행 × 7열\n",
            "   📋 컬럼: ['tm', 'branch_id', 'heating_season', 'stacking_prediction', 'prophet_prediction', 'catboost_prediction', 'hour']\n",
            "   🔧 tm 컬럼 타입: object\n",
            "   ⚙️ datetime 변환 중...\n",
            "   ✅ 변환 완료: datetime64[ns]\n",
            "   📊 정렬 전 상태:\n",
            "      총 행수: 166,915개\n",
            "      고유 지사: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n",
            "      시간 범위: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00\n",
            "      지사별 데이터 개수:\n",
            "        지사 A: 8,785개\n",
            "        지사 B: 8,785개\n",
            "        지사 C: 8,785개\n",
            "        지사 D: 8,785개\n",
            "        지사 E: 8,785개\n",
            "        지사 F: 8,785개\n",
            "        지사 G: 8,785개\n",
            "        지사 H: 8,785개\n",
            "        지사 I: 8,785개\n",
            "        지사 J: 8,785개\n",
            "        지사 K: 8,785개\n",
            "        지사 L: 8,785개\n",
            "        지사 M: 8,785개\n",
            "        지사 N: 8,785개\n",
            "        지사 O: 8,785개\n",
            "        지사 P: 8,785개\n",
            "        지사 Q: 8,785개\n",
            "        지사 R: 8,785개\n",
            "        지사 S: 8,785개\n",
            "   🎯 정렬 실행: branch_id → tm\n",
            "   ✅ 정렬 완료!\n",
            "   🔍 정렬 결과 확인 (첫 10개):\n",
            "       0: 2024-01-01 00:00:00 - 지사A - 237.1\n",
            "       1: 2024-01-01 01:00:00 - 지사A - 222.2\n",
            "       2: 2024-01-01 02:00:00 - 지사A - 214.4\n",
            "       3: 2024-01-01 03:00:00 - 지사A - 210.6\n",
            "       4: 2024-01-01 04:00:00 - 지사A - 211.3\n",
            "       5: 2024-01-01 05:00:00 - 지사A - 216.8\n",
            "       6: 2024-01-01 06:00:00 - 지사A - 218.5\n",
            "       7: 2024-01-01 07:00:00 - 지사A - 235.9\n",
            "       8: 2024-01-01 08:00:00 - 지사A - 247.1\n",
            "       9: 2024-01-01 09:00:00 - 지사A - 247.8\n",
            "   📋 지사별 데이터 패턴:\n",
            "      지사 A: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00 (8,785개)\n",
            "      지사 B: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00 (8,785개)\n",
            "      지사 C: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00 (8,785개)\n",
            "\n",
            "============================================================\n",
            "2️⃣ 제출용 파일 정렬\n",
            "\n",
            "📁 제출용 파일 처리: original_structure_submission.csv\n",
            "   ✅ 파일 읽기 완료: 166,915행 × 3열\n",
            "   📋 컬럼: ['tm', 'branch_id', 'heat_demand']\n",
            "   🔧 tm 컬럼 타입: object\n",
            "   ⚙️ datetime 변환 중...\n",
            "   ✅ 변환 완료: datetime64[ns]\n",
            "   📊 정렬 전 상태:\n",
            "      총 행수: 166,915개\n",
            "      고유 지사: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n",
            "      시간 범위: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00\n",
            "      지사별 데이터 개수:\n",
            "        지사 A: 8,785개\n",
            "        지사 B: 8,785개\n",
            "        지사 C: 8,785개\n",
            "        지사 D: 8,785개\n",
            "        지사 E: 8,785개\n",
            "        지사 F: 8,785개\n",
            "        지사 G: 8,785개\n",
            "        지사 H: 8,785개\n",
            "        지사 I: 8,785개\n",
            "        지사 J: 8,785개\n",
            "        지사 K: 8,785개\n",
            "        지사 L: 8,785개\n",
            "        지사 M: 8,785개\n",
            "        지사 N: 8,785개\n",
            "        지사 O: 8,785개\n",
            "        지사 P: 8,785개\n",
            "        지사 Q: 8,785개\n",
            "        지사 R: 8,785개\n",
            "        지사 S: 8,785개\n",
            "   🎯 정렬 실행: branch_id → tm\n",
            "   ✅ 정렬 완료!\n",
            "   🔍 정렬 결과 확인 (첫 10개):\n",
            "       0: 2024-01-01 00:00:00 - 지사A - 237.1\n",
            "       1: 2024-01-01 01:00:00 - 지사A - 222.2\n",
            "       2: 2024-01-01 02:00:00 - 지사A - 214.4\n",
            "       3: 2024-01-01 03:00:00 - 지사A - 210.6\n",
            "       4: 2024-01-01 04:00:00 - 지사A - 211.3\n",
            "       5: 2024-01-01 05:00:00 - 지사A - 216.8\n",
            "       6: 2024-01-01 06:00:00 - 지사A - 218.5\n",
            "       7: 2024-01-01 07:00:00 - 지사A - 235.9\n",
            "       8: 2024-01-01 08:00:00 - 지사A - 247.1\n",
            "       9: 2024-01-01 09:00:00 - 지사A - 247.8\n",
            "   📋 지사별 데이터 패턴:\n",
            "      지사 A: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00 (8,785개)\n",
            "      지사 B: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00 (8,785개)\n",
            "      지사 C: 2024-01-01 00:00:00 ~ 2025-01-01 00:00:00 (8,785개)\n",
            "\n",
            "============================================================\n",
            "💾 정렬된 파일 저장\n",
            "   ✅ 상세 예측 파일 저장: sorted_original_structure_predictions.csv\n",
            "   ✅ 원본 파일 업데이트: original_structure_predictions.csv\n",
            "   ✅ 제출용 파일 저장: sorted_original_structure_submission.csv\n",
            "   ✅ 원본 파일 업데이트: original_structure_submission.csv\n",
            "\n",
            "🔄 전역 변수 업데이트:\n",
            "   ✅ result_df 업데이트 완료\n",
            "   ✅ submission_df 업데이트 완료\n",
            "\n",
            "🎉 모든 파일 정렬 완료!\n",
            "📁 생성된 파일:\n",
            "   📋 sorted_original_structure_predictions.csv\n",
            "   📋 original_structure_predictions.csv (업데이트됨)\n",
            "   📋 sorted_original_structure_submission.csv\n",
            "   📋 original_structure_submission.csv (업데이트됨)\n",
            "\n",
            "✨ 정렬 방식: 지사별(A,B,C...) → 시간순(날짜/시간)\n",
            "📊 모든 지사의 모든 시간 데이터가 지사별로 연속 배치됨\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 🔄 기존 CSV 파일들을 지사별 시간순으로 정렬\n",
        "print(\"🔄 기존 CSV 파일 지사별 시간순 정렬\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 파일 경로\n",
        "detail_file = 'original_structure_predictions.csv'\n",
        "submission_file = 'original_structure_submission.csv'\n",
        "\n",
        "def sort_csv_by_branch_and_time(file_path, file_type):\n",
        "    \"\"\"CSV 파일을 지사별, 시간순으로 정렬하는 함수\"\"\"\n",
        "    \n",
        "    print(f\"\\n📁 {file_type} 파일 처리: {file_path}\")\n",
        "    \n",
        "    try:\n",
        "        # 1. 파일 읽기\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"   ✅ 파일 읽기 완료: {len(df):,}행 × {len(df.columns)}열\")\n",
        "        print(f\"   📋 컬럼: {list(df.columns)}\")\n",
        "        \n",
        "        # 2. tm 컬럼을 datetime으로 변환\n",
        "        print(f\"   🔧 tm 컬럼 타입: {df['tm'].dtype}\")\n",
        "        if df['tm'].dtype == 'object':\n",
        "            print(\"   ⚙️ datetime 변환 중...\")\n",
        "            df['tm'] = pd.to_datetime(df['tm'])\n",
        "            print(f\"   ✅ 변환 완료: {df['tm'].dtype}\")\n",
        "        \n",
        "        # 3. 정렬 전 상태 확인\n",
        "        print(f\"   📊 정렬 전 상태:\")\n",
        "        print(f\"      총 행수: {len(df):,}개\")\n",
        "        print(f\"      고유 지사: {sorted(df['branch_id'].unique())}\")\n",
        "        print(f\"      시간 범위: {df['tm'].min()} ~ {df['tm'].max()}\")\n",
        "        \n",
        "        # 지사별 데이터 개수\n",
        "        branch_counts = df['branch_id'].value_counts().sort_index()\n",
        "        print(f\"      지사별 데이터 개수:\")\n",
        "        for branch, count in branch_counts.items():\n",
        "            print(f\"        지사 {branch}: {count:,}개\")\n",
        "        \n",
        "        # 4. 지사별, 시간순 정렬\n",
        "        print(f\"   🎯 정렬 실행: branch_id → tm\")\n",
        "        df_sorted = df.sort_values(['branch_id', 'tm'], ascending=[True, True])\n",
        "        df_sorted = df_sorted.reset_index(drop=True)\n",
        "        print(f\"   ✅ 정렬 완료!\")\n",
        "        \n",
        "        # 5. 정렬 결과 확인\n",
        "        print(f\"   🔍 정렬 결과 확인 (첫 10개):\")\n",
        "        for i in range(min(10, len(df_sorted))):\n",
        "            tm = df_sorted.iloc[i]['tm']\n",
        "            branch = df_sorted.iloc[i]['branch_id']\n",
        "            if 'heat_demand' in df_sorted.columns:\n",
        "                value = df_sorted.iloc[i]['heat_demand']\n",
        "                print(f\"      {i:2d}: {tm} - 지사{branch} - {value:.1f}\")\n",
        "            elif 'stacking_prediction' in df_sorted.columns:\n",
        "                value = df_sorted.iloc[i]['stacking_prediction']\n",
        "                print(f\"      {i:2d}: {tm} - 지사{branch} - {value:.1f}\")\n",
        "            else:\n",
        "                print(f\"      {i:2d}: {tm} - 지사{branch}\")\n",
        "        \n",
        "        # 6. 지사별 패턴 확인\n",
        "        print(f\"   📋 지사별 데이터 패턴:\")\n",
        "        for branch in sorted(df_sorted['branch_id'].unique())[:3]:  # 처음 3개 지사만\n",
        "            branch_data = df_sorted[df_sorted['branch_id'] == branch]\n",
        "            first_time = branch_data['tm'].iloc[0]\n",
        "            last_time = branch_data['tm'].iloc[-1]\n",
        "            print(f\"      지사 {branch}: {first_time} ~ {last_time} ({len(branch_data):,}개)\")\n",
        "        \n",
        "        return df_sorted\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(f\"   ❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ 오류 발생: {e}\")\n",
        "        return None\n",
        "\n",
        "# 1. 상세 예측 파일 정렬\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"1️⃣ 상세 예측 파일 정렬\")\n",
        "sorted_detail_df = sort_csv_by_branch_and_time(detail_file, \"상세 예측\")\n",
        "\n",
        "# 2. 제출용 파일 정렬  \n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"2️⃣ 제출용 파일 정렬\")\n",
        "sorted_submission_df = sort_csv_by_branch_and_time(submission_file, \"제출용\")\n",
        "\n",
        "# 3. 정렬된 파일 저장\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"💾 정렬된 파일 저장\")\n",
        "\n",
        "if sorted_detail_df is not None:\n",
        "    # 새로운 파일명 생성\n",
        "    sorted_detail_file = 'sorted_' + detail_file\n",
        "    sorted_detail_df.to_csv(sorted_detail_file, index=False)\n",
        "    print(f\"   ✅ 상세 예측 파일 저장: {sorted_detail_file}\")\n",
        "    \n",
        "    # 원본 파일도 덮어쓰기\n",
        "    sorted_detail_df.to_csv(detail_file, index=False)\n",
        "    print(f\"   ✅ 원본 파일 업데이트: {detail_file}\")\n",
        "\n",
        "if sorted_submission_df is not None:\n",
        "    # 새로운 파일명 생성\n",
        "    sorted_submission_file = 'sorted_' + submission_file\n",
        "    sorted_submission_df.to_csv(sorted_submission_file, index=False)\n",
        "    print(f\"   ✅ 제출용 파일 저장: {sorted_submission_file}\")\n",
        "    \n",
        "    # 원본 파일도 덮어쓰기\n",
        "    sorted_submission_df.to_csv(submission_file, index=False)\n",
        "    print(f\"   ✅ 원본 파일 업데이트: {submission_file}\")\n",
        "\n",
        "# 4. 전역 변수 업데이트 (있다면)\n",
        "print(f\"\\n🔄 전역 변수 업데이트:\")\n",
        "if sorted_detail_df is not None:\n",
        "    try:\n",
        "        result_df = sorted_detail_df.copy()\n",
        "        print(\"   ✅ result_df 업데이트 완료\")\n",
        "    except:\n",
        "        print(\"   ⚠️ result_df 업데이트 불가 (변수 없음)\")\n",
        "\n",
        "if sorted_submission_df is not None:\n",
        "    try:\n",
        "        submission_df = sorted_submission_df.copy()\n",
        "        print(\"   ✅ submission_df 업데이트 완료\")\n",
        "    except:\n",
        "        print(\"   ⚠️ submission_df 업데이트 불가 (변수 없음)\")\n",
        "\n",
        "# 5. 최종 요약\n",
        "print(f\"\\n🎉 모든 파일 정렬 완료!\")\n",
        "print(f\"📁 생성된 파일:\")\n",
        "if sorted_detail_df is not None:\n",
        "    print(f\"   📋 sorted_{detail_file}\")\n",
        "    print(f\"   📋 {detail_file} (업데이트됨)\")\n",
        "if sorted_submission_df is not None:\n",
        "    print(f\"   📋 sorted_{submission_file}\")\n",
        "    print(f\"   📋 {submission_file} (업데이트됨)\")\n",
        "\n",
        "print(f\"\\n✨ 정렬 방식: 지사별(A,B,C...) → 시간순(날짜/시간)\")\n",
        "print(f\"📊 모든 지사의 모든 시간 데이터가 지사별로 연속 배치됨\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
